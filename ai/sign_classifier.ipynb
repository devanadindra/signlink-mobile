{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397381d5",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5efbb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl (16.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt_einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, idna, grpcio, google_pasta, gast, fonttools, cycler, charset_normalizer, certifi, astunparse, absl-py, werkzeug, scipy, requests, opencv-python, ml_dtypes, markdown-it-py, h5py, contourpy, tensorboard, rich, onnx, matplotlib, tf2onnx, keras, tensorflow\n",
      "\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "   -- -------------------------------------  3/42 [wrapt]\n",
      "   ---- -----------------------------------  5/42 [termcolor]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   --------- ------------------------------ 10/42 [optree]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ------------- -------------------------- 14/42 [MarkupSafe]\n",
      "   ---------------- ----------------------- 17/42 [idna]\n",
      "   ----------------- ---------------------- 18/42 [grpcio]\n",
      "   ------------------ --------------------- 19/42 [google_pasta]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   --------------------- ------------------ 23/42 [charset_normalizer]\n",
      "   ------------------------ --------------- 26/42 [absl-py]\n",
      "   ------------------------- -------------- 27/42 [werkzeug]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   --------------------------- ------------ 29/42 [requests]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ------------------------------ --------- 32/42 [markdown-it-py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------- 42/42 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.10.5 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.9.23 fonttools-4.60.1 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.15.0 idna-3.11 keras-3.11.3 kiwisolver-1.4.9 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.2.6 onnx-1.19.1 opencv-python-4.12.0.88 opt_einsum-3.4.0 optree-0.17.0 pillow-12.0.0 protobuf-6.33.0 pyparsing-3.2.5 requests-2.32.5 rich-14.2.0 scipy-1.16.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 tf2onnx-1.8.4 urllib3-2.5.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tf2onnx matplotlib numpy opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed27fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.20-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.15-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.14-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.13-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: pip is still looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.16.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.14.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.11.4-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.3-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (192 kB)\n",
      "  Using cached scipy-1.11.1.tar.gz (56.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2 /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.9.1\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: SciPy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 0.29.37)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/usr/local/bin/python3)\n",
      "  \u001b[31m   \u001b[0m Did not find pkg-config by name 'pkg-config'\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: NO\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.12\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-build-env-whd2yr7w/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../../meson.build:82:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall tensorflow tf2onnx matplotlib numpy opencv-python scipy mediapipe pandas tqdm scikit-learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "908a35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m959.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18590",
   "metadata": {},
   "source": [
    "# import and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc1fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be719935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "model_name = 'sign_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13103e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766be0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0  114M    0 83232    0     0  54378      0  0:36:51  0:00:01  0:36:50 54378\n",
      "  8  114M    8 10.0M    0     0  4148k      0  0:00:28  0:00:02  0:00:26 10.5M\n",
      " 18  114M   18 21.2M    0     0  6273k      0  0:00:18  0:00:03  0:00:15 10.9M\n",
      " 28  114M   28 32.5M    0     0  7453k      0  0:00:15  0:00:04  0:00:11 11.0M\n",
      " 38  114M   38 43.8M    0     0  8198k      0  0:00:14  0:00:05  0:00:09 11.0M\n",
      " 48  114M   48 55.1M    0     0  8716k      0  0:00:13  0:00:06  0:00:07 11.1M\n",
      " 56  114M   56 65.1M    0     0  8920k      0  0:00:13  0:00:07  0:00:06 11.0M\n",
      " 66  114M   66 76.4M    0     0  9230k      0  0:00:12  0:00:08  0:00:04 11.0M\n",
      " 76  114M   76 87.6M    0     0  9475k      0  0:00:12  0:00:09  0:00:03 11.0M\n",
      " 86  114M   86 98.9M    0     0  9671k      0  0:00:12  0:00:10  0:00:02 11.0M\n",
      " 96  114M   96  110M    0     0  9834k      0  0:00:11  0:00:11 --:--:-- 11.0M\n",
      "100  114M  100  114M    0     0  9892k      0  0:00:11  0:00:11 --:--:-- 11.2M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./alfabet-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/achmadnoer/alfabet-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66037a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./alfabet-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./alfabet-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21028c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Memindahkan 'Citra BISINDO' ke './dataset' ...\n",
      "✅ Berhasil dipindahkan ke ./dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = \"Citra BISINDO\"\n",
    "dst_dir = \"./dataset\"\n",
    "\n",
    "if not os.path.exists(src_dir):\n",
    "    raise FileNotFoundError(f\"❌ Folder sumber tidak ditemukan: {src_dir}\")\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📂 Memindahkan '{src_dir}' ke '{dst_dir}' ...\")\n",
    "shutil.move(src_dir, dst_dir)\n",
    "print(f\"✅ Berhasil dipindahkan ke {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b1bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 1396M    0  110k    0     0  70686      0  5:45:23  0:00:01  5:45:22  111k\n",
      "  0 1396M    0 2528k    0     0   976k      0  0:24:25  0:00:02  0:24:23 1277k\n",
      "  0 1396M    0 7005k    0     0  1950k      0  0:12:13  0:00:03  0:12:10 2350k\n",
      "  0 1396M    0 11.4M    0     0  2551k      0  0:09:20  0:00:04  0:09:16 2942k\n",
      "  1 1396M    1 16.0M    0     0  2945k      0  0:08:05  0:00:05  0:08:00 3306k\n",
      "  1 1396M    1 20.4M    0     0  3179k      0  0:07:29  0:00:06  0:07:23 4178k\n",
      "  1 1396M    1 23.4M    0     0  3167k      0  0:07:31  0:00:07  0:07:24 4303k\n",
      "  1 1396M    1 27.1M    0     0  3238k      0  0:07:21  0:00:08  0:07:13 4164k\n",
      "  2 1396M    2 31.2M    0     0  3337k      0  0:07:08  0:00:09  0:06:59 4059k\n",
      "  2 1396M    2 35.2M    0     0  3403k      0  0:07:00  0:00:10  0:06:50 3915k\n",
      "  2 1396M    2 39.7M    0     0  3511k      0  0:06:47  0:00:11  0:06:36 3948k\n",
      "  3 1396M    3 43.8M    0     0  3566k      0  0:06:41  0:00:12  0:06:29 4172k\n",
      "  3 1396M    3 47.9M    0     0  3614k      0  0:06:35  0:00:13  0:06:22 4259k\n",
      "  3 1396M    3 52.5M    0     0  3688k      0  0:06:27  0:00:14  0:06:13 4361k\n",
      "  4 1396M    4 57.9M    0     0  3804k      0  0:06:16  0:00:15  0:06:01 4652k\n",
      "  4 1396M    4 62.7M    0     0  3871k      0  0:06:09  0:00:16  0:05:53 4708k\n",
      "  4 1396M    4 67.7M    0     0  3943k      0  0:06:02  0:00:17  0:05:45 4892k\n",
      "  5 1396M    5 72.7M    0     0  4004k      0  0:05:57  0:00:18  0:05:39 5064k\n",
      "  5 1396M    5 77.8M    0     0  4067k      0  0:05:51  0:00:19  0:05:32 5173k\n",
      "  5 1396M    5 82.9M    0     0  4124k      0  0:05:46  0:00:20  0:05:26 5123k\n",
      "  6 1396M    6 87.4M    0     0  4149k      0  0:05:44  0:00:21  0:05:23 5073k\n",
      "  6 1396M    6 92.4M    0     0  4191k      0  0:05:41  0:00:22  0:05:19 5061k\n",
      "  6 1396M    6 97.3M    0     0  4225k      0  0:05:38  0:00:23  0:05:15 5049k\n",
      "  7 1396M    7  102M    0     0  4260k      0  0:05:35  0:00:24  0:05:11 5016k\n",
      "  7 1396M    7  107M    0     0  4294k      0  0:05:33  0:00:25  0:05:08 4995k\n",
      "  8 1396M    8  112M    0     0  4318k      0  0:05:31  0:00:26  0:05:05 5046k\n",
      "  8 1396M    8  116M    0     0  4339k      0  0:05:29  0:00:27  0:05:02 5009k\n",
      "  8 1396M    8  121M    0     0  4360k      0  0:05:28  0:00:28  0:05:00 4992k\n",
      "  9 1396M    9  127M    0     0  4404k      0  0:05:24  0:00:29  0:04:55 5111k\n",
      "  9 1396M    9  132M    0     0  4437k      0  0:05:22  0:00:30  0:04:52 5171k\n",
      "  9 1396M    9  137M    0     0  4472k      0  0:05:19  0:00:31  0:04:48 5292k\n",
      " 10 1396M   10  142M    0     0  4486k      0  0:05:18  0:00:32  0:04:46 5299k\n",
      " 10 1396M   10  146M    0     0  4455k      0  0:05:21  0:00:33  0:04:48 5005k\n",
      " 10 1396M   10  150M    0     0  4445k      0  0:05:21  0:00:34  0:04:47 4690k\n",
      " 10 1396M   10  153M    0     0  4416k      0  0:05:23  0:00:35  0:04:48 4284k\n",
      " 11 1396M   11  157M    0     0  4399k      0  0:05:25  0:00:36  0:04:49 3939k\n",
      " 11 1396M   11  160M    0     0  4380k      0  0:05:26  0:00:37  0:04:49 3691k\n",
      " 11 1396M   11  164M    0     0  4364k      0  0:05:27  0:00:38  0:04:49 3750k\n",
      " 12 1396M   12  168M    0     0  4360k      0  0:05:28  0:00:39  0:04:49 3770k\n",
      " 12 1396M   12  172M    0     0  4364k      0  0:05:27  0:00:40  0:04:47 3993k\n",
      " 12 1396M   12  177M    0     0  4368k      0  0:05:27  0:00:41  0:04:46 4140k\n",
      " 12 1396M   12  181M    0     0  4363k      0  0:05:27  0:00:42  0:04:45 4231k\n",
      " 13 1396M   13  185M    0     0  4367k      0  0:05:27  0:00:43  0:04:44 4387k\n",
      " 13 1396M   13  190M    0     0  4370k      0  0:05:27  0:00:44  0:04:43 4454k\n",
      " 13 1396M   13  195M    0     0  4392k      0  0:05:25  0:00:45  0:04:40 4621k\n",
      " 14 1396M   14  202M    0     0  4448k      0  0:05:21  0:00:46  0:04:35 5116k\n",
      " 14 1396M   14  208M    0     0  4489k      0  0:05:18  0:00:47  0:04:31 5561k\n",
      " 15 1396M   15  214M    0     0  4514k      0  0:05:16  0:00:48  0:04:28 5802k\n",
      " 15 1396M   15  219M    0     0  4542k      0  0:05:14  0:00:49  0:04:25 6076k\n",
      " 16 1396M   16  225M    0     0  4567k      0  0:05:13  0:00:50  0:04:23 6166k\n",
      " 16 1396M   16  231M    0     0  4595k      0  0:05:11  0:00:51  0:04:20 5961k\n",
      " 16 1396M   16  237M    0     0  4622k      0  0:05:09  0:00:52  0:04:17 5886k\n",
      " 17 1396M   17  242M    0     0  4636k      0  0:05:08  0:00:53  0:04:15 5820k\n",
      " 17 1396M   17  248M    0     0  4661k      0  0:05:06  0:00:54  0:04:12 5840k\n",
      " 18 1396M   18  254M    0     0  4685k      0  0:05:05  0:00:55  0:04:10 5874k\n",
      " 18 1396M   18  260M    0     0  4720k      0  0:05:03  0:00:56  0:04:07 6006k\n",
      " 19 1396M   19  270M    0     0  4803k      0  0:04:57  0:00:57  0:04:00 6714k\n",
      " 20 1396M   20  281M    0     0  4918k      0  0:04:50  0:00:58  0:03:52 7942k\n",
      " 20 1396M   20  292M    0     0  5029k      0  0:04:44  0:00:59  0:03:45 9049k\n",
      " 21 1396M   21  303M    0     0  5137k      0  0:04:38  0:01:00  0:03:38  9.9M\n",
      " 22 1396M   22  315M    0     0  5241k      0  0:04:32  0:01:01  0:03:31 10.8M\n",
      " 23 1396M   23  325M    0     0  5320k      0  0:04:28  0:01:02  0:03:26 11.0M\n",
      " 24 1396M   24  336M    0     0  5418k      0  0:04:23  0:01:03  0:03:20 11.0M\n",
      " 24 1396M   24  347M    0     0  5513k      0  0:04:19  0:01:04  0:03:15 11.0M\n",
      " 25 1396M   25  359M    0     0  5605k      0  0:04:15  0:01:05  0:03:10 11.0M\n",
      " 26 1396M   26  370M    0     0  5694k      0  0:04:11  0:01:06  0:03:05 11.0M\n",
      " 27 1396M   27  380M    0     0  5762k      0  0:04:08  0:01:07  0:03:01 11.0M\n",
      " 28 1396M   28  391M    0     0  5846k      0  0:04:04  0:01:08  0:02:56 11.0M\n",
      " 28 1396M   28  402M    0     0  5928k      0  0:04:01  0:01:09  0:02:52 11.0M\n",
      " 29 1396M   29  414M    0     0  6008k      0  0:03:58  0:01:10  0:02:48 11.0M\n",
      " 30 1396M   30  425M    0     0  6085k      0  0:03:55  0:01:11  0:02:44 11.0M\n",
      " 31 1396M   31  436M    0     0  6159k      0  0:03:52  0:01:12  0:02:40 11.2M\n",
      " 31 1396M   31  446M    0     0  6216k      0  0:03:50  0:01:13  0:02:37 11.0M\n",
      " 32 1396M   32  458M    0     0  6287k      0  0:03:47  0:01:14  0:02:33 11.0M\n",
      " 33 1396M   33  469M    0     0  6357k      0  0:03:45  0:01:15  0:02:30 11.0M\n",
      " 34 1396M   34  480M    0     0  6424k      0  0:03:42  0:01:16  0:02:26 11.0M\n",
      " 35 1396M   35  490M    0     0  6466k      0  0:03:41  0:01:17  0:02:24 10.6M\n",
      " 35 1396M   35  496M    0     0  6463k      0  0:03:41  0:01:18  0:02:23  9.8M\n",
      " 36 1396M   36  504M    0     0  6494k      0  0:03:40  0:01:19  0:02:21 9580k\n",
      " 36 1396M   36  510M    0     0  6489k      0  0:03:40  0:01:20  0:02:20 8492k\n",
      " 37 1396M   37  521M    0     0  6549k      0  0:03:38  0:01:21  0:02:17 8464k\n",
      " 38 1396M   38  533M    0     0  6608k      0  0:03:36  0:01:22  0:02:14 8824k\n",
      " 38 1396M   38  544M    0     0  6664k      0  0:03:34  0:01:23  0:02:11 9815k\n",
      " 39 1396M   39  554M    0     0  6717k      0  0:03:32  0:01:24  0:02:08 10.0M\n",
      " 40 1396M   40  565M    0     0  6771k      0  0:03:31  0:01:25  0:02:06 11.0M\n",
      " 41 1396M   41  577M    0     0  6826k      0  0:03:29  0:01:26  0:02:03 11.0M\n",
      " 42 1396M   42  588M    0     0  6879k      0  0:03:27  0:01:27  0:02:00 11.0M\n",
      " 42 1396M   42  599M    0     0  6931k      0  0:03:26  0:01:28  0:01:58 11.1M\n",
      " 43 1396M   43  609M    0     0  6964k      0  0:03:25  0:01:29  0:01:56 10.8M\n",
      " 44 1396M   44  620M    0     0  7014k      0  0:03:23  0:01:30  0:01:53 10.9M\n",
      " 45 1396M   45  631M    0     0  7062k      0  0:03:22  0:01:31  0:01:51 10.8M\n",
      " 46 1396M   46  642M    0     0  7110k      0  0:03:21  0:01:32  0:01:49 10.8M\n",
      " 46 1396M   46  654M    0     0  7156k      0  0:03:19  0:01:33  0:01:46 10.8M\n",
      " 47 1396M   47  664M    0     0  7189k      0  0:03:18  0:01:34  0:01:44 10.9M\n",
      " 48 1396M   48  675M    0     0  7234k      0  0:03:17  0:01:35  0:01:42 10.9M\n",
      " 49 1396M   49  686M    0     0  7278k      0  0:03:16  0:01:36  0:01:40 10.9M\n",
      " 49 1396M   49  697M    0     0  7321k      0  0:03:15  0:01:37  0:01:38 10.9M\n",
      " 50 1396M   50  708M    0     0  7363k      0  0:03:14  0:01:38  0:01:36 10.9M\n",
      " 51 1396M   51  720M    0     0  7405k      0  0:03:13  0:01:39  0:01:34 11.2M\n",
      " 52 1396M   52  730M    0     0  7433k      0  0:03:12  0:01:40  0:01:32 10.9M\n",
      " 53 1396M   53  741M    0     0  7473k      0  0:03:11  0:01:41  0:01:30 10.9M\n",
      " 53 1396M   53  752M    0     0  7512k      0  0:03:10  0:01:42  0:01:28 10.9M\n",
      " 54 1396M   54  763M    0     0  7551k      0  0:03:09  0:01:43  0:01:26 10.9M\n",
      " 55 1396M   55  775M    0     0  7589k      0  0:03:08  0:01:44  0:01:24 10.9M\n",
      " 56 1396M   56  785M    0     0  7613k      0  0:03:07  0:01:45  0:01:22 10.9M\n",
      " 57 1396M   57  796M    0     0  7649k      0  0:03:06  0:01:46  0:01:20 10.9M\n",
      " 57 1396M   57  807M    0     0  7685k      0  0:03:06  0:01:47  0:01:19 10.9M\n",
      " 58 1396M   58  818M    0     0  7720k      0  0:03:05  0:01:48  0:01:17 10.9M\n",
      " 59 1396M   59  829M    0     0  7755k      0  0:03:04  0:01:49  0:01:15 10.9M\n",
      " 60 1396M   60  839M    0     0  7777k      0  0:03:03  0:01:50  0:01:13 10.9M\n",
      " 60 1396M   60  851M    0     0  7810k      0  0:03:03  0:01:51  0:01:12 10.9M\n",
      " 61 1396M   61  862M    0     0  7843k      0  0:03:02  0:01:52  0:01:10 10.9M\n",
      " 62 1396M   62  873M    0     0  7875k      0  0:03:01  0:01:53  0:01:08 10.9M\n",
      " 63 1396M   63  884M    0     0  7907k      0  0:03:00  0:01:54  0:01:06 10.9M\n",
      " 64 1396M   64  894M    0     0  7928k      0  0:03:00  0:01:55  0:01:05 11.0M\n",
      " 64 1396M   64  906M    0     0  7958k      0  0:02:59  0:01:56  0:01:03 10.9M\n",
      " 65 1396M   65  917M    0     0  7988k      0  0:02:59  0:01:57  0:01:02 10.9M\n",
      " 66 1396M   66  928M    0     0  8018k      0  0:02:58  0:01:58  0:01:00 10.9M\n",
      " 67 1396M   67  939M    0     0  8047k      0  0:02:57  0:01:59  0:00:58 10.9M\n",
      " 68 1396M   68  950M    0     0  8075k      0  0:02:57  0:02:00  0:00:57 11.2M\n",
      " 68 1396M   68  961M    0     0  8094k      0  0:02:56  0:02:01  0:00:55 10.9M\n",
      " 69 1396M   69  972M    0     0  8121k      0  0:02:56  0:02:02  0:00:54 10.9M\n",
      " 70 1396M   70  983M    0     0  8149k      0  0:02:55  0:02:03  0:00:52 10.9M\n",
      " 71 1396M   71  994M    0     0  8176k      0  0:02:54  0:02:04  0:00:50 10.9M\n",
      " 72 1396M   72 1006M    0     0  8202k      0  0:02:54  0:02:05  0:00:49 11.0M\n",
      " 72 1396M   72 1015M    0     0  8218k      0  0:02:54  0:02:06  0:00:48 10.9M\n",
      " 73 1396M   73 1027M    0     0  8244k      0  0:02:53  0:02:07  0:00:46 10.9M\n",
      " 74 1396M   74 1038M    0     0  8269k      0  0:02:52  0:02:08  0:00:44 10.9M\n",
      " 75 1396M   75 1049M    0     0  8294k      0  0:02:52  0:02:09  0:00:43 10.9M\n",
      " 75 1396M   75 1060M    0     0  8319k      0  0:02:51  0:02:10  0:00:41 10.9M\n",
      " 76 1396M   76 1070M    0     0  8332k      0  0:02:51  0:02:11  0:00:40 10.9M\n",
      " 77 1396M   77 1082M    0     0  8356k      0  0:02:51  0:02:12  0:00:39 10.9M\n",
      " 78 1396M   78 1093M    0     0  8380k      0  0:02:50  0:02:13  0:00:37 10.9M\n",
      " 79 1396M   79 1104M    0     0  8403k      0  0:02:50  0:02:14  0:00:36 10.9M\n",
      " 79 1396M   79 1115M    0     0  8426k      0  0:02:49  0:02:15  0:00:34 10.9M\n",
      " 80 1396M   80 1125M    0     0  8439k      0  0:02:49  0:02:16  0:00:33 10.9M\n",
      " 81 1396M   81 1136M    0     0  8461k      0  0:02:49  0:02:17  0:00:32 10.9M\n",
      " 82 1396M   82 1148M    0     0  8483k      0  0:02:48  0:02:18  0:00:30 10.9M\n",
      " 82 1396M   82 1159M    0     0  8505k      0  0:02:48  0:02:19  0:00:29 10.9M\n",
      " 83 1396M   83 1170M    0     0  8526k      0  0:02:47  0:02:20  0:00:27 10.9M\n",
      " 84 1396M   84 1181M    0     0  8545k      0  0:02:47  0:02:21  0:00:26 11.1M\n",
      " 85 1396M   85 1191M    0     0  8559k      0  0:02:47  0:02:22  0:00:25 10.9M\n",
      " 86 1396M   86 1203M    0     0  8579k      0  0:02:46  0:02:23  0:00:23 10.9M\n",
      " 86 1396M   86 1214M    0     0  8599k      0  0:02:46  0:02:24  0:00:22 10.9M\n",
      " 87 1396M   87 1225M    0     0  8619k      0  0:02:45  0:02:25  0:00:20 10.9M\n",
      " 88 1396M   88 1236M    0     0  8639k      0  0:02:45  0:02:26  0:00:19 11.0M\n",
      " 89 1396M   89 1246M    0     0  8650k      0  0:02:45  0:02:27  0:00:18 10.9M\n",
      " 90 1396M   90 1258M    0     0  8669k      0  0:02:45  0:02:28  0:00:17 10.9M\n",
      " 90 1396M   90 1269M    0     0  8688k      0  0:02:44  0:02:29  0:00:15 10.9M\n",
      " 91 1396M   91 1280M    0     0  8707k      0  0:02:44  0:02:30  0:00:14 10.9M\n",
      " 92 1396M   92 1291M    0     0  8725k      0  0:02:43  0:02:31  0:00:12 10.9M\n",
      " 93 1396M   93 1301M    0     0  8734k      0  0:02:43  0:02:32  0:00:11 10.9M\n",
      " 93 1396M   93 1312M    0     0  8752k      0  0:02:43  0:02:33  0:00:10 10.9M\n",
      " 94 1396M   94 1323M    0     0  8769k      0  0:02:43  0:02:34  0:00:09 10.9M\n",
      " 95 1396M   95 1335M    0     0  8787k      0  0:02:42  0:02:35  0:00:07 10.9M\n",
      " 96 1396M   96 1346M    0     0  8804k      0  0:02:42  0:02:36  0:00:06 10.9M\n",
      " 97 1396M   97 1356M    0     0  8813k      0  0:02:42  0:02:37  0:00:05 10.9M\n",
      " 97 1396M   97 1367M    0     0  8830k      0  0:02:41  0:02:38  0:00:03 10.9M\n",
      " 98 1396M   98 1378M    0     0  8847k      0  0:02:41  0:02:39  0:00:02 10.9M\n",
      " 99 1396M   99 1390M    0     0  8863k      0  0:02:41  0:02:40  0:00:01 10.9M\n",
      "100 1396M  100 1396M    0     0  8874k      0  0:02:41  0:02:41 --:--:-- 10.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/agungmrf/indonesian-sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    Example: src_folder/cat -> dataset/cat\n",
    "             src_folder/dog -> dataset/dog\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all label folders in the source\n",
    "    for label in os.listdir(src_folder):\n",
    "        # Lewati folder yang mengandung '_npy'\n",
    "        if \"_npy\" in label:\n",
    "            continue\n",
    "        \n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Skip if not a folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Move all files from src → dest\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Avoid overwriting files with same name\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_2{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c61958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "def unzip_file(zip_path,extract_dir = \"./\"):\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "    print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "    if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "        print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "    else:\n",
    "        print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d301a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def remove_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(\"✅ Folder berhasil dihapus.\")\n",
    "    else:\n",
    "        print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./indonesian-sign-language-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "unzip_file(\"./indonesian-sign-language-bisindo.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61be52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/train' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/val' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1353535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./bisindo\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "remove_folder('./bisindo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbeabb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/yunitayupratiwi/bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./bisindo-dataset.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "unzip_file(\"./bisindo-dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, based on the first letter of the filename.\n",
    "    Example: src_folder/A.66ae97e2-c1e4-11eb-83d3-0008ca6b6d30.jpg -> dataset/A\n",
    "             src_folder/B.002d8fdf-c1e3-11eb-952a-0008ca6b6d30.jpg -> dataset/B\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all file folders in the source\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "\n",
    "        # Skip if a folder\n",
    "        if os.path.isdir(src_file):\n",
    "            continue\n",
    "        \n",
    "        # Skip if not a jpg\n",
    "        if not src_file.lower().endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        label = filename[0].upper()  # First character as label\n",
    "        dest = os.path.join(dataset_dir, label)\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        dst_file = os.path.join(dest, filename)\n",
    "\n",
    "        # Avoid overwriting files with same name\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            dst_file = os.path.join(dest, f\"{base}_3{ext}\")\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "    print(f\"successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b15a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf12b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./BISINDO - Dataset\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "remove_folder('./BISINDO - Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca6282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  238M  100  238M    0     0   952k      0  0:04:17  0:04:16  0:00:01  937k0:14:54  0:00:02  0:14:52  367k48k      0  0:05:26  0:00:52  0:04:34  680k  0:01:14  0:04:07  824k:04:00  808k    0   762k      0  0:05:20  0:01:21  0:03:59  801k03:44  984kM    0     0   838k      0  0:04:51  0:01:46  0:03:05 1354k 0   839k      0  0:04:51  0:01:47  0:03:04 1247k 0   951k      0  0:04:17  0:04:17 --:--:--  889k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/bonarsitorus/sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667681d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./sign-language-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "unzip_file(\"./sign-language-bisindo.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "debd9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './data_tambahan' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa3406b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./data_tambahan\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "remove_folder('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da58f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1944M  100 1944M    0     0  1384k      0  0:23:58  0:23:58 --:--:-- 1620k  1289k      0  0:25:44  0:00:35  0:25:09 1107k    0  0:25:05  0:00:52  0:24:13 1231k:25:11  930k2:35  0:01:37  0:20:58 1712k:20:45 1870k   0  1510k      0  0:21:58  0:01:58  0:20:00 1295k30  0:02:03  0:20:27  599k2:55  0:02:08  0:20:47  794k      0  0:23:20  0:02:17  0:21:03  706k8k      0  0:23:24  0:02:31  0:20:53 1673k  0:23:12  0:02:37  0:20:35 1660k3:18  0:02:38  0:20:40 1286k1383k      0  0:23:59  0:02:51  0:21:08  906k      0  0:24:05  0:02:55  0:21:10 1172k 0:21:07 1661k82k      0  0:24:00  0:03:51  0:20:09  813k03:59  0:20:19  804kk1339k      0  0:24:47  0:05:30  0:19:17 1022k06:40  0:17:47 1785k0     0  1354k      0  0:24:30  0:07:02  0:17:28  849k4  0:16:58 1683k22  0:07:37  0:16:45 1668k0:07:51  0:16:17 1896kk      0  0:23:55  0:08:08  0:15:47 1609k    0  0:23:58  0:08:12  0:15:46 1089k0  0:23:51  0:08:34  0:15:17 1328k08:56  0:15:04 1120k 0  1374k      0  0:24:08  0:09:10  0:14:58 1260k0:24:07  0:09:15  0:14:52 1463k0:14:46 1587k   0  0:24:18  0:09:42  0:14:36  593k 1042k     0  0:24:25  0:10:10  0:14:15 1320k 0:10:17  0:14:11 1015k6k      0  0:24:39  0:10:30  0:14:09  868k:03  0:13:47 1161k 0:24:50  0:11:04  0:13:46 1249k:15 1328k2:25 1482k  1321k      0  0:25:06  0:13:03  0:12:03 1544k1M    0     0  1328k      0  0:24:59  0:13:30  0:11:29 1590k3k      0  0:24:42  0:14:05  0:10:37 1889k24:41  0:14:13  0:10:28 1573k:18 1698k   0     0  1343k      0  0:24:42  0:14:28  0:10:14  852k  694k  174k:25:08  0:14:55  0:10:13  715k:14:56  0:10:14  705k  1306k      0  0:25:24  0:15:24  0:10:00  840k0  1305k      0  0:25:25  0:15:26  0:09:59  892k 0:25:26  0:15:27  0:09:59  962k 1306k      0  0:25:24  0:15:30  0:09:54 1375k  0:25:23  0:15:40  0:09:43 1594k53  0:09:31 1029k 0  0:25:23  0:16:02  0:09:21 1481k  0  0:25:17  0:16:18  0:08:59 1551k 0:25:17  0:16:24  0:08:53 1142k  0  0:25:14  0:16:33  0:08:41 1677k   0  0:25:10  0:16:45  0:08:25 1648k0  1318k      0  0:25:10  0:16:47  0:08:23 1401k:25:08  0:17:00  0:08:08 1339k0:25:09  0:17:12  0:07:57 1152k7:39 1438k3  0:07:37 1294k 0:17:55  0:07:06 1721k 1326k      0  0:25:01  0:18:08  0:06:53  783k30k      0  0:24:57  0:18:22  0:06:35 1750k24:53  0:18:32  0:06:21 1633k0     0  1341k      0  0:24:44  0:18:49  0:05:55 2106k77 1503M    0     0  1346k      0  0:24:38  0:19:03  0:05:35 1496k0:24:32  0:19:24  0:05:08 1409k358k      0  0:24:26  0:20:03  0:04:23 1385k32k0  1361k      0  0:24:22  0:20:50  0:03:32 1422k:24:18  0:21:12  0:03:06 1532k   87 1701M    0     0  1364k      0  0:24:19  0:21:16  0:03:03 1208k:24:14  0:21:38  0:02:36 1775k  1370k      0  0:24:13  0:21:45  0:02:28 1531k50M    0     0  1370k      0  0:24:12  0:21:47  0:02:25 1497k 1769k  1373k      0  0:24:10  0:22:24  0:01:46 1579k   0     0  1375k      0  0:24:07  0:22:37  0:01:30 1613k0  0:24:05  0:23:07  0:00:58 1638k15  0:00:50 1397k     0  0:24:05  0:23:20  0:00:45 1446k:21  0:00:44 1504kk      0  0:24:03  0:23:31  0:00:32 1659k 0  0:24:01  0:23:37  0:00:24 1714k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-hand-sign-language-bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/kelsha/indonesian-hand-sign-language-bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "321d2d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./indonesian-hand-sign-language-bisindo-dataset.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "unzip_file(\"./indonesian-hand-sign-language-bisindo-dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f31bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './dataset_bisindo/train/images' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./dataset_bisindo/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d39e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './dataset_bisindo/val/images' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./dataset_bisindo/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1beb708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./dataset_bisindo\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "remove_folder(\"./dataset_bisindo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 2198M  100 2197M    0     0  1517k      0  0:24:43  0:24:42  0:00:01  568k   0     0  1659k      0  0:22:36  0:00:31  0:22:05 2007k47  0:00:36  0:22:11 1553kk     0  0:22:54  0:00:53  0:22:01 1672k 0  1697k      0  0:22:06  0:01:15  0:20:51 1689k01  0:01:19  0:20:42 1814k 1704k      0  0:22:00  0:01:20  0:20:40 1820k:50  0:01:29  0:21:21 1060k:01:51  0:21:12 1507k2:52  0:02:01  0:20:51 1726k:55  0:02:05  0:20:50 1538k:22:51  0:02:12  0:20:39 1828k   0  1640k      0  0:22:51  0:02:14  0:20:37 1832k22:27  0:02:50  0:19:37 1691k    0  1688k      0  0:22:12  0:03:13  0:18:59 1755k20  0:18:45 2060k707k      0  0:21:58  0:03:28  0:18:30 1978k 1707k      0  0:21:58  0:03:29  0:18:29 1991k  0:18:10 2012k5  0:04:24  0:17:01 1897k90k      0  0:20:56  0:04:42  0:16:14 2650k     0  0:21:03  0:05:07  0:15:56 2003k6 2378kk      0  0:20:52  0:05:29  0:15:23 1248k28  630M    0     0  1722k      0  0:21:46  0:06:14  0:15:32 1096k    0  0:21:50  0:06:16  0:15:34  918k15:33  873k4 1151k0:06:31  0:15:42  808k658k      0  0:22:36  0:06:50  0:15:46 1835k  0:06:56  0:15:42 1594k:37  0:07:04  0:15:33 1692k 0  0:22:43  0:08:07  0:14:36 1436k50k      0  0:22:43  0:08:10  0:14:33 1600k      0  0:22:45  0:08:29  0:14:16 1794k:08:43  0:13:58 1800k     0  0:22:41  0:08:50  0:13:51 1472kk      0  0:22:37  0:09:13  0:13:24 1532k2:36  0:09:16  0:13:20 1589k:35  0:09:34  0:13:01 1381k2  936M    0     0  1662k      0  0:22:33  0:09:36  0:12:57 1786k 0  0:22:26  0:09:51  0:12:35 1945k  0:10:16  0:12:06 1474k   0  0:22:21  0:10:23  0:11:58 1852k0:10:24  0:11:57 1845k76k      0  0:22:22  0:10:32  0:11:50 1652k48 1208k 0  0:22:23  0:10:56  0:11:27 1761k  0:22:19  0:11:04  0:11:15 2064k  0:22:20  0:11:07  0:11:13 1625k  0:10:39 1926k 0  1685k      0  0:22:15  0:11:38  0:10:37 1770k:51  0:10:21 1663k92k      0  0:22:09  0:11:59  0:10:10 2127k2:07  0:12:08  0:09:59 1826k  0  1696k      0  0:22:06  0:12:25  0:09:41 1437k 0  0:22:08  0:12:27  0:09:41 1107k   56 1244M    0     0  1688k      0  0:22:12  0:12:34  0:09:38 1328k9:24 1000k  0:13:07  0:09:25  858k 0  0:22:36  0:13:20  0:09:16 1264k 1659k      0  0:22:36  0:13:24  0:09:12 1499k0:13:39  0:09:04 1071k  0:22:46  0:13:45  0:09:01 1029k 0:13:50  0:09:00  844k 0  1628k      0  0:23:02  0:14:21  0:08:41 1784k8M   62 1372M    0     0  1626k      0  0:23:03  0:14:23  0:08:40 1399k  0:08:36  960k4:44  0:08:30 1595k6  0:08:22 1288k23:18  0:15:03  0:08:15 1638k05k      0  0:23:22  0:15:18  0:08:04  913k 1604k      0  0:23:23  0:15:21  0:08:02 1105kk      0  0:23:30  0:15:46  0:07:44 1096k1 1545k      0  0:23:32  0:15:59  0:07:33 1160k 1590k      0  0:23:35  0:16:04  0:07:31 1107k:07  0:07:30  871k0:16:25  0:07:22 1006k19  740k 0  0:23:58  0:17:08  0:06:50 1826k41 2415k:11 2256k23:36  0:17:50  0:05:46 2350k0:23:25  0:18:19  0:05:06 1917k  0  0:23:24  0:18:24  0:05:00 1807k 2198M   79 1747M    0     0  1606k      0  0:23:21  0:18:33  0:04:48 1975k0:04:44 1776k88k     0  0:23:17  0:18:50  0:04:27 1422k 0:23:17  0:18:51  0:04:26 1390k5  393k0:23:27  0:19:03  0:04:24  538k510k    0     0  1587k      0  0:23:38  0:19:25  0:04:13 1514k0:04:09 1265k4k      0  0:23:40  0:19:34  0:04:06 1162k23:42  0:19:36  0:04:06  953k6k4k      0  0:23:58  0:20:29  0:03:29  924k:30  0:03:28  994k 1886M    0     0  1560k      0  0:24:01  0:20:37  0:03:24  929k22 1091k  0:20:44  0:03:19 1184kk      0  0:24:00  0:21:10  0:02:50 2212k:32 1449k8  0:21:28  0:02:30 1131k21:41  0:02:21 1008k2:15 1216k4 1305k21:58  0:02:09 1071k0:22:01  0:02:06 1476k 0:24:16  0:22:25  0:01:51 1089k  0  1544k      0  0:24:17  0:22:30  0:01:47 1206kk      0  0:24:20  0:22:38  0:01:42 1057k7k50  0:01:33 1165k 94 2071M    0     0  1537k      0  0:24:24  0:22:59  0:01:25 1268k 0:24:26  0:23:08  0:01:18 1198k:01:09 1755k0:24:26  0:23:39  0:00:47 1197k  0  0:24:26  0:23:49  0:00:37 1412k0  0:24:26  0:23:51  0:00:35 1296k 1518k      0  0:24:41  0:24:40  0:00:01  870k98M    0     0  1517k      0  0:24:43  0:24:43 --:--:--  601k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o .bisindo-final.zip/\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/skripsiairlangga/bisindo-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93998690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari bisindo-final.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./temp_dataset\n"
     ]
    }
   ],
   "source": [
    "unzip_file(\"bisindo-final.zip\",\"./temp_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ce715f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './temp_dataset' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./temp_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcd4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./temp_dataset\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "remove_folder('./temp_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc5e9ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760603272.901772 1210015 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760603272.927674 1401344 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760603272.933433 1401350 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)  # dua tangan\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4257553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    \n",
    "    if not result.multi_hand_landmarks:\n",
    "        return None\n",
    "    \n",
    "    # List semua tangan yang terdeteksi\n",
    "    coords_all = []\n",
    "    for landmarks in result.multi_hand_landmarks:\n",
    "        coords = []\n",
    "        for lm in landmarks.landmark:\n",
    "            coords.extend([lm.x, lm.y, lm.z])\n",
    "        coords_all.append(coords)\n",
    "    \n",
    "    # Jika hanya 1 tangan, tambahkan 0 agar panjang fitur tetap konsisten\n",
    "    if len(coords_all) == 1:\n",
    "        coords_all.append([0.0]*63)  # tangan kosong\n",
    "    \n",
    "    # Flatten dua tangan (kanan + kiri)\n",
    "    features = np.array(coords_all[0] + coords_all[1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d20d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1185 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "100%|██████████| 1185/1185 [00:44<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:44<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:38<00:00, 30.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:48<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1192/1192 [00:40<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1223/1223 [00:44<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1211/1211 [00:48<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:47<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1210/1210 [00:41<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:40<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1181/1181 [00:47<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1205/1205 [00:40<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [00:52<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:48<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [00:42<00:00, 28.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1205/1205 [00:48<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1180/1180 [00:50<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:41<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1176/1176 [00:50<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1212/1212 [00:50<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1203/1203 [00:41<00:00, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1204/1204 [00:42<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:49<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:51<00:00, 23.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [00:43<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1211/1211 [00:41<00:00, 29.14it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label in sorted(os.listdir(dataset_dir)):\n",
    "    label_path = os.path.join(dataset_dir, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing label: {label}')\n",
    "    for img_name in tqdm(os.listdir(label_path)):\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        landmarks = extract_hand_landmarks(img_path)\n",
    "        if landmarks is not None:\n",
    "            data.append(landmarks)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7e16017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dan label berhasil disimpan ke hand_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "# Ubah list menjadi DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "# Simpan ke CSV\n",
    "df.to_csv(\"hand_keypoints.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data dan label berhasil disimpan ke hand_keypoints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeba27f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9411987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 25042\n",
      "          0         1             2         3         4         5         6  \\\n",
      "0  0.589247  0.788576  7.728872e-08  0.540709  0.797574 -0.010116  0.494011   \n",
      "1  0.212959  0.805963  9.068014e-07  0.289683  0.816899 -0.121823  0.372062   \n",
      "2  0.816977  0.762781 -9.138290e-08  0.801776  0.732194  0.003006  0.774098   \n",
      "3  0.113166  0.822598  5.402187e-07  0.195478  0.813337 -0.077612  0.288585   \n",
      "4  0.261052  0.846672  7.994739e-07  0.341049  0.836045 -0.129487  0.410872   \n",
      "\n",
      "          7         8         9  ...       117       118       119       120  \\\n",
      "0  0.776065 -0.034892  0.458913  ...  0.259818  0.687959 -0.093514  0.256858   \n",
      "1  0.769015 -0.183119  0.454951  ...  0.842265  0.543980 -0.132140  0.839403   \n",
      "2  0.710473  0.000879  0.747478  ...  0.627653  0.740314 -0.056922  0.625121   \n",
      "3  0.775301 -0.115066  0.381175  ...  0.871712  0.542661 -0.079860  0.875387   \n",
      "4  0.782396 -0.189924  0.487691  ...  0.855348  0.492066 -0.134088  0.863155   \n",
      "\n",
      "        121       122       123       124       125  label  \n",
      "0  0.731087 -0.083110  0.242543  0.740920 -0.070937      A  \n",
      "1  0.625160 -0.115789  0.830242  0.676599 -0.085944      A  \n",
      "2  0.737795 -0.057063  0.627400  0.744683 -0.054733      A  \n",
      "3  0.603266 -0.072772  0.862451  0.643375 -0.055663      A  \n",
      "4  0.576930 -0.119729  0.856915  0.633002 -0.090756      A  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hand_keypoints.csv\")\n",
    "print(f\"Total data: {len(df)}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8db2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "X = df.drop('label', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84f130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3f9fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "565b55f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,354</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m32,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m3,354\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9753c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2742 - loss: 2.4622 - val_accuracy: 0.5233 - val_loss: 1.7429\n",
      "Epoch 2/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5186 - loss: 1.6601 - val_accuracy: 0.6544 - val_loss: 1.2588\n",
      "Epoch 3/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6142 - loss: 1.3427 - val_accuracy: 0.7319 - val_loss: 1.0242\n",
      "Epoch 4/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6594 - loss: 1.1704 - val_accuracy: 0.7357 - val_loss: 0.9552\n",
      "Epoch 5/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6964 - loss: 1.0598 - val_accuracy: 0.7872 - val_loss: 0.8133\n",
      "Epoch 6/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7211 - loss: 0.9715 - val_accuracy: 0.7732 - val_loss: 0.7961\n",
      "Epoch 7/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7345 - loss: 0.9196 - val_accuracy: 0.7988 - val_loss: 0.7275\n",
      "Epoch 8/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7514 - loss: 0.8613 - val_accuracy: 0.8133 - val_loss: 0.6754\n",
      "Epoch 9/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7646 - loss: 0.8168 - val_accuracy: 0.8297 - val_loss: 0.6351\n",
      "Epoch 10/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7715 - loss: 0.7920 - val_accuracy: 0.8345 - val_loss: 0.6064\n",
      "Epoch 11/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7822 - loss: 0.7633 - val_accuracy: 0.8457 - val_loss: 0.5679\n",
      "Epoch 12/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7868 - loss: 0.7380 - val_accuracy: 0.8475 - val_loss: 0.5550\n",
      "Epoch 13/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7927 - loss: 0.7155 - val_accuracy: 0.8509 - val_loss: 0.5359\n",
      "Epoch 14/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.6949 - val_accuracy: 0.8597 - val_loss: 0.5051\n",
      "Epoch 15/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8083 - loss: 0.6659 - val_accuracy: 0.8415 - val_loss: 0.5414\n",
      "Epoch 16/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.6636 - val_accuracy: 0.8593 - val_loss: 0.4966\n",
      "Epoch 17/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8119 - loss: 0.6431 - val_accuracy: 0.8620 - val_loss: 0.4890\n",
      "Epoch 18/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.6314 - val_accuracy: 0.8758 - val_loss: 0.4467\n",
      "Epoch 19/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.6151 - val_accuracy: 0.8726 - val_loss: 0.4535\n",
      "Epoch 20/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8239 - loss: 0.5949 - val_accuracy: 0.8784 - val_loss: 0.4348\n",
      "Epoch 21/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8262 - loss: 0.5990 - val_accuracy: 0.8870 - val_loss: 0.4267\n",
      "Epoch 22/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8312 - loss: 0.5797 - val_accuracy: 0.8762 - val_loss: 0.4287\n",
      "Epoch 23/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8249 - loss: 0.5921 - val_accuracy: 0.8828 - val_loss: 0.4200\n",
      "Epoch 24/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.5557 - val_accuracy: 0.8834 - val_loss: 0.4011\n",
      "Epoch 25/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.5676 - val_accuracy: 0.8870 - val_loss: 0.4088\n",
      "Epoch 26/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.5445 - val_accuracy: 0.8884 - val_loss: 0.3897\n",
      "Epoch 27/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.5356 - val_accuracy: 0.8900 - val_loss: 0.3884\n",
      "Epoch 28/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8411 - loss: 0.5324 - val_accuracy: 0.8896 - val_loss: 0.3827\n",
      "Epoch 29/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.5261 - val_accuracy: 0.8880 - val_loss: 0.3908\n",
      "Epoch 30/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.5254 - val_accuracy: 0.8908 - val_loss: 0.3840\n",
      "Epoch 31/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8478 - loss: 0.5189 - val_accuracy: 0.8934 - val_loss: 0.3649\n",
      "Epoch 32/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8508 - loss: 0.5026 - val_accuracy: 0.8962 - val_loss: 0.3609\n",
      "Epoch 33/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8507 - loss: 0.5024 - val_accuracy: 0.8926 - val_loss: 0.3700\n",
      "Epoch 34/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.5104 - val_accuracy: 0.8996 - val_loss: 0.3520\n",
      "Epoch 35/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.4986 - val_accuracy: 0.8974 - val_loss: 0.3580\n",
      "Epoch 36/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8514 - loss: 0.4826 - val_accuracy: 0.9054 - val_loss: 0.3493\n",
      "Epoch 37/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8521 - loss: 0.4882 - val_accuracy: 0.9078 - val_loss: 0.3282\n",
      "Epoch 38/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.4723 - val_accuracy: 0.9034 - val_loss: 0.3354\n",
      "Epoch 39/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8586 - loss: 0.4693 - val_accuracy: 0.9052 - val_loss: 0.3428\n",
      "Epoch 40/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.4693 - val_accuracy: 0.9080 - val_loss: 0.3280\n",
      "Epoch 41/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.4621 - val_accuracy: 0.9030 - val_loss: 0.3358\n",
      "Epoch 42/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.4706 - val_accuracy: 0.9068 - val_loss: 0.3328\n",
      "Epoch 43/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.4686 - val_accuracy: 0.9094 - val_loss: 0.3254\n",
      "Epoch 44/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.4640 - val_accuracy: 0.9070 - val_loss: 0.3288\n",
      "Epoch 45/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8621 - loss: 0.4507 - val_accuracy: 0.9082 - val_loss: 0.3222\n",
      "Epoch 46/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8644 - loss: 0.4453 - val_accuracy: 0.9090 - val_loss: 0.3161\n",
      "Epoch 47/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8621 - loss: 0.4468 - val_accuracy: 0.9130 - val_loss: 0.3190\n",
      "Epoch 48/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8685 - loss: 0.4374 - val_accuracy: 0.9118 - val_loss: 0.3205\n",
      "Epoch 49/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.4390 - val_accuracy: 0.9102 - val_loss: 0.3114\n",
      "Epoch 50/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.4411 - val_accuracy: 0.9136 - val_loss: 0.3032\n",
      "Epoch 51/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8664 - loss: 0.4443 - val_accuracy: 0.9169 - val_loss: 0.2936\n",
      "Epoch 52/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8685 - loss: 0.4399 - val_accuracy: 0.9156 - val_loss: 0.2958\n",
      "Epoch 53/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8682 - loss: 0.4283 - val_accuracy: 0.9120 - val_loss: 0.3053\n",
      "Epoch 54/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.4450 - val_accuracy: 0.9164 - val_loss: 0.2895\n",
      "Epoch 55/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.4330 - val_accuracy: 0.9110 - val_loss: 0.3104\n",
      "Epoch 56/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8711 - loss: 0.4196 - val_accuracy: 0.9106 - val_loss: 0.3070\n",
      "Epoch 57/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8719 - loss: 0.4173 - val_accuracy: 0.9154 - val_loss: 0.2969\n",
      "Epoch 58/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8713 - loss: 0.4250 - val_accuracy: 0.9158 - val_loss: 0.3018\n",
      "Epoch 59/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8729 - loss: 0.4159 - val_accuracy: 0.9179 - val_loss: 0.2806\n",
      "Epoch 60/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.4240 - val_accuracy: 0.9106 - val_loss: 0.3043\n",
      "Epoch 61/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8753 - loss: 0.4061 - val_accuracy: 0.9187 - val_loss: 0.2924\n",
      "Epoch 62/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.4131 - val_accuracy: 0.9193 - val_loss: 0.2867\n",
      "Epoch 63/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8770 - loss: 0.4071 - val_accuracy: 0.9211 - val_loss: 0.2887\n",
      "Epoch 64/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8752 - loss: 0.4037 - val_accuracy: 0.9209 - val_loss: 0.2842\n",
      "Epoch 65/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8751 - loss: 0.4013 - val_accuracy: 0.9152 - val_loss: 0.2961\n",
      "Epoch 66/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.4040 - val_accuracy: 0.9154 - val_loss: 0.2928\n",
      "Epoch 67/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8742 - loss: 0.3982 - val_accuracy: 0.9179 - val_loss: 0.2860\n",
      "Epoch 68/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8772 - loss: 0.4008 - val_accuracy: 0.9183 - val_loss: 0.2846\n",
      "Epoch 69/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.3985 - val_accuracy: 0.9175 - val_loss: 0.2790\n",
      "Epoch 70/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8779 - loss: 0.3926 - val_accuracy: 0.9239 - val_loss: 0.2780\n",
      "Epoch 71/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.3885 - val_accuracy: 0.9193 - val_loss: 0.2753\n",
      "Epoch 72/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8804 - loss: 0.3962 - val_accuracy: 0.9219 - val_loss: 0.2788\n",
      "Epoch 73/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8767 - loss: 0.3985 - val_accuracy: 0.9207 - val_loss: 0.2763\n",
      "Epoch 74/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.3917 - val_accuracy: 0.9249 - val_loss: 0.2697\n",
      "Epoch 75/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8788 - loss: 0.3892 - val_accuracy: 0.9213 - val_loss: 0.2707\n",
      "Epoch 76/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.3836 - val_accuracy: 0.9207 - val_loss: 0.2789\n",
      "Epoch 77/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3877 - val_accuracy: 0.9195 - val_loss: 0.2921\n",
      "Epoch 78/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8788 - loss: 0.3934 - val_accuracy: 0.9243 - val_loss: 0.2689\n",
      "Epoch 79/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3748 - val_accuracy: 0.9197 - val_loss: 0.2774\n",
      "Epoch 80/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.3830 - val_accuracy: 0.9257 - val_loss: 0.2645\n",
      "Epoch 81/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.3730 - val_accuracy: 0.9217 - val_loss: 0.2706\n",
      "Epoch 82/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8825 - loss: 0.3820 - val_accuracy: 0.9197 - val_loss: 0.2785\n",
      "Epoch 83/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.3746 - val_accuracy: 0.9203 - val_loss: 0.2656\n",
      "Epoch 84/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.3711 - val_accuracy: 0.9231 - val_loss: 0.2576\n",
      "Epoch 85/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8854 - loss: 0.3676 - val_accuracy: 0.9197 - val_loss: 0.2629\n",
      "Epoch 86/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8848 - loss: 0.3676 - val_accuracy: 0.9213 - val_loss: 0.2789\n",
      "Epoch 87/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8857 - loss: 0.3677 - val_accuracy: 0.9229 - val_loss: 0.2600\n",
      "Epoch 88/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8863 - loss: 0.3644 - val_accuracy: 0.9247 - val_loss: 0.2589\n",
      "Epoch 89/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8825 - loss: 0.3725 - val_accuracy: 0.9211 - val_loss: 0.2681\n",
      "Epoch 90/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.3656 - val_accuracy: 0.9243 - val_loss: 0.2520\n",
      "Epoch 91/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.3738 - val_accuracy: 0.9233 - val_loss: 0.2681\n",
      "Epoch 92/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8868 - loss: 0.3618 - val_accuracy: 0.9267 - val_loss: 0.2666\n",
      "Epoch 93/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.3626 - val_accuracy: 0.9301 - val_loss: 0.2522\n",
      "Epoch 94/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8862 - loss: 0.3641 - val_accuracy: 0.9259 - val_loss: 0.2534\n",
      "Epoch 95/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8895 - loss: 0.3576 - val_accuracy: 0.9241 - val_loss: 0.2626\n",
      "Epoch 96/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.3644 - val_accuracy: 0.9257 - val_loss: 0.2628\n",
      "Epoch 97/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.3673 - val_accuracy: 0.9253 - val_loss: 0.2510\n",
      "Epoch 98/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8887 - loss: 0.3580 - val_accuracy: 0.9239 - val_loss: 0.2593\n",
      "Epoch 99/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3642 - val_accuracy: 0.9221 - val_loss: 0.2630\n",
      "Epoch 100/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8888 - loss: 0.3593 - val_accuracy: 0.9279 - val_loss: 0.2487\n",
      "Epoch 101/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.3600 - val_accuracy: 0.9283 - val_loss: 0.2483\n",
      "Epoch 102/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8899 - loss: 0.3487 - val_accuracy: 0.9185 - val_loss: 0.2668\n",
      "Epoch 103/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8889 - loss: 0.3549 - val_accuracy: 0.9311 - val_loss: 0.2452\n",
      "Epoch 104/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3784 - val_accuracy: 0.9255 - val_loss: 0.2501\n",
      "Epoch 105/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8891 - loss: 0.3515 - val_accuracy: 0.9293 - val_loss: 0.2473\n",
      "Epoch 106/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.3616 - val_accuracy: 0.9251 - val_loss: 0.2515\n",
      "Epoch 107/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.3572 - val_accuracy: 0.9223 - val_loss: 0.2611\n",
      "Epoch 108/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8898 - loss: 0.3476 - val_accuracy: 0.9283 - val_loss: 0.2525\n",
      "Epoch 109/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8904 - loss: 0.3458 - val_accuracy: 0.9301 - val_loss: 0.2454\n",
      "Epoch 110/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.3423 - val_accuracy: 0.9297 - val_loss: 0.2434\n",
      "Epoch 111/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8901 - loss: 0.3544 - val_accuracy: 0.9283 - val_loss: 0.2473\n",
      "Epoch 112/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8857 - loss: 0.3639 - val_accuracy: 0.9325 - val_loss: 0.2399\n",
      "Epoch 113/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.3499 - val_accuracy: 0.9245 - val_loss: 0.2536\n",
      "Epoch 114/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8907 - loss: 0.3414 - val_accuracy: 0.9299 - val_loss: 0.2484\n",
      "Epoch 115/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8920 - loss: 0.3436 - val_accuracy: 0.9309 - val_loss: 0.2455\n",
      "Epoch 116/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3609 - val_accuracy: 0.9311 - val_loss: 0.2464\n",
      "Epoch 117/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.3493 - val_accuracy: 0.9317 - val_loss: 0.2385\n",
      "Epoch 118/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8920 - loss: 0.3366 - val_accuracy: 0.9293 - val_loss: 0.2468\n",
      "Epoch 119/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8886 - loss: 0.3576 - val_accuracy: 0.9303 - val_loss: 0.2453\n",
      "Epoch 120/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.3464 - val_accuracy: 0.9299 - val_loss: 0.2499\n",
      "Epoch 121/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8929 - loss: 0.3384 - val_accuracy: 0.9289 - val_loss: 0.2480\n",
      "Epoch 122/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.3404 - val_accuracy: 0.9305 - val_loss: 0.2462\n",
      "Epoch 123/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8916 - loss: 0.3421 - val_accuracy: 0.9231 - val_loss: 0.2547\n",
      "Epoch 124/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8934 - loss: 0.3389 - val_accuracy: 0.9267 - val_loss: 0.2499\n",
      "Epoch 125/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8953 - loss: 0.3335 - val_accuracy: 0.9309 - val_loss: 0.2432\n",
      "Epoch 126/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.3346 - val_accuracy: 0.9281 - val_loss: 0.2495\n",
      "Epoch 127/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.3304 - val_accuracy: 0.9321 - val_loss: 0.2373\n",
      "Epoch 128/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.3385 - val_accuracy: 0.9287 - val_loss: 0.2376\n",
      "Epoch 129/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.3342 - val_accuracy: 0.9283 - val_loss: 0.2510\n",
      "Epoch 130/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.3329 - val_accuracy: 0.9341 - val_loss: 0.2395\n",
      "Epoch 131/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.3298 - val_accuracy: 0.9289 - val_loss: 0.2396\n",
      "Epoch 132/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.3386 - val_accuracy: 0.9311 - val_loss: 0.2350\n",
      "Epoch 133/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8963 - loss: 0.3276 - val_accuracy: 0.9327 - val_loss: 0.2383\n",
      "Epoch 134/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.3275 - val_accuracy: 0.9349 - val_loss: 0.2425\n",
      "Epoch 135/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.3335 - val_accuracy: 0.9281 - val_loss: 0.2508\n",
      "Epoch 136/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.3330 - val_accuracy: 0.9311 - val_loss: 0.2383\n",
      "Epoch 137/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.3348 - val_accuracy: 0.9279 - val_loss: 0.2560\n",
      "Epoch 138/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8955 - loss: 0.3234 - val_accuracy: 0.9319 - val_loss: 0.2340\n",
      "Epoch 139/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.3256 - val_accuracy: 0.9297 - val_loss: 0.2527\n",
      "Epoch 140/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.3258 - val_accuracy: 0.9291 - val_loss: 0.2430\n",
      "Epoch 141/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8904 - loss: 0.3486 - val_accuracy: 0.9323 - val_loss: 0.2349\n",
      "Epoch 142/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3234 - val_accuracy: 0.9335 - val_loss: 0.2373\n",
      "Epoch 143/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.3252 - val_accuracy: 0.9319 - val_loss: 0.2419\n",
      "Epoch 144/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.3546 - val_accuracy: 0.9303 - val_loss: 0.2463\n",
      "Epoch 145/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.3286 - val_accuracy: 0.9311 - val_loss: 0.2396\n",
      "Epoch 146/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.3229 - val_accuracy: 0.9351 - val_loss: 0.2325\n",
      "Epoch 147/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3254 - val_accuracy: 0.9325 - val_loss: 0.2364\n",
      "Epoch 148/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.3284 - val_accuracy: 0.9321 - val_loss: 0.2397\n",
      "Epoch 149/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.3275 - val_accuracy: 0.9329 - val_loss: 0.2357\n",
      "Epoch 150/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.3312 - val_accuracy: 0.9341 - val_loss: 0.2332\n",
      "Epoch 151/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.3269 - val_accuracy: 0.9357 - val_loss: 0.2325\n",
      "Epoch 152/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.3106 - val_accuracy: 0.9269 - val_loss: 0.2485\n",
      "Epoch 153/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8953 - loss: 0.3268 - val_accuracy: 0.9301 - val_loss: 0.2382\n",
      "Epoch 154/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3221 - val_accuracy: 0.9333 - val_loss: 0.2271\n",
      "Epoch 155/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.3281 - val_accuracy: 0.9373 - val_loss: 0.2248\n",
      "Epoch 156/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.3172 - val_accuracy: 0.9359 - val_loss: 0.2257\n",
      "Epoch 157/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.3181 - val_accuracy: 0.9297 - val_loss: 0.2337\n",
      "Epoch 158/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.3159 - val_accuracy: 0.9345 - val_loss: 0.2310\n",
      "Epoch 159/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8996 - loss: 0.3199 - val_accuracy: 0.9301 - val_loss: 0.2338\n",
      "Epoch 160/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.3240 - val_accuracy: 0.9295 - val_loss: 0.2355\n",
      "Epoch 161/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8995 - loss: 0.3212 - val_accuracy: 0.9331 - val_loss: 0.2376\n",
      "Epoch 162/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3155 - val_accuracy: 0.9307 - val_loss: 0.2364\n",
      "Epoch 163/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.3201 - val_accuracy: 0.9323 - val_loss: 0.2344\n",
      "Epoch 164/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 0.3136 - val_accuracy: 0.9361 - val_loss: 0.2281\n",
      "Epoch 165/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8985 - loss: 0.3191 - val_accuracy: 0.9339 - val_loss: 0.2287\n",
      "Epoch 166/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3202 - val_accuracy: 0.9309 - val_loss: 0.2355\n",
      "Epoch 167/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8982 - loss: 0.3251 - val_accuracy: 0.9333 - val_loss: 0.2257\n",
      "Epoch 168/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.3077 - val_accuracy: 0.9363 - val_loss: 0.2232\n",
      "Epoch 169/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3125 - val_accuracy: 0.9341 - val_loss: 0.2276\n",
      "Epoch 170/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.3130 - val_accuracy: 0.9379 - val_loss: 0.2299\n",
      "Epoch 171/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3022 - val_accuracy: 0.9351 - val_loss: 0.2319\n",
      "Epoch 172/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3094 - val_accuracy: 0.9301 - val_loss: 0.2439\n",
      "Epoch 173/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2991 - val_accuracy: 0.9331 - val_loss: 0.2373\n",
      "Epoch 174/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3148 - val_accuracy: 0.9365 - val_loss: 0.2290\n",
      "Epoch 175/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8977 - loss: 0.3208 - val_accuracy: 0.9333 - val_loss: 0.2238\n",
      "Epoch 176/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.3084 - val_accuracy: 0.9331 - val_loss: 0.2274\n",
      "Epoch 177/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.3115 - val_accuracy: 0.9351 - val_loss: 0.2233\n",
      "Epoch 178/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.3123 - val_accuracy: 0.9345 - val_loss: 0.2275\n",
      "Epoch 179/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.3135 - val_accuracy: 0.9333 - val_loss: 0.2403\n",
      "Epoch 180/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.3040 - val_accuracy: 0.9335 - val_loss: 0.2283\n",
      "Epoch 181/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3004 - val_accuracy: 0.9377 - val_loss: 0.2201\n",
      "Epoch 182/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.3118 - val_accuracy: 0.9309 - val_loss: 0.2348\n",
      "Epoch 183/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.3146 - val_accuracy: 0.9347 - val_loss: 0.2245\n",
      "Epoch 184/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8991 - loss: 0.3123 - val_accuracy: 0.9363 - val_loss: 0.2196\n",
      "Epoch 185/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.3018 - val_accuracy: 0.9333 - val_loss: 0.2290\n",
      "Epoch 186/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.3003 - val_accuracy: 0.9353 - val_loss: 0.2279\n",
      "Epoch 187/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.3124 - val_accuracy: 0.9353 - val_loss: 0.2205\n",
      "Epoch 188/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2997 - val_accuracy: 0.9347 - val_loss: 0.2276\n",
      "Epoch 189/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3138 - val_accuracy: 0.9375 - val_loss: 0.2258\n",
      "Epoch 190/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3051 - val_accuracy: 0.9335 - val_loss: 0.2293\n",
      "Epoch 191/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.3045 - val_accuracy: 0.9337 - val_loss: 0.2227\n",
      "Epoch 192/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9058 - loss: 0.2948 - val_accuracy: 0.9309 - val_loss: 0.2336\n",
      "Epoch 193/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.3033 - val_accuracy: 0.9359 - val_loss: 0.2243\n",
      "Epoch 194/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.3035 - val_accuracy: 0.9371 - val_loss: 0.2255\n",
      "Epoch 195/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.3116 - val_accuracy: 0.9301 - val_loss: 0.2370\n",
      "Epoch 196/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.3019 - val_accuracy: 0.9349 - val_loss: 0.2266\n",
      "Epoch 197/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3046 - val_accuracy: 0.9309 - val_loss: 0.2326\n",
      "Epoch 198/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2930 - val_accuracy: 0.9397 - val_loss: 0.2206\n",
      "Epoch 199/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.3101 - val_accuracy: 0.9363 - val_loss: 0.2230\n",
      "Epoch 200/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2916 - val_accuracy: 0.9303 - val_loss: 0.2362\n",
      "Epoch 201/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9047 - loss: 0.2949 - val_accuracy: 0.9371 - val_loss: 0.2200\n",
      "Epoch 202/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.2883 - val_accuracy: 0.9347 - val_loss: 0.2342\n",
      "Epoch 203/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2909 - val_accuracy: 0.9369 - val_loss: 0.2231\n",
      "Epoch 204/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2956 - val_accuracy: 0.9319 - val_loss: 0.2346\n",
      "Epoch 205/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.3013 - val_accuracy: 0.9345 - val_loss: 0.2259\n",
      "Epoch 206/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9054 - loss: 0.2884 - val_accuracy: 0.9319 - val_loss: 0.2287\n",
      "Epoch 207/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2982 - val_accuracy: 0.9359 - val_loss: 0.2242\n",
      "Epoch 208/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.3042 - val_accuracy: 0.9339 - val_loss: 0.2293\n",
      "Epoch 209/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3034 - val_accuracy: 0.9367 - val_loss: 0.2178\n",
      "Epoch 210/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2935 - val_accuracy: 0.9347 - val_loss: 0.2222\n",
      "Epoch 211/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2894 - val_accuracy: 0.9321 - val_loss: 0.2315\n",
      "Epoch 212/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.3020 - val_accuracy: 0.9389 - val_loss: 0.2187\n",
      "Epoch 213/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9002 - loss: 0.3118 - val_accuracy: 0.9359 - val_loss: 0.2207\n",
      "Epoch 214/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.2957 - val_accuracy: 0.9373 - val_loss: 0.2239\n",
      "Epoch 215/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2935 - val_accuracy: 0.9377 - val_loss: 0.2189\n",
      "Epoch 216/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.2957 - val_accuracy: 0.9379 - val_loss: 0.2221\n",
      "Epoch 217/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2927 - val_accuracy: 0.9327 - val_loss: 0.2308\n",
      "Epoch 218/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9038 - loss: 0.2937 - val_accuracy: 0.9331 - val_loss: 0.2312\n",
      "Epoch 219/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.2994 - val_accuracy: 0.9391 - val_loss: 0.2126\n",
      "Epoch 220/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.3094 - val_accuracy: 0.9385 - val_loss: 0.2170\n",
      "Epoch 221/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2859 - val_accuracy: 0.9379 - val_loss: 0.2199\n",
      "Epoch 222/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2944 - val_accuracy: 0.9277 - val_loss: 0.2441\n",
      "Epoch 223/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9064 - loss: 0.2923 - val_accuracy: 0.9365 - val_loss: 0.2236\n",
      "Epoch 224/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2858 - val_accuracy: 0.9349 - val_loss: 0.2156\n",
      "Epoch 225/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2894 - val_accuracy: 0.9413 - val_loss: 0.2103\n",
      "Epoch 226/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.2915 - val_accuracy: 0.9375 - val_loss: 0.2148\n",
      "Epoch 227/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9054 - loss: 0.2909 - val_accuracy: 0.9353 - val_loss: 0.2283\n",
      "Epoch 228/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2907 - val_accuracy: 0.9281 - val_loss: 0.2473\n",
      "Epoch 229/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2957 - val_accuracy: 0.9389 - val_loss: 0.2211\n",
      "Epoch 230/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2962 - val_accuracy: 0.9345 - val_loss: 0.2276\n",
      "Epoch 231/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.2903 - val_accuracy: 0.9389 - val_loss: 0.2157\n",
      "Epoch 232/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2930 - val_accuracy: 0.9363 - val_loss: 0.2215\n",
      "Epoch 233/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2918 - val_accuracy: 0.9379 - val_loss: 0.2230\n",
      "Epoch 234/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2880 - val_accuracy: 0.9401 - val_loss: 0.2196\n",
      "Epoch 235/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2939 - val_accuracy: 0.9337 - val_loss: 0.2214\n",
      "Epoch 236/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2867 - val_accuracy: 0.9371 - val_loss: 0.2222\n",
      "Epoch 237/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2915 - val_accuracy: 0.9395 - val_loss: 0.2057\n",
      "Epoch 238/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9065 - loss: 0.2919 - val_accuracy: 0.9381 - val_loss: 0.2183\n",
      "Epoch 239/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2985 - val_accuracy: 0.9377 - val_loss: 0.2150\n",
      "Epoch 240/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.2909 - val_accuracy: 0.9399 - val_loss: 0.2155\n",
      "Epoch 241/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.2958 - val_accuracy: 0.9359 - val_loss: 0.2186\n",
      "Epoch 242/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9054 - loss: 0.2972 - val_accuracy: 0.9375 - val_loss: 0.2201\n",
      "Epoch 243/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3010 - val_accuracy: 0.9355 - val_loss: 0.2144\n",
      "Epoch 244/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2927 - val_accuracy: 0.9351 - val_loss: 0.2227\n",
      "Epoch 245/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2933 - val_accuracy: 0.9387 - val_loss: 0.2181\n",
      "Epoch 246/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2795 - val_accuracy: 0.9363 - val_loss: 0.2148\n",
      "Epoch 247/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3011 - val_accuracy: 0.9395 - val_loss: 0.2182\n",
      "Epoch 248/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2923 - val_accuracy: 0.9359 - val_loss: 0.2244\n",
      "Epoch 249/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2862 - val_accuracy: 0.9383 - val_loss: 0.2118\n",
      "Epoch 250/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2865 - val_accuracy: 0.9393 - val_loss: 0.2163\n",
      "Epoch 251/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.2930 - val_accuracy: 0.9367 - val_loss: 0.2182\n",
      "Epoch 252/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.3053 - val_accuracy: 0.9359 - val_loss: 0.2179\n",
      "Epoch 253/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.3123 - val_accuracy: 0.9337 - val_loss: 0.2309\n",
      "Epoch 254/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9066 - loss: 0.2974 - val_accuracy: 0.9377 - val_loss: 0.2162\n",
      "Epoch 255/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2779 - val_accuracy: 0.9381 - val_loss: 0.2162\n",
      "Epoch 256/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2887 - val_accuracy: 0.9353 - val_loss: 0.2204\n",
      "Epoch 257/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2905 - val_accuracy: 0.9353 - val_loss: 0.2275\n",
      "Epoch 258/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9068 - loss: 0.2939 - val_accuracy: 0.9383 - val_loss: 0.2118\n",
      "Epoch 259/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2796 - val_accuracy: 0.9397 - val_loss: 0.2153\n",
      "Epoch 260/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2886 - val_accuracy: 0.9409 - val_loss: 0.2216\n",
      "Epoch 261/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2822 - val_accuracy: 0.9389 - val_loss: 0.2243\n",
      "Epoch 262/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2782 - val_accuracy: 0.9391 - val_loss: 0.2224\n",
      "Epoch 263/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2808 - val_accuracy: 0.9371 - val_loss: 0.2222\n",
      "Epoch 264/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.2849 - val_accuracy: 0.9359 - val_loss: 0.2199\n",
      "Epoch 265/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2914 - val_accuracy: 0.9371 - val_loss: 0.2173\n",
      "Epoch 266/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2797 - val_accuracy: 0.9385 - val_loss: 0.2169\n",
      "Epoch 267/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2820 - val_accuracy: 0.9359 - val_loss: 0.2196\n",
      "Epoch 268/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2843 - val_accuracy: 0.9391 - val_loss: 0.2165\n",
      "Epoch 269/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2816 - val_accuracy: 0.9367 - val_loss: 0.2217\n",
      "Epoch 270/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2818 - val_accuracy: 0.9393 - val_loss: 0.2138\n",
      "Epoch 271/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2928 - val_accuracy: 0.9409 - val_loss: 0.2131\n",
      "Epoch 272/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2800 - val_accuracy: 0.9399 - val_loss: 0.2146\n",
      "Epoch 273/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2814 - val_accuracy: 0.9429 - val_loss: 0.2142\n",
      "Epoch 274/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2794 - val_accuracy: 0.9421 - val_loss: 0.2116\n",
      "Epoch 275/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2818 - val_accuracy: 0.9375 - val_loss: 0.2169\n",
      "Epoch 276/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2768 - val_accuracy: 0.9413 - val_loss: 0.2173\n",
      "Epoch 277/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2681 - val_accuracy: 0.9395 - val_loss: 0.2173\n",
      "Epoch 278/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2785 - val_accuracy: 0.9363 - val_loss: 0.2266\n",
      "Epoch 279/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2795 - val_accuracy: 0.9413 - val_loss: 0.2096\n",
      "Epoch 280/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2825 - val_accuracy: 0.9411 - val_loss: 0.2058\n",
      "Epoch 281/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2763 - val_accuracy: 0.9395 - val_loss: 0.2168\n",
      "Epoch 282/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.2865 - val_accuracy: 0.9389 - val_loss: 0.2091\n",
      "Epoch 283/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2739 - val_accuracy: 0.9417 - val_loss: 0.2091\n",
      "Epoch 284/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2801 - val_accuracy: 0.9401 - val_loss: 0.2187\n",
      "Epoch 285/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2763 - val_accuracy: 0.9369 - val_loss: 0.2154\n",
      "Epoch 286/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2749 - val_accuracy: 0.9383 - val_loss: 0.2168\n",
      "Epoch 287/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.2802 - val_accuracy: 0.9399 - val_loss: 0.2247\n",
      "Epoch 288/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2898 - val_accuracy: 0.9419 - val_loss: 0.2089\n",
      "Epoch 289/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2698 - val_accuracy: 0.9413 - val_loss: 0.2128\n",
      "Epoch 290/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2738 - val_accuracy: 0.9407 - val_loss: 0.2112\n",
      "Epoch 291/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2780 - val_accuracy: 0.9365 - val_loss: 0.2191\n",
      "Epoch 292/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2691 - val_accuracy: 0.9373 - val_loss: 0.2239\n",
      "Epoch 293/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2741 - val_accuracy: 0.9373 - val_loss: 0.2195\n",
      "Epoch 294/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2804 - val_accuracy: 0.9389 - val_loss: 0.2186\n",
      "Epoch 295/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2796 - val_accuracy: 0.9365 - val_loss: 0.2234\n",
      "Epoch 296/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2732 - val_accuracy: 0.9365 - val_loss: 0.2212\n",
      "Epoch 297/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2768 - val_accuracy: 0.9407 - val_loss: 0.2079\n",
      "Epoch 298/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2696 - val_accuracy: 0.9409 - val_loss: 0.2144\n",
      "Epoch 299/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2668 - val_accuracy: 0.9421 - val_loss: 0.2042\n",
      "Epoch 300/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2822 - val_accuracy: 0.9411 - val_loss: 0.2112\n",
      "Epoch 301/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2775 - val_accuracy: 0.9401 - val_loss: 0.2125\n",
      "Epoch 302/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2705 - val_accuracy: 0.9405 - val_loss: 0.2140\n",
      "Epoch 303/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2844 - val_accuracy: 0.9361 - val_loss: 0.2238\n",
      "Epoch 304/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2733 - val_accuracy: 0.9399 - val_loss: 0.2169\n",
      "Epoch 305/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2714 - val_accuracy: 0.9405 - val_loss: 0.2171\n",
      "Epoch 306/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2891 - val_accuracy: 0.9399 - val_loss: 0.2153\n",
      "Epoch 307/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2708 - val_accuracy: 0.9379 - val_loss: 0.2219\n",
      "Epoch 308/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2691 - val_accuracy: 0.9391 - val_loss: 0.2220\n",
      "Epoch 309/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2798 - val_accuracy: 0.9413 - val_loss: 0.2153\n",
      "Epoch 310/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2769 - val_accuracy: 0.9381 - val_loss: 0.2247\n",
      "Epoch 311/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2790 - val_accuracy: 0.9383 - val_loss: 0.2186\n",
      "Epoch 312/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2696 - val_accuracy: 0.9401 - val_loss: 0.2138\n",
      "Epoch 313/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2736 - val_accuracy: 0.9415 - val_loss: 0.2148\n",
      "Epoch 314/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2687 - val_accuracy: 0.9393 - val_loss: 0.2181\n",
      "Epoch 315/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2695 - val_accuracy: 0.9405 - val_loss: 0.2088\n",
      "Epoch 316/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2774 - val_accuracy: 0.9387 - val_loss: 0.2222\n",
      "Epoch 317/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2893 - val_accuracy: 0.9373 - val_loss: 0.2232\n",
      "Epoch 318/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2676 - val_accuracy: 0.9351 - val_loss: 0.2149\n",
      "Epoch 319/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2696 - val_accuracy: 0.9403 - val_loss: 0.2136\n",
      "Epoch 320/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2657 - val_accuracy: 0.9411 - val_loss: 0.2102\n",
      "Epoch 321/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2621 - val_accuracy: 0.9389 - val_loss: 0.2021\n",
      "Epoch 322/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2787 - val_accuracy: 0.9391 - val_loss: 0.2167\n",
      "Epoch 323/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2659 - val_accuracy: 0.9389 - val_loss: 0.2154\n",
      "Epoch 324/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2814 - val_accuracy: 0.9343 - val_loss: 0.2281\n",
      "Epoch 325/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2570 - val_accuracy: 0.9403 - val_loss: 0.2100\n",
      "Epoch 326/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2785 - val_accuracy: 0.9375 - val_loss: 0.2127\n",
      "Epoch 327/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2725 - val_accuracy: 0.9355 - val_loss: 0.2224\n",
      "Epoch 328/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2657 - val_accuracy: 0.9407 - val_loss: 0.2115\n",
      "Epoch 329/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2762 - val_accuracy: 0.9349 - val_loss: 0.2263\n",
      "Epoch 330/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2675 - val_accuracy: 0.9393 - val_loss: 0.2096\n",
      "Epoch 331/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2713 - val_accuracy: 0.9409 - val_loss: 0.2082\n",
      "Epoch 332/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2671 - val_accuracy: 0.9411 - val_loss: 0.2070\n",
      "Epoch 333/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2697 - val_accuracy: 0.9393 - val_loss: 0.2102\n",
      "Epoch 334/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2707 - val_accuracy: 0.9439 - val_loss: 0.2033\n",
      "Epoch 335/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2653 - val_accuracy: 0.9409 - val_loss: 0.2132\n",
      "Epoch 336/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2697 - val_accuracy: 0.9399 - val_loss: 0.2091\n",
      "Epoch 337/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2734 - val_accuracy: 0.9389 - val_loss: 0.2110\n",
      "Epoch 338/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2612 - val_accuracy: 0.9437 - val_loss: 0.2137\n",
      "Epoch 339/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2809 - val_accuracy: 0.9389 - val_loss: 0.2127\n",
      "Epoch 340/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2647 - val_accuracy: 0.9391 - val_loss: 0.2155\n",
      "Epoch 341/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2570 - val_accuracy: 0.9405 - val_loss: 0.2157\n",
      "Epoch 342/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2602 - val_accuracy: 0.9399 - val_loss: 0.2096\n",
      "Epoch 343/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2648 - val_accuracy: 0.9403 - val_loss: 0.2097\n",
      "Epoch 344/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2639 - val_accuracy: 0.9365 - val_loss: 0.2168\n",
      "Epoch 345/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2758 - val_accuracy: 0.9387 - val_loss: 0.2123\n",
      "Epoch 346/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2650 - val_accuracy: 0.9367 - val_loss: 0.2175\n",
      "Epoch 347/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2662 - val_accuracy: 0.9407 - val_loss: 0.2086\n",
      "Epoch 348/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2710 - val_accuracy: 0.9385 - val_loss: 0.2075\n",
      "Epoch 349/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2717 - val_accuracy: 0.9395 - val_loss: 0.2153\n",
      "Epoch 350/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2605 - val_accuracy: 0.9413 - val_loss: 0.2070\n",
      "Epoch 351/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2673 - val_accuracy: 0.9371 - val_loss: 0.2145\n",
      "Epoch 352/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2704 - val_accuracy: 0.9417 - val_loss: 0.2131\n",
      "Epoch 353/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2644 - val_accuracy: 0.9363 - val_loss: 0.2170\n",
      "Epoch 354/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2731 - val_accuracy: 0.9375 - val_loss: 0.2237\n",
      "Epoch 355/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2692 - val_accuracy: 0.9415 - val_loss: 0.2047\n",
      "Epoch 356/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2673 - val_accuracy: 0.9391 - val_loss: 0.2083\n",
      "Epoch 357/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2594 - val_accuracy: 0.9345 - val_loss: 0.2188\n",
      "Epoch 358/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2715 - val_accuracy: 0.9391 - val_loss: 0.2177\n",
      "Epoch 359/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2648 - val_accuracy: 0.9385 - val_loss: 0.2177\n",
      "Epoch 360/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2704 - val_accuracy: 0.9409 - val_loss: 0.2103\n",
      "Epoch 361/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2629 - val_accuracy: 0.9357 - val_loss: 0.2149\n",
      "Epoch 362/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2692 - val_accuracy: 0.9431 - val_loss: 0.2050\n",
      "Epoch 363/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2573 - val_accuracy: 0.9445 - val_loss: 0.2046\n",
      "Epoch 364/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2513 - val_accuracy: 0.9431 - val_loss: 0.2097\n",
      "Epoch 365/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2696 - val_accuracy: 0.9429 - val_loss: 0.2072\n",
      "Epoch 366/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2637 - val_accuracy: 0.9423 - val_loss: 0.2133\n",
      "Epoch 367/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2566 - val_accuracy: 0.9431 - val_loss: 0.2053\n",
      "Epoch 368/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2572 - val_accuracy: 0.9393 - val_loss: 0.2082\n",
      "Epoch 369/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2610 - val_accuracy: 0.9347 - val_loss: 0.2219\n",
      "Epoch 370/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2602 - val_accuracy: 0.9427 - val_loss: 0.1992\n",
      "Epoch 371/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2663 - val_accuracy: 0.9411 - val_loss: 0.2038\n",
      "Epoch 372/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2655 - val_accuracy: 0.9421 - val_loss: 0.2081\n",
      "Epoch 373/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2608 - val_accuracy: 0.9411 - val_loss: 0.2082\n",
      "Epoch 374/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2642 - val_accuracy: 0.9405 - val_loss: 0.2136\n",
      "Epoch 375/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2647 - val_accuracy: 0.9409 - val_loss: 0.2107\n",
      "Epoch 376/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2596 - val_accuracy: 0.9393 - val_loss: 0.2108\n",
      "Epoch 377/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2638 - val_accuracy: 0.9437 - val_loss: 0.2053\n",
      "Epoch 378/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2648 - val_accuracy: 0.9371 - val_loss: 0.2129\n",
      "Epoch 379/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2563 - val_accuracy: 0.9457 - val_loss: 0.2004\n",
      "Epoch 380/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2614 - val_accuracy: 0.9389 - val_loss: 0.2082\n",
      "Epoch 381/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2732 - val_accuracy: 0.9413 - val_loss: 0.2044\n",
      "Epoch 382/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2671 - val_accuracy: 0.9383 - val_loss: 0.2080\n",
      "Epoch 383/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2594 - val_accuracy: 0.9415 - val_loss: 0.2047\n",
      "Epoch 384/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2493 - val_accuracy: 0.9401 - val_loss: 0.2076\n",
      "Epoch 385/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2572 - val_accuracy: 0.9353 - val_loss: 0.2238\n",
      "Epoch 386/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2518 - val_accuracy: 0.9407 - val_loss: 0.2075\n",
      "Epoch 387/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2610 - val_accuracy: 0.9437 - val_loss: 0.2082\n",
      "Epoch 388/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2522 - val_accuracy: 0.9437 - val_loss: 0.2062\n",
      "Epoch 389/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2543 - val_accuracy: 0.9435 - val_loss: 0.2060\n",
      "Epoch 390/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2571 - val_accuracy: 0.9369 - val_loss: 0.2144\n",
      "Epoch 391/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2637 - val_accuracy: 0.9405 - val_loss: 0.2178\n",
      "Epoch 392/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2635 - val_accuracy: 0.9393 - val_loss: 0.2136\n",
      "Epoch 393/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9179 - loss: 0.2602 - val_accuracy: 0.9381 - val_loss: 0.2188\n",
      "Epoch 394/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2565 - val_accuracy: 0.9421 - val_loss: 0.2039\n",
      "Epoch 395/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2632 - val_accuracy: 0.9441 - val_loss: 0.2011\n",
      "Epoch 396/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2608 - val_accuracy: 0.9417 - val_loss: 0.2059\n",
      "Epoch 397/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2657 - val_accuracy: 0.9397 - val_loss: 0.2124\n",
      "Epoch 398/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2505 - val_accuracy: 0.9445 - val_loss: 0.2101\n",
      "Epoch 399/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2691 - val_accuracy: 0.9441 - val_loss: 0.2006\n",
      "Epoch 400/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2470 - val_accuracy: 0.9417 - val_loss: 0.2039\n",
      "Epoch 401/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2528 - val_accuracy: 0.9409 - val_loss: 0.2103\n",
      "Epoch 402/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2583 - val_accuracy: 0.9429 - val_loss: 0.2025\n",
      "Epoch 403/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2482 - val_accuracy: 0.9423 - val_loss: 0.2072\n",
      "Epoch 404/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2688 - val_accuracy: 0.9399 - val_loss: 0.1989\n",
      "Epoch 405/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9179 - loss: 0.2642 - val_accuracy: 0.9413 - val_loss: 0.2065\n",
      "Epoch 406/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2529 - val_accuracy: 0.9383 - val_loss: 0.2087\n",
      "Epoch 407/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2619 - val_accuracy: 0.9427 - val_loss: 0.2048\n",
      "Epoch 408/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2539 - val_accuracy: 0.9427 - val_loss: 0.2007\n",
      "Epoch 409/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2633 - val_accuracy: 0.9435 - val_loss: 0.2063\n",
      "Epoch 410/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2619 - val_accuracy: 0.9425 - val_loss: 0.2051\n",
      "Epoch 411/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2566 - val_accuracy: 0.9423 - val_loss: 0.2059\n",
      "Epoch 412/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2468 - val_accuracy: 0.9411 - val_loss: 0.2036\n",
      "Epoch 413/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2605 - val_accuracy: 0.9427 - val_loss: 0.2049\n",
      "Epoch 414/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2608 - val_accuracy: 0.9383 - val_loss: 0.2109\n",
      "Epoch 415/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2553 - val_accuracy: 0.9387 - val_loss: 0.2025\n",
      "Epoch 416/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2490 - val_accuracy: 0.9401 - val_loss: 0.2099\n",
      "Epoch 417/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2593 - val_accuracy: 0.9421 - val_loss: 0.2035\n",
      "Epoch 418/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2632 - val_accuracy: 0.9427 - val_loss: 0.2037\n",
      "Epoch 419/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2584 - val_accuracy: 0.9423 - val_loss: 0.2071\n",
      "Epoch 420/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9180 - loss: 0.2581 - val_accuracy: 0.9405 - val_loss: 0.2075\n",
      "Epoch 421/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2448 - val_accuracy: 0.9415 - val_loss: 0.2028\n",
      "Epoch 422/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2517 - val_accuracy: 0.9407 - val_loss: 0.2078\n",
      "Epoch 423/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2600 - val_accuracy: 0.9391 - val_loss: 0.2056\n",
      "Epoch 424/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2546 - val_accuracy: 0.9427 - val_loss: 0.2035\n",
      "Epoch 425/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2605 - val_accuracy: 0.9417 - val_loss: 0.2095\n",
      "Epoch 426/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2566 - val_accuracy: 0.9433 - val_loss: 0.2071\n",
      "Epoch 427/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2500 - val_accuracy: 0.9449 - val_loss: 0.2029\n",
      "Epoch 428/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2539 - val_accuracy: 0.9401 - val_loss: 0.2006\n",
      "Epoch 429/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2545 - val_accuracy: 0.9431 - val_loss: 0.2041\n",
      "Epoch 430/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2563 - val_accuracy: 0.9413 - val_loss: 0.2047\n",
      "Epoch 431/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2542 - val_accuracy: 0.9445 - val_loss: 0.1995\n",
      "Epoch 432/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2616 - val_accuracy: 0.9421 - val_loss: 0.2102\n",
      "Epoch 433/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2573 - val_accuracy: 0.9427 - val_loss: 0.2068\n",
      "Epoch 434/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2499 - val_accuracy: 0.9443 - val_loss: 0.2030\n",
      "Epoch 435/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2558 - val_accuracy: 0.9447 - val_loss: 0.1994\n",
      "Epoch 436/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2373 - val_accuracy: 0.9413 - val_loss: 0.2054\n",
      "Epoch 437/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9223 - loss: 0.2474 - val_accuracy: 0.9431 - val_loss: 0.2050\n",
      "Epoch 438/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2483 - val_accuracy: 0.9419 - val_loss: 0.1987\n",
      "Epoch 439/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2487 - val_accuracy: 0.9395 - val_loss: 0.2084\n",
      "Epoch 440/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2509 - val_accuracy: 0.9425 - val_loss: 0.2063\n",
      "Epoch 441/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2558 - val_accuracy: 0.9405 - val_loss: 0.2076\n",
      "Epoch 442/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2518 - val_accuracy: 0.9393 - val_loss: 0.2121\n",
      "Epoch 443/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2556 - val_accuracy: 0.9407 - val_loss: 0.2066\n",
      "Epoch 444/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2460 - val_accuracy: 0.9429 - val_loss: 0.2062\n",
      "Epoch 445/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2455 - val_accuracy: 0.9435 - val_loss: 0.2041\n",
      "Epoch 446/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9189 - loss: 0.2524 - val_accuracy: 0.9427 - val_loss: 0.2027\n",
      "Epoch 447/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2505 - val_accuracy: 0.9425 - val_loss: 0.2069\n",
      "Epoch 448/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2426 - val_accuracy: 0.9415 - val_loss: 0.2026\n",
      "Epoch 449/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2587 - val_accuracy: 0.9419 - val_loss: 0.2023\n",
      "Epoch 450/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2543 - val_accuracy: 0.9421 - val_loss: 0.2038\n",
      "Epoch 451/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2537 - val_accuracy: 0.9435 - val_loss: 0.2038\n",
      "Epoch 452/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2434 - val_accuracy: 0.9411 - val_loss: 0.2050\n",
      "Epoch 453/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2584 - val_accuracy: 0.9443 - val_loss: 0.1994\n",
      "Epoch 454/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2506 - val_accuracy: 0.9435 - val_loss: 0.2081\n",
      "Epoch 455/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2474 - val_accuracy: 0.9427 - val_loss: 0.2034\n",
      "Epoch 456/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2426 - val_accuracy: 0.9413 - val_loss: 0.2055\n",
      "Epoch 457/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2579 - val_accuracy: 0.9455 - val_loss: 0.1953\n",
      "Epoch 458/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2447 - val_accuracy: 0.9441 - val_loss: 0.1992\n",
      "Epoch 459/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9210 - loss: 0.2491 - val_accuracy: 0.9421 - val_loss: 0.2056\n",
      "Epoch 460/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2640 - val_accuracy: 0.9405 - val_loss: 0.2009\n",
      "Epoch 461/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2531 - val_accuracy: 0.9419 - val_loss: 0.2091\n",
      "Epoch 462/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2361 - val_accuracy: 0.9439 - val_loss: 0.2049\n",
      "Epoch 463/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2610 - val_accuracy: 0.9409 - val_loss: 0.1996\n",
      "Epoch 464/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.2380 - val_accuracy: 0.9431 - val_loss: 0.2027\n",
      "Epoch 465/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2500 - val_accuracy: 0.9433 - val_loss: 0.1998\n",
      "Epoch 466/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2472 - val_accuracy: 0.9441 - val_loss: 0.2019\n",
      "Epoch 467/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9212 - loss: 0.2505 - val_accuracy: 0.9455 - val_loss: 0.2033\n",
      "Epoch 468/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2444 - val_accuracy: 0.9439 - val_loss: 0.1986\n",
      "Epoch 469/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2433 - val_accuracy: 0.9447 - val_loss: 0.1963\n",
      "Epoch 470/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2481 - val_accuracy: 0.9433 - val_loss: 0.1966\n",
      "Epoch 471/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2548 - val_accuracy: 0.9421 - val_loss: 0.2034\n",
      "Epoch 472/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2551 - val_accuracy: 0.9405 - val_loss: 0.2024\n",
      "Epoch 473/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2484 - val_accuracy: 0.9395 - val_loss: 0.2007\n",
      "Epoch 474/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2483 - val_accuracy: 0.9407 - val_loss: 0.2073\n",
      "Epoch 475/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2613 - val_accuracy: 0.9407 - val_loss: 0.2115\n",
      "Epoch 476/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2440 - val_accuracy: 0.9449 - val_loss: 0.2007\n",
      "Epoch 477/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2476 - val_accuracy: 0.9455 - val_loss: 0.2021\n",
      "Epoch 478/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2381 - val_accuracy: 0.9455 - val_loss: 0.1970\n",
      "Epoch 479/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2472 - val_accuracy: 0.9423 - val_loss: 0.2050\n",
      "Epoch 480/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2573 - val_accuracy: 0.9411 - val_loss: 0.2037\n",
      "Epoch 481/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2467 - val_accuracy: 0.9397 - val_loss: 0.2034\n",
      "Epoch 482/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2399 - val_accuracy: 0.9417 - val_loss: 0.2099\n",
      "Epoch 483/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2472 - val_accuracy: 0.9437 - val_loss: 0.1985\n",
      "Epoch 484/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2477 - val_accuracy: 0.9433 - val_loss: 0.2039\n",
      "Epoch 485/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2388 - val_accuracy: 0.9409 - val_loss: 0.2017\n",
      "Epoch 486/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2422 - val_accuracy: 0.9423 - val_loss: 0.1956\n",
      "Epoch 487/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2533 - val_accuracy: 0.9437 - val_loss: 0.2028\n",
      "Epoch 488/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2404 - val_accuracy: 0.9403 - val_loss: 0.2111\n",
      "Epoch 489/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2520 - val_accuracy: 0.9439 - val_loss: 0.2003\n",
      "Epoch 490/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2446 - val_accuracy: 0.9417 - val_loss: 0.2136\n",
      "Epoch 491/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2490 - val_accuracy: 0.9465 - val_loss: 0.2021\n",
      "Epoch 492/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2553 - val_accuracy: 0.9423 - val_loss: 0.2061\n",
      "Epoch 493/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2444 - val_accuracy: 0.9439 - val_loss: 0.1981\n",
      "Epoch 494/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2428 - val_accuracy: 0.9423 - val_loss: 0.2070\n",
      "Epoch 495/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.2391 - val_accuracy: 0.9447 - val_loss: 0.2055\n",
      "Epoch 496/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2343 - val_accuracy: 0.9463 - val_loss: 0.1976\n",
      "Epoch 497/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2565 - val_accuracy: 0.9453 - val_loss: 0.1978\n",
      "Epoch 498/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2464 - val_accuracy: 0.9485 - val_loss: 0.1955\n",
      "Epoch 499/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2472 - val_accuracy: 0.9465 - val_loss: 0.2011\n",
      "Epoch 500/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2508 - val_accuracy: 0.9449 - val_loss: 0.2050\n",
      "Epoch 501/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2466 - val_accuracy: 0.9411 - val_loss: 0.2088\n",
      "Epoch 502/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9199 - loss: 0.2493 - val_accuracy: 0.9433 - val_loss: 0.2021\n",
      "Epoch 503/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2557 - val_accuracy: 0.9449 - val_loss: 0.2010\n",
      "Epoch 504/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2526 - val_accuracy: 0.9437 - val_loss: 0.1961\n",
      "Epoch 505/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2414 - val_accuracy: 0.9385 - val_loss: 0.2095\n",
      "Epoch 506/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9212 - loss: 0.2467 - val_accuracy: 0.9397 - val_loss: 0.2071\n",
      "Epoch 507/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2515 - val_accuracy: 0.9441 - val_loss: 0.1939\n",
      "Epoch 508/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2465 - val_accuracy: 0.9411 - val_loss: 0.2013\n",
      "Epoch 509/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2362 - val_accuracy: 0.9413 - val_loss: 0.2023\n",
      "Epoch 510/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2429 - val_accuracy: 0.9419 - val_loss: 0.2004\n",
      "Epoch 511/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2381 - val_accuracy: 0.9475 - val_loss: 0.1925\n",
      "Epoch 512/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2562 - val_accuracy: 0.9457 - val_loss: 0.1959\n",
      "Epoch 513/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2483 - val_accuracy: 0.9467 - val_loss: 0.1977\n",
      "Epoch 514/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2513 - val_accuracy: 0.9439 - val_loss: 0.1980\n",
      "Epoch 515/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2402 - val_accuracy: 0.9459 - val_loss: 0.1958\n",
      "Epoch 516/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2439 - val_accuracy: 0.9449 - val_loss: 0.1967\n",
      "Epoch 517/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2426 - val_accuracy: 0.9411 - val_loss: 0.2028\n",
      "Epoch 518/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2477 - val_accuracy: 0.9425 - val_loss: 0.1991\n",
      "Epoch 519/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2485 - val_accuracy: 0.9405 - val_loss: 0.2026\n",
      "Epoch 520/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2508 - val_accuracy: 0.9401 - val_loss: 0.2085\n",
      "Epoch 521/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2385 - val_accuracy: 0.9415 - val_loss: 0.2109\n",
      "Epoch 522/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2443 - val_accuracy: 0.9407 - val_loss: 0.2103\n",
      "Epoch 523/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2366 - val_accuracy: 0.9461 - val_loss: 0.1919\n",
      "Epoch 524/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2598 - val_accuracy: 0.9427 - val_loss: 0.1954\n",
      "Epoch 525/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2569 - val_accuracy: 0.9459 - val_loss: 0.2053\n",
      "Epoch 526/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2381 - val_accuracy: 0.9437 - val_loss: 0.2010\n",
      "Epoch 527/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2374 - val_accuracy: 0.9453 - val_loss: 0.1988\n",
      "Epoch 528/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2507 - val_accuracy: 0.9445 - val_loss: 0.1983\n",
      "Epoch 529/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2442 - val_accuracy: 0.9471 - val_loss: 0.1981\n",
      "Epoch 530/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9213 - loss: 0.2493 - val_accuracy: 0.9425 - val_loss: 0.1958\n",
      "Epoch 531/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2428 - val_accuracy: 0.9401 - val_loss: 0.2086\n",
      "Epoch 532/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2424 - val_accuracy: 0.9467 - val_loss: 0.1965\n",
      "Epoch 533/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2443 - val_accuracy: 0.9437 - val_loss: 0.1973\n",
      "Epoch 534/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.2419 - val_accuracy: 0.9439 - val_loss: 0.2018\n",
      "Epoch 535/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2430 - val_accuracy: 0.9429 - val_loss: 0.1989\n",
      "Epoch 536/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9209 - loss: 0.2414 - val_accuracy: 0.9439 - val_loss: 0.2044\n",
      "Epoch 537/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9219 - loss: 0.2400 - val_accuracy: 0.9445 - val_loss: 0.2018\n",
      "Epoch 538/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2471 - val_accuracy: 0.9451 - val_loss: 0.1991\n",
      "Epoch 539/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9216 - loss: 0.2424 - val_accuracy: 0.9427 - val_loss: 0.2081\n",
      "Epoch 540/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2431 - val_accuracy: 0.9457 - val_loss: 0.1942\n",
      "Epoch 541/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2416 - val_accuracy: 0.9443 - val_loss: 0.1986\n",
      "Epoch 542/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2428 - val_accuracy: 0.9477 - val_loss: 0.1973\n",
      "Epoch 543/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2392 - val_accuracy: 0.9423 - val_loss: 0.2023\n",
      "Epoch 544/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2313 - val_accuracy: 0.9453 - val_loss: 0.1989\n",
      "Epoch 545/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2346 - val_accuracy: 0.9451 - val_loss: 0.1978\n",
      "Epoch 546/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2442 - val_accuracy: 0.9447 - val_loss: 0.2033\n",
      "Epoch 547/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2455 - val_accuracy: 0.9437 - val_loss: 0.1945\n",
      "Epoch 548/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2379 - val_accuracy: 0.9449 - val_loss: 0.1957\n",
      "Epoch 549/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2396 - val_accuracy: 0.9431 - val_loss: 0.1974\n",
      "Epoch 550/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9207 - loss: 0.2426 - val_accuracy: 0.9451 - val_loss: 0.1961\n",
      "Epoch 551/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2479 - val_accuracy: 0.9431 - val_loss: 0.2055\n",
      "Epoch 552/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.2322 - val_accuracy: 0.9449 - val_loss: 0.2023\n",
      "Epoch 553/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2499 - val_accuracy: 0.9435 - val_loss: 0.1935\n",
      "Epoch 554/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9223 - loss: 0.2449 - val_accuracy: 0.9449 - val_loss: 0.1954\n",
      "Epoch 555/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2326 - val_accuracy: 0.9473 - val_loss: 0.1925\n",
      "Epoch 556/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2413 - val_accuracy: 0.9451 - val_loss: 0.1943\n",
      "Epoch 557/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2444 - val_accuracy: 0.9455 - val_loss: 0.1950\n",
      "Epoch 558/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2333 - val_accuracy: 0.9427 - val_loss: 0.1956\n",
      "Epoch 559/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9179 - loss: 0.2539 - val_accuracy: 0.9431 - val_loss: 0.2006\n",
      "Epoch 560/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2434 - val_accuracy: 0.9393 - val_loss: 0.2126\n",
      "Epoch 561/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2395 - val_accuracy: 0.9405 - val_loss: 0.2029\n",
      "Epoch 562/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2271 - val_accuracy: 0.9429 - val_loss: 0.1931\n",
      "Epoch 563/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2483 - val_accuracy: 0.9405 - val_loss: 0.2020\n",
      "Epoch 564/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2372 - val_accuracy: 0.9447 - val_loss: 0.1969\n",
      "Epoch 565/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2409 - val_accuracy: 0.9433 - val_loss: 0.1975\n",
      "Epoch 566/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.2419 - val_accuracy: 0.9443 - val_loss: 0.1930\n",
      "Epoch 567/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2451 - val_accuracy: 0.9443 - val_loss: 0.1994\n",
      "Epoch 568/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2415 - val_accuracy: 0.9471 - val_loss: 0.1952\n",
      "Epoch 569/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2371 - val_accuracy: 0.9453 - val_loss: 0.1955\n",
      "Epoch 570/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2535 - val_accuracy: 0.9441 - val_loss: 0.1978\n",
      "Epoch 571/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2419 - val_accuracy: 0.9463 - val_loss: 0.1925\n",
      "Epoch 572/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.2333 - val_accuracy: 0.9431 - val_loss: 0.2077\n",
      "Epoch 573/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2432 - val_accuracy: 0.9449 - val_loss: 0.1972\n",
      "Epoch 574/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2411 - val_accuracy: 0.9437 - val_loss: 0.1910\n",
      "Epoch 575/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.2395 - val_accuracy: 0.9425 - val_loss: 0.1981\n",
      "Epoch 576/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2362 - val_accuracy: 0.9447 - val_loss: 0.1911\n",
      "Epoch 577/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.2395 - val_accuracy: 0.9429 - val_loss: 0.1962\n",
      "Epoch 578/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2388 - val_accuracy: 0.9443 - val_loss: 0.2000\n",
      "Epoch 579/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2380 - val_accuracy: 0.9463 - val_loss: 0.1932\n",
      "Epoch 580/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2439 - val_accuracy: 0.9471 - val_loss: 0.1996\n",
      "Epoch 581/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2649 - val_accuracy: 0.9419 - val_loss: 0.2107\n",
      "Epoch 582/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2360 - val_accuracy: 0.9443 - val_loss: 0.1959\n",
      "Epoch 583/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2326 - val_accuracy: 0.9435 - val_loss: 0.2013\n",
      "Epoch 584/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2353 - val_accuracy: 0.9445 - val_loss: 0.1990\n",
      "Epoch 585/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2403 - val_accuracy: 0.9467 - val_loss: 0.1901\n",
      "Epoch 586/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2342 - val_accuracy: 0.9447 - val_loss: 0.1945\n",
      "Epoch 587/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2274 - val_accuracy: 0.9435 - val_loss: 0.1985\n",
      "Epoch 588/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2396 - val_accuracy: 0.9443 - val_loss: 0.1984\n",
      "Epoch 589/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2368 - val_accuracy: 0.9417 - val_loss: 0.1985\n",
      "Epoch 590/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2377 - val_accuracy: 0.9445 - val_loss: 0.1943\n",
      "Epoch 591/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2395 - val_accuracy: 0.9431 - val_loss: 0.2006\n",
      "Epoch 592/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2345 - val_accuracy: 0.9449 - val_loss: 0.1977\n",
      "Epoch 593/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2383 - val_accuracy: 0.9413 - val_loss: 0.2047\n",
      "Epoch 594/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2356 - val_accuracy: 0.9429 - val_loss: 0.1943\n",
      "Epoch 595/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2370 - val_accuracy: 0.9435 - val_loss: 0.2019\n",
      "Epoch 596/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2375 - val_accuracy: 0.9451 - val_loss: 0.1923\n",
      "Epoch 597/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2366 - val_accuracy: 0.9435 - val_loss: 0.1924\n",
      "Epoch 598/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2530 - val_accuracy: 0.9455 - val_loss: 0.1965\n",
      "Epoch 599/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2595 - val_accuracy: 0.9441 - val_loss: 0.1926\n",
      "Epoch 600/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2393 - val_accuracy: 0.9425 - val_loss: 0.1970\n",
      "Epoch 601/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2331 - val_accuracy: 0.9419 - val_loss: 0.2058\n",
      "Epoch 602/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2221 - val_accuracy: 0.9423 - val_loss: 0.1974\n",
      "Epoch 603/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2296 - val_accuracy: 0.9453 - val_loss: 0.1924\n",
      "Epoch 604/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2343 - val_accuracy: 0.9427 - val_loss: 0.1920\n",
      "Epoch 605/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2284 - val_accuracy: 0.9447 - val_loss: 0.1998\n",
      "Epoch 606/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2289 - val_accuracy: 0.9439 - val_loss: 0.1977\n",
      "Epoch 607/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2303 - val_accuracy: 0.9467 - val_loss: 0.1967\n",
      "Epoch 608/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2406 - val_accuracy: 0.9407 - val_loss: 0.2017\n",
      "Epoch 609/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2377 - val_accuracy: 0.9427 - val_loss: 0.2027\n",
      "Epoch 610/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2272 - val_accuracy: 0.9441 - val_loss: 0.1974\n",
      "Epoch 611/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2368 - val_accuracy: 0.9473 - val_loss: 0.2001\n",
      "Epoch 612/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2340 - val_accuracy: 0.9457 - val_loss: 0.1910\n",
      "Epoch 613/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2379 - val_accuracy: 0.9461 - val_loss: 0.1942\n",
      "Epoch 614/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9211 - loss: 0.2483 - val_accuracy: 0.9435 - val_loss: 0.1994\n",
      "Epoch 615/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2394 - val_accuracy: 0.9411 - val_loss: 0.2064\n",
      "Epoch 616/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2388 - val_accuracy: 0.9443 - val_loss: 0.1963\n",
      "Epoch 617/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2369 - val_accuracy: 0.9459 - val_loss: 0.1935\n",
      "Epoch 618/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2325 - val_accuracy: 0.9457 - val_loss: 0.1973\n",
      "Epoch 619/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2329 - val_accuracy: 0.9465 - val_loss: 0.1973\n",
      "Epoch 620/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2348 - val_accuracy: 0.9459 - val_loss: 0.1930\n",
      "Epoch 621/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2310 - val_accuracy: 0.9439 - val_loss: 0.1973\n",
      "Epoch 622/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2307 - val_accuracy: 0.9479 - val_loss: 0.1882\n",
      "Epoch 623/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2341 - val_accuracy: 0.9467 - val_loss: 0.1982\n",
      "Epoch 624/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2334 - val_accuracy: 0.9475 - val_loss: 0.1920\n",
      "Epoch 625/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2225 - val_accuracy: 0.9447 - val_loss: 0.2020\n",
      "Epoch 626/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2394 - val_accuracy: 0.9451 - val_loss: 0.1914\n",
      "Epoch 627/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2246 - val_accuracy: 0.9443 - val_loss: 0.1949\n",
      "Epoch 628/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9186 - loss: 0.2603 - val_accuracy: 0.9437 - val_loss: 0.1961\n",
      "Epoch 629/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2297 - val_accuracy: 0.9477 - val_loss: 0.1927\n",
      "Epoch 630/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2338 - val_accuracy: 0.9457 - val_loss: 0.2023\n",
      "Epoch 631/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2359 - val_accuracy: 0.9437 - val_loss: 0.2022\n",
      "Epoch 632/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2356 - val_accuracy: 0.9467 - val_loss: 0.1925\n",
      "Epoch 633/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2238 - val_accuracy: 0.9461 - val_loss: 0.1963\n",
      "Epoch 634/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2426 - val_accuracy: 0.9461 - val_loss: 0.1991\n",
      "Epoch 635/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2309 - val_accuracy: 0.9455 - val_loss: 0.1966\n",
      "Epoch 636/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2379 - val_accuracy: 0.9471 - val_loss: 0.1904\n",
      "Epoch 637/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2183 - val_accuracy: 0.9467 - val_loss: 0.1914\n",
      "Epoch 638/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2376 - val_accuracy: 0.9403 - val_loss: 0.2141\n",
      "Epoch 639/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2382 - val_accuracy: 0.9441 - val_loss: 0.2031\n",
      "Epoch 640/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2332 - val_accuracy: 0.9461 - val_loss: 0.1992\n",
      "Epoch 641/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2335 - val_accuracy: 0.9439 - val_loss: 0.1998\n",
      "Epoch 642/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.2393 - val_accuracy: 0.9431 - val_loss: 0.1931\n",
      "Epoch 643/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2399 - val_accuracy: 0.9427 - val_loss: 0.1963\n",
      "Epoch 644/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2273 - val_accuracy: 0.9415 - val_loss: 0.1982\n",
      "Epoch 645/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.2289 - val_accuracy: 0.9469 - val_loss: 0.1944\n",
      "Epoch 646/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2299 - val_accuracy: 0.9435 - val_loss: 0.1988\n",
      "Epoch 647/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2423 - val_accuracy: 0.9469 - val_loss: 0.1938\n",
      "Epoch 648/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2203 - val_accuracy: 0.9453 - val_loss: 0.1994\n",
      "Epoch 649/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2357 - val_accuracy: 0.9467 - val_loss: 0.1973\n",
      "Epoch 650/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2351 - val_accuracy: 0.9475 - val_loss: 0.1920\n",
      "Epoch 651/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2339 - val_accuracy: 0.9455 - val_loss: 0.1944\n",
      "Epoch 652/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2355 - val_accuracy: 0.9451 - val_loss: 0.1926\n",
      "Epoch 653/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2290 - val_accuracy: 0.9457 - val_loss: 0.2003\n",
      "Epoch 654/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2404 - val_accuracy: 0.9417 - val_loss: 0.2041\n",
      "Epoch 655/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2356 - val_accuracy: 0.9437 - val_loss: 0.1988\n",
      "Epoch 656/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2284 - val_accuracy: 0.9431 - val_loss: 0.2045\n",
      "Epoch 657/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2333 - val_accuracy: 0.9433 - val_loss: 0.1948\n",
      "Epoch 658/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2339 - val_accuracy: 0.9449 - val_loss: 0.1928\n",
      "Epoch 659/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2237 - val_accuracy: 0.9453 - val_loss: 0.2010\n",
      "Epoch 660/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2302 - val_accuracy: 0.9435 - val_loss: 0.1994\n",
      "Epoch 661/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2322 - val_accuracy: 0.9467 - val_loss: 0.1959\n",
      "Epoch 662/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2309 - val_accuracy: 0.9427 - val_loss: 0.1986\n",
      "Epoch 663/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9240 - loss: 0.2269 - val_accuracy: 0.9445 - val_loss: 0.1991\n",
      "Epoch 664/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2248 - val_accuracy: 0.9451 - val_loss: 0.1995\n",
      "Epoch 665/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.2348 - val_accuracy: 0.9441 - val_loss: 0.1989\n",
      "Epoch 666/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2242 - val_accuracy: 0.9449 - val_loss: 0.1933\n",
      "Epoch 667/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2419 - val_accuracy: 0.9467 - val_loss: 0.1987\n",
      "Epoch 668/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2257 - val_accuracy: 0.9435 - val_loss: 0.1960\n",
      "Epoch 669/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2305 - val_accuracy: 0.9473 - val_loss: 0.1975\n",
      "Epoch 670/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2345 - val_accuracy: 0.9451 - val_loss: 0.1990\n",
      "Epoch 671/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2223 - val_accuracy: 0.9441 - val_loss: 0.1943\n",
      "Epoch 672/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2296 - val_accuracy: 0.9443 - val_loss: 0.2009\n",
      "Epoch 673/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2210 - val_accuracy: 0.9449 - val_loss: 0.2064\n",
      "Epoch 674/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2323 - val_accuracy: 0.9453 - val_loss: 0.1981\n",
      "Epoch 675/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2591 - val_accuracy: 0.9483 - val_loss: 0.1982\n",
      "Epoch 676/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2325 - val_accuracy: 0.9463 - val_loss: 0.1997\n",
      "Epoch 677/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2312 - val_accuracy: 0.9447 - val_loss: 0.1970\n",
      "Epoch 678/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.2382 - val_accuracy: 0.9467 - val_loss: 0.1965\n",
      "Epoch 679/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2223 - val_accuracy: 0.9451 - val_loss: 0.1979\n",
      "Epoch 680/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9205 - loss: 0.2452 - val_accuracy: 0.9465 - val_loss: 0.1911\n",
      "Epoch 681/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.2292 - val_accuracy: 0.9467 - val_loss: 0.1911\n",
      "Epoch 682/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2182 - val_accuracy: 0.9449 - val_loss: 0.1950\n",
      "Epoch 683/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2253 - val_accuracy: 0.9499 - val_loss: 0.1985\n",
      "Epoch 684/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2327 - val_accuracy: 0.9479 - val_loss: 0.1970\n",
      "Epoch 685/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2275 - val_accuracy: 0.9439 - val_loss: 0.2007\n",
      "Epoch 686/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2299 - val_accuracy: 0.9451 - val_loss: 0.2041\n",
      "Epoch 687/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2297 - val_accuracy: 0.9441 - val_loss: 0.1942\n",
      "Epoch 688/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2368 - val_accuracy: 0.9471 - val_loss: 0.1971\n",
      "Epoch 689/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2203 - val_accuracy: 0.9421 - val_loss: 0.2016\n",
      "Epoch 690/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2423 - val_accuracy: 0.9473 - val_loss: 0.1907\n",
      "Epoch 691/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9247 - loss: 0.2343 - val_accuracy: 0.9469 - val_loss: 0.1903\n",
      "Epoch 692/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2302 - val_accuracy: 0.9407 - val_loss: 0.2018\n",
      "Epoch 693/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2251 - val_accuracy: 0.9449 - val_loss: 0.1928\n",
      "Epoch 694/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2440 - val_accuracy: 0.9445 - val_loss: 0.1935\n",
      "Epoch 695/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2366 - val_accuracy: 0.9451 - val_loss: 0.1942\n",
      "Epoch 696/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2273 - val_accuracy: 0.9453 - val_loss: 0.1909\n",
      "Epoch 697/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2230 - val_accuracy: 0.9463 - val_loss: 0.1912\n",
      "Epoch 698/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2270 - val_accuracy: 0.9445 - val_loss: 0.1958\n",
      "Epoch 699/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2208 - val_accuracy: 0.9435 - val_loss: 0.2003\n",
      "Epoch 700/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2263 - val_accuracy: 0.9445 - val_loss: 0.1931\n",
      "Epoch 701/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2177 - val_accuracy: 0.9457 - val_loss: 0.1951\n",
      "Epoch 702/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2341 - val_accuracy: 0.9443 - val_loss: 0.2045\n",
      "Epoch 703/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2300 - val_accuracy: 0.9445 - val_loss: 0.1928\n",
      "Epoch 704/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2231 - val_accuracy: 0.9443 - val_loss: 0.1942\n",
      "Epoch 705/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2344 - val_accuracy: 0.9419 - val_loss: 0.1984\n",
      "Epoch 706/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2278 - val_accuracy: 0.9459 - val_loss: 0.1895\n",
      "Epoch 707/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2262 - val_accuracy: 0.9431 - val_loss: 0.1968\n",
      "Epoch 708/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2244 - val_accuracy: 0.9413 - val_loss: 0.1959\n",
      "Epoch 709/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2444 - val_accuracy: 0.9431 - val_loss: 0.1942\n",
      "Epoch 710/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2259 - val_accuracy: 0.9453 - val_loss: 0.1967\n",
      "Epoch 711/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2347 - val_accuracy: 0.9455 - val_loss: 0.1927\n",
      "Epoch 712/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2343 - val_accuracy: 0.9429 - val_loss: 0.1991\n",
      "Epoch 713/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2302 - val_accuracy: 0.9447 - val_loss: 0.1949\n",
      "Epoch 714/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2309 - val_accuracy: 0.9469 - val_loss: 0.1936\n",
      "Epoch 715/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2214 - val_accuracy: 0.9477 - val_loss: 0.1929\n",
      "Epoch 716/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2160 - val_accuracy: 0.9491 - val_loss: 0.1894\n",
      "Epoch 717/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2292 - val_accuracy: 0.9435 - val_loss: 0.1934\n",
      "Epoch 718/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2431 - val_accuracy: 0.9425 - val_loss: 0.1947\n",
      "Epoch 719/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2262 - val_accuracy: 0.9453 - val_loss: 0.1974\n",
      "Epoch 720/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.2187 - val_accuracy: 0.9457 - val_loss: 0.1915\n",
      "Epoch 721/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2352 - val_accuracy: 0.9489 - val_loss: 0.1929\n",
      "Epoch 722/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2254 - val_accuracy: 0.9435 - val_loss: 0.1987\n",
      "Epoch 723/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2322 - val_accuracy: 0.9473 - val_loss: 0.1948\n",
      "Epoch 724/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2369 - val_accuracy: 0.9453 - val_loss: 0.1947\n",
      "Epoch 725/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2208 - val_accuracy: 0.9417 - val_loss: 0.1991\n",
      "Epoch 726/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2298 - val_accuracy: 0.9423 - val_loss: 0.2011\n",
      "Epoch 727/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2275 - val_accuracy: 0.9433 - val_loss: 0.1994\n",
      "Epoch 728/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2325 - val_accuracy: 0.9423 - val_loss: 0.2021\n",
      "Epoch 729/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2290 - val_accuracy: 0.9441 - val_loss: 0.2062\n",
      "Epoch 730/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.2362 - val_accuracy: 0.9435 - val_loss: 0.1988\n",
      "Epoch 731/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2340 - val_accuracy: 0.9443 - val_loss: 0.2027\n",
      "Epoch 732/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2221 - val_accuracy: 0.9461 - val_loss: 0.1986\n",
      "Epoch 733/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2295 - val_accuracy: 0.9427 - val_loss: 0.1999\n",
      "Epoch 734/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2237 - val_accuracy: 0.9437 - val_loss: 0.1979\n",
      "Epoch 735/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2175 - val_accuracy: 0.9441 - val_loss: 0.1971\n",
      "Epoch 736/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2302 - val_accuracy: 0.9459 - val_loss: 0.1942\n",
      "Epoch 737/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2242 - val_accuracy: 0.9435 - val_loss: 0.2041\n",
      "Epoch 738/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2182 - val_accuracy: 0.9481 - val_loss: 0.1880\n",
      "Epoch 739/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2247 - val_accuracy: 0.9461 - val_loss: 0.1911\n",
      "Epoch 740/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2296 - val_accuracy: 0.9463 - val_loss: 0.1867\n",
      "Epoch 741/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.2246 - val_accuracy: 0.9487 - val_loss: 0.1946\n",
      "Epoch 742/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2294 - val_accuracy: 0.9459 - val_loss: 0.1907\n",
      "Epoch 743/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2221 - val_accuracy: 0.9447 - val_loss: 0.2033\n",
      "Epoch 744/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2335 - val_accuracy: 0.9477 - val_loss: 0.1910\n",
      "Epoch 745/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2267 - val_accuracy: 0.9435 - val_loss: 0.2071\n",
      "Epoch 746/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2275 - val_accuracy: 0.9461 - val_loss: 0.1922\n",
      "Epoch 747/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2361 - val_accuracy: 0.9459 - val_loss: 0.1930\n",
      "Epoch 748/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2237 - val_accuracy: 0.9455 - val_loss: 0.1912\n",
      "Epoch 749/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2344 - val_accuracy: 0.9475 - val_loss: 0.1914\n",
      "Epoch 750/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2166 - val_accuracy: 0.9461 - val_loss: 0.1972\n",
      "Epoch 751/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2274 - val_accuracy: 0.9461 - val_loss: 0.1980\n",
      "Epoch 752/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2226 - val_accuracy: 0.9461 - val_loss: 0.1889\n",
      "Epoch 753/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2278 - val_accuracy: 0.9451 - val_loss: 0.1964\n",
      "Epoch 754/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2261 - val_accuracy: 0.9447 - val_loss: 0.1939\n",
      "Epoch 755/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.2558 - val_accuracy: 0.9441 - val_loss: 0.1965\n",
      "Epoch 756/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2279 - val_accuracy: 0.9461 - val_loss: 0.2003\n",
      "Epoch 757/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2307 - val_accuracy: 0.9453 - val_loss: 0.1968\n",
      "Epoch 758/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2273 - val_accuracy: 0.9463 - val_loss: 0.1963\n",
      "Epoch 759/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2234 - val_accuracy: 0.9453 - val_loss: 0.1992\n",
      "Epoch 760/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2251 - val_accuracy: 0.9443 - val_loss: 0.1967\n",
      "Epoch 761/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2363 - val_accuracy: 0.9445 - val_loss: 0.1972\n",
      "Epoch 762/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2235 - val_accuracy: 0.9455 - val_loss: 0.1944\n",
      "Epoch 763/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2341 - val_accuracy: 0.9443 - val_loss: 0.2082\n",
      "Epoch 764/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2178 - val_accuracy: 0.9467 - val_loss: 0.2009\n",
      "Epoch 765/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2193 - val_accuracy: 0.9451 - val_loss: 0.1992\n",
      "Epoch 766/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2269 - val_accuracy: 0.9435 - val_loss: 0.1986\n",
      "Epoch 767/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2269 - val_accuracy: 0.9455 - val_loss: 0.1991\n",
      "Epoch 768/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2273 - val_accuracy: 0.9453 - val_loss: 0.1954\n",
      "Epoch 769/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2300 - val_accuracy: 0.9481 - val_loss: 0.1910\n",
      "Epoch 770/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2154 - val_accuracy: 0.9463 - val_loss: 0.1984\n",
      "Epoch 771/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2279 - val_accuracy: 0.9441 - val_loss: 0.1928\n",
      "Epoch 772/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2250 - val_accuracy: 0.9457 - val_loss: 0.1978\n",
      "Epoch 773/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2303 - val_accuracy: 0.9465 - val_loss: 0.1951\n",
      "Epoch 774/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2263 - val_accuracy: 0.9473 - val_loss: 0.1935\n",
      "Epoch 775/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.2173 - val_accuracy: 0.9445 - val_loss: 0.1983\n",
      "Epoch 776/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2170 - val_accuracy: 0.9459 - val_loss: 0.1956\n",
      "Epoch 777/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2310 - val_accuracy: 0.9463 - val_loss: 0.1949\n",
      "Epoch 778/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2223 - val_accuracy: 0.9469 - val_loss: 0.1963\n",
      "Epoch 779/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2268 - val_accuracy: 0.9435 - val_loss: 0.1952\n",
      "Epoch 780/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2213 - val_accuracy: 0.9475 - val_loss: 0.1931\n",
      "Epoch 781/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2363 - val_accuracy: 0.9457 - val_loss: 0.1916\n",
      "Epoch 782/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2262 - val_accuracy: 0.9471 - val_loss: 0.1959\n",
      "Epoch 783/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2169 - val_accuracy: 0.9467 - val_loss: 0.1958\n",
      "Epoch 784/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2252 - val_accuracy: 0.9447 - val_loss: 0.2019\n",
      "Epoch 785/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2198 - val_accuracy: 0.9455 - val_loss: 0.1985\n",
      "Epoch 786/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2235 - val_accuracy: 0.9471 - val_loss: 0.1930\n",
      "Epoch 787/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2161 - val_accuracy: 0.9467 - val_loss: 0.1905\n",
      "Epoch 788/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2159 - val_accuracy: 0.9449 - val_loss: 0.1974\n",
      "Epoch 789/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2251 - val_accuracy: 0.9463 - val_loss: 0.1989\n",
      "Epoch 790/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.2146 - val_accuracy: 0.9453 - val_loss: 0.1843\n",
      "Epoch 791/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2255 - val_accuracy: 0.9461 - val_loss: 0.1963\n",
      "Epoch 792/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2227 - val_accuracy: 0.9467 - val_loss: 0.1921\n",
      "Epoch 793/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2395 - val_accuracy: 0.9461 - val_loss: 0.2022\n",
      "Epoch 794/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2289 - val_accuracy: 0.9435 - val_loss: 0.2061\n",
      "Epoch 795/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2237 - val_accuracy: 0.9469 - val_loss: 0.1993\n",
      "Epoch 796/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2333 - val_accuracy: 0.9469 - val_loss: 0.2010\n",
      "Epoch 797/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2237 - val_accuracy: 0.9439 - val_loss: 0.1997\n",
      "Epoch 798/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2248 - val_accuracy: 0.9437 - val_loss: 0.2009\n",
      "Epoch 799/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2170 - val_accuracy: 0.9449 - val_loss: 0.1975\n",
      "Epoch 800/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2346 - val_accuracy: 0.9445 - val_loss: 0.2043\n",
      "Epoch 801/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.2167 - val_accuracy: 0.9459 - val_loss: 0.1975\n",
      "Epoch 802/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2364 - val_accuracy: 0.9443 - val_loss: 0.2023\n",
      "Epoch 803/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.2247 - val_accuracy: 0.9421 - val_loss: 0.2036\n",
      "Epoch 804/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2223 - val_accuracy: 0.9435 - val_loss: 0.2041\n",
      "Epoch 805/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2244 - val_accuracy: 0.9431 - val_loss: 0.1926\n",
      "Epoch 806/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2276 - val_accuracy: 0.9473 - val_loss: 0.1941\n",
      "Epoch 807/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2205 - val_accuracy: 0.9457 - val_loss: 0.1932\n",
      "Epoch 808/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2295 - val_accuracy: 0.9461 - val_loss: 0.2007\n",
      "Epoch 809/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2269 - val_accuracy: 0.9445 - val_loss: 0.1955\n",
      "Epoch 810/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2266 - val_accuracy: 0.9441 - val_loss: 0.1983\n",
      "Epoch 811/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2244 - val_accuracy: 0.9461 - val_loss: 0.1985\n",
      "Epoch 812/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.2175 - val_accuracy: 0.9465 - val_loss: 0.1987\n",
      "Epoch 813/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2146 - val_accuracy: 0.9473 - val_loss: 0.1975\n",
      "Epoch 814/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2193 - val_accuracy: 0.9485 - val_loss: 0.2027\n",
      "Epoch 815/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.2124 - val_accuracy: 0.9447 - val_loss: 0.1985\n",
      "Epoch 816/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2175 - val_accuracy: 0.9479 - val_loss: 0.2014\n",
      "Epoch 817/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2318 - val_accuracy: 0.9497 - val_loss: 0.1950\n",
      "Epoch 818/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2373 - val_accuracy: 0.9407 - val_loss: 0.2106\n",
      "Epoch 819/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2219 - val_accuracy: 0.9491 - val_loss: 0.2036\n",
      "Epoch 820/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2257 - val_accuracy: 0.9467 - val_loss: 0.1984\n",
      "Epoch 821/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2164 - val_accuracy: 0.9473 - val_loss: 0.1953\n",
      "Epoch 822/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2133 - val_accuracy: 0.9463 - val_loss: 0.1954\n",
      "Epoch 823/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2317 - val_accuracy: 0.9479 - val_loss: 0.1996\n",
      "Epoch 824/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2360 - val_accuracy: 0.9489 - val_loss: 0.1880\n",
      "Epoch 825/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2186 - val_accuracy: 0.9483 - val_loss: 0.1892\n",
      "Epoch 826/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2228 - val_accuracy: 0.9453 - val_loss: 0.1965\n",
      "Epoch 827/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2206 - val_accuracy: 0.9459 - val_loss: 0.1914\n",
      "Epoch 828/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2158 - val_accuracy: 0.9451 - val_loss: 0.1898\n",
      "Epoch 829/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9317 - loss: 0.2099 - val_accuracy: 0.9513 - val_loss: 0.1855\n",
      "Epoch 830/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2286 - val_accuracy: 0.9485 - val_loss: 0.1869\n",
      "Epoch 831/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2191 - val_accuracy: 0.9457 - val_loss: 0.1929\n",
      "Epoch 832/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2293 - val_accuracy: 0.9455 - val_loss: 0.1975\n",
      "Epoch 833/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2162 - val_accuracy: 0.9465 - val_loss: 0.1916\n",
      "Epoch 834/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2335 - val_accuracy: 0.9459 - val_loss: 0.1961\n",
      "Epoch 835/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2165 - val_accuracy: 0.9475 - val_loss: 0.1924\n",
      "Epoch 836/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2226 - val_accuracy: 0.9473 - val_loss: 0.1837\n",
      "Epoch 837/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2238 - val_accuracy: 0.9469 - val_loss: 0.1940\n",
      "Epoch 838/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2137 - val_accuracy: 0.9449 - val_loss: 0.1944\n",
      "Epoch 839/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2185 - val_accuracy: 0.9471 - val_loss: 0.1859\n",
      "Epoch 840/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2249 - val_accuracy: 0.9441 - val_loss: 0.2009\n",
      "Epoch 841/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2269 - val_accuracy: 0.9467 - val_loss: 0.1937\n",
      "Epoch 842/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2228 - val_accuracy: 0.9461 - val_loss: 0.1951\n",
      "Epoch 843/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2128 - val_accuracy: 0.9463 - val_loss: 0.1956\n",
      "Epoch 844/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.2305 - val_accuracy: 0.9465 - val_loss: 0.1993\n",
      "Epoch 845/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2233 - val_accuracy: 0.9461 - val_loss: 0.2053\n",
      "Epoch 846/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2203 - val_accuracy: 0.9461 - val_loss: 0.1972\n",
      "Epoch 847/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2205 - val_accuracy: 0.9463 - val_loss: 0.1972\n",
      "Epoch 848/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2167 - val_accuracy: 0.9461 - val_loss: 0.1921\n",
      "Epoch 849/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2155 - val_accuracy: 0.9439 - val_loss: 0.1997\n",
      "Epoch 850/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2207 - val_accuracy: 0.9417 - val_loss: 0.2118\n",
      "Epoch 851/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2300 - val_accuracy: 0.9463 - val_loss: 0.1908\n",
      "Epoch 852/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2099 - val_accuracy: 0.9457 - val_loss: 0.1973\n",
      "Epoch 853/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2239 - val_accuracy: 0.9459 - val_loss: 0.1887\n",
      "Epoch 854/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2177 - val_accuracy: 0.9449 - val_loss: 0.1975\n",
      "Epoch 855/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9327 - loss: 0.2095 - val_accuracy: 0.9485 - val_loss: 0.1941\n",
      "Epoch 856/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2244 - val_accuracy: 0.9489 - val_loss: 0.1960\n",
      "Epoch 857/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2170 - val_accuracy: 0.9487 - val_loss: 0.1927\n",
      "Epoch 858/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.2230 - val_accuracy: 0.9493 - val_loss: 0.1917\n",
      "Epoch 859/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.2102 - val_accuracy: 0.9481 - val_loss: 0.1920\n",
      "Epoch 860/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2136 - val_accuracy: 0.9487 - val_loss: 0.1929\n",
      "Epoch 861/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2292 - val_accuracy: 0.9475 - val_loss: 0.1986\n",
      "Epoch 862/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2162 - val_accuracy: 0.9451 - val_loss: 0.1937\n",
      "Epoch 863/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2235 - val_accuracy: 0.9437 - val_loss: 0.1956\n",
      "Epoch 864/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2266 - val_accuracy: 0.9433 - val_loss: 0.2026\n",
      "Epoch 865/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.2158 - val_accuracy: 0.9455 - val_loss: 0.1955\n",
      "Epoch 866/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2142 - val_accuracy: 0.9455 - val_loss: 0.2026\n",
      "Epoch 867/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.2170 - val_accuracy: 0.9479 - val_loss: 0.1945\n",
      "Epoch 868/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.2233 - val_accuracy: 0.9439 - val_loss: 0.2023\n",
      "Epoch 869/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.2177 - val_accuracy: 0.9461 - val_loss: 0.1981\n",
      "Epoch 870/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2228 - val_accuracy: 0.9443 - val_loss: 0.2034\n",
      "Epoch 871/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.2148 - val_accuracy: 0.9491 - val_loss: 0.1933\n",
      "Epoch 872/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2155 - val_accuracy: 0.9461 - val_loss: 0.1945\n",
      "Epoch 873/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2200 - val_accuracy: 0.9421 - val_loss: 0.2031\n",
      "Epoch 874/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2148 - val_accuracy: 0.9445 - val_loss: 0.2041\n",
      "Epoch 875/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2266 - val_accuracy: 0.9465 - val_loss: 0.1942\n",
      "Epoch 876/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2166 - val_accuracy: 0.9455 - val_loss: 0.1993\n",
      "Epoch 877/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2101 - val_accuracy: 0.9465 - val_loss: 0.2028\n",
      "Epoch 878/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2182 - val_accuracy: 0.9457 - val_loss: 0.1908\n",
      "Epoch 879/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9342 - loss: 0.2055 - val_accuracy: 0.9495 - val_loss: 0.1882\n",
      "Epoch 880/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2221 - val_accuracy: 0.9469 - val_loss: 0.2021\n",
      "Epoch 881/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.2198 - val_accuracy: 0.9471 - val_loss: 0.1967\n",
      "Epoch 882/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2132 - val_accuracy: 0.9469 - val_loss: 0.1924\n",
      "Epoch 883/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.2248 - val_accuracy: 0.9459 - val_loss: 0.1996\n",
      "Epoch 884/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.2122 - val_accuracy: 0.9481 - val_loss: 0.1932\n",
      "Epoch 885/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2185 - val_accuracy: 0.9449 - val_loss: 0.2023\n",
      "Epoch 886/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2294 - val_accuracy: 0.9481 - val_loss: 0.1907\n",
      "Epoch 887/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2205 - val_accuracy: 0.9485 - val_loss: 0.1905\n",
      "Epoch 888/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2101 - val_accuracy: 0.9465 - val_loss: 0.1878\n",
      "Epoch 889/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2154 - val_accuracy: 0.9439 - val_loss: 0.1987\n",
      "Epoch 890/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2230 - val_accuracy: 0.9449 - val_loss: 0.1963\n",
      "Epoch 891/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2132 - val_accuracy: 0.9447 - val_loss: 0.1906\n",
      "Epoch 892/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2094 - val_accuracy: 0.9433 - val_loss: 0.1985\n",
      "Epoch 893/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2140 - val_accuracy: 0.9465 - val_loss: 0.1885\n",
      "Epoch 894/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.2222 - val_accuracy: 0.9477 - val_loss: 0.1971\n",
      "Epoch 895/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2163 - val_accuracy: 0.9405 - val_loss: 0.2072\n",
      "Epoch 896/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2203 - val_accuracy: 0.9461 - val_loss: 0.1908\n",
      "Epoch 897/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2225 - val_accuracy: 0.9473 - val_loss: 0.1897\n",
      "Epoch 898/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2167 - val_accuracy: 0.9465 - val_loss: 0.1893\n",
      "Epoch 899/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2199 - val_accuracy: 0.9451 - val_loss: 0.1953\n",
      "Epoch 900/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2073 - val_accuracy: 0.9443 - val_loss: 0.2042\n",
      "Epoch 901/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.2154 - val_accuracy: 0.9461 - val_loss: 0.1959\n",
      "Epoch 902/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2210 - val_accuracy: 0.9489 - val_loss: 0.1985\n",
      "Epoch 903/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.2151 - val_accuracy: 0.9465 - val_loss: 0.1979\n",
      "Epoch 904/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2221 - val_accuracy: 0.9445 - val_loss: 0.2030\n",
      "Epoch 905/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.2172 - val_accuracy: 0.9481 - val_loss: 0.1919\n",
      "Epoch 906/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.2113 - val_accuracy: 0.9479 - val_loss: 0.1943\n",
      "Epoch 907/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2180 - val_accuracy: 0.9399 - val_loss: 0.2015\n",
      "Epoch 908/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2222 - val_accuracy: 0.9445 - val_loss: 0.1926\n",
      "Epoch 909/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2235 - val_accuracy: 0.9449 - val_loss: 0.1981\n",
      "Epoch 910/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.2294 - val_accuracy: 0.9459 - val_loss: 0.1993\n",
      "Epoch 911/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2152 - val_accuracy: 0.9477 - val_loss: 0.1940\n",
      "Epoch 912/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.2154 - val_accuracy: 0.9489 - val_loss: 0.1977\n",
      "Epoch 913/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2095 - val_accuracy: 0.9463 - val_loss: 0.2012\n",
      "Epoch 914/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.2086 - val_accuracy: 0.9457 - val_loss: 0.2035\n",
      "Epoch 915/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2167 - val_accuracy: 0.9459 - val_loss: 0.1984\n",
      "Epoch 916/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2126 - val_accuracy: 0.9441 - val_loss: 0.2064\n",
      "Epoch 917/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9299 - loss: 0.2097 - val_accuracy: 0.9447 - val_loss: 0.2083\n",
      "Epoch 918/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2179 - val_accuracy: 0.9469 - val_loss: 0.2011\n",
      "Epoch 919/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2195 - val_accuracy: 0.9459 - val_loss: 0.1927\n",
      "Epoch 920/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2196 - val_accuracy: 0.9471 - val_loss: 0.1988\n",
      "Epoch 921/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2158 - val_accuracy: 0.9487 - val_loss: 0.1897\n",
      "Epoch 922/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2217 - val_accuracy: 0.9471 - val_loss: 0.1986\n",
      "Epoch 923/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2131 - val_accuracy: 0.9457 - val_loss: 0.1997\n",
      "Epoch 924/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2178 - val_accuracy: 0.9483 - val_loss: 0.1944\n",
      "Epoch 925/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2276 - val_accuracy: 0.9469 - val_loss: 0.1811\n",
      "Epoch 926/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.2148 - val_accuracy: 0.9495 - val_loss: 0.1946\n",
      "Epoch 927/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2175 - val_accuracy: 0.9475 - val_loss: 0.1905\n",
      "Epoch 928/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2133 - val_accuracy: 0.9481 - val_loss: 0.1906\n",
      "Epoch 929/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.2118 - val_accuracy: 0.9489 - val_loss: 0.1891\n",
      "Epoch 930/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2200 - val_accuracy: 0.9475 - val_loss: 0.1944\n",
      "Epoch 931/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2166 - val_accuracy: 0.9461 - val_loss: 0.1934\n",
      "Epoch 932/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.2121 - val_accuracy: 0.9457 - val_loss: 0.1972\n",
      "Epoch 933/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.2162 - val_accuracy: 0.9475 - val_loss: 0.1897\n",
      "Epoch 934/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2103 - val_accuracy: 0.9443 - val_loss: 0.2022\n",
      "Epoch 935/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2130 - val_accuracy: 0.9477 - val_loss: 0.1990\n",
      "Epoch 936/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2136 - val_accuracy: 0.9473 - val_loss: 0.1925\n",
      "Epoch 937/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2129 - val_accuracy: 0.9477 - val_loss: 0.1955\n",
      "Epoch 938/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2203 - val_accuracy: 0.9499 - val_loss: 0.1880\n",
      "Epoch 939/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2162 - val_accuracy: 0.9473 - val_loss: 0.1944\n",
      "Epoch 940/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2265 - val_accuracy: 0.9465 - val_loss: 0.1941\n",
      "Epoch 941/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.2105 - val_accuracy: 0.9483 - val_loss: 0.1955\n",
      "Epoch 942/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.2113 - val_accuracy: 0.9459 - val_loss: 0.2032\n",
      "Epoch 943/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2191 - val_accuracy: 0.9477 - val_loss: 0.1926\n",
      "Epoch 944/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2176 - val_accuracy: 0.9479 - val_loss: 0.1948\n",
      "Epoch 945/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.2103 - val_accuracy: 0.9455 - val_loss: 0.1908\n",
      "Epoch 946/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.2237 - val_accuracy: 0.9419 - val_loss: 0.2020\n",
      "Epoch 947/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2221 - val_accuracy: 0.9447 - val_loss: 0.1984\n",
      "Epoch 948/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2180 - val_accuracy: 0.9459 - val_loss: 0.1959\n",
      "Epoch 949/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.2100 - val_accuracy: 0.9475 - val_loss: 0.1956\n",
      "Epoch 950/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2092 - val_accuracy: 0.9461 - val_loss: 0.1885\n",
      "Epoch 951/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.2074 - val_accuracy: 0.9455 - val_loss: 0.1914\n",
      "Epoch 952/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2180 - val_accuracy: 0.9477 - val_loss: 0.1892\n",
      "Epoch 953/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2124 - val_accuracy: 0.9473 - val_loss: 0.1974\n",
      "Epoch 954/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2287 - val_accuracy: 0.9459 - val_loss: 0.2006\n",
      "Epoch 955/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2160 - val_accuracy: 0.9479 - val_loss: 0.1902\n",
      "Epoch 956/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9339 - loss: 0.2073 - val_accuracy: 0.9461 - val_loss: 0.1935\n",
      "Epoch 957/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2195 - val_accuracy: 0.9465 - val_loss: 0.1981\n",
      "Epoch 958/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2242 - val_accuracy: 0.9491 - val_loss: 0.1859\n",
      "Epoch 959/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2171 - val_accuracy: 0.9469 - val_loss: 0.1873\n",
      "Epoch 960/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9222 - loss: 0.2431 - val_accuracy: 0.9475 - val_loss: 0.2017\n",
      "Epoch 961/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.2166 - val_accuracy: 0.9459 - val_loss: 0.1966\n",
      "Epoch 962/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9317 - loss: 0.2096 - val_accuracy: 0.9505 - val_loss: 0.1909\n",
      "Epoch 963/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2117 - val_accuracy: 0.9491 - val_loss: 0.1866\n",
      "Epoch 964/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.2138 - val_accuracy: 0.9477 - val_loss: 0.1976\n",
      "Epoch 965/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.2048 - val_accuracy: 0.9467 - val_loss: 0.1887\n",
      "Epoch 966/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2150 - val_accuracy: 0.9485 - val_loss: 0.1911\n",
      "Epoch 967/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2116 - val_accuracy: 0.9465 - val_loss: 0.2008\n",
      "Epoch 968/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2174 - val_accuracy: 0.9493 - val_loss: 0.1917\n",
      "Epoch 969/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2146 - val_accuracy: 0.9457 - val_loss: 0.1879\n",
      "Epoch 970/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9310 - loss: 0.2058 - val_accuracy: 0.9517 - val_loss: 0.1857\n",
      "Epoch 971/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9327 - loss: 0.2108 - val_accuracy: 0.9501 - val_loss: 0.1936\n",
      "Epoch 972/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2135 - val_accuracy: 0.9471 - val_loss: 0.2007\n",
      "Epoch 973/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.2095 - val_accuracy: 0.9455 - val_loss: 0.1965\n",
      "Epoch 974/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.2248 - val_accuracy: 0.9479 - val_loss: 0.1915\n",
      "Epoch 975/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9301 - loss: 0.2180 - val_accuracy: 0.9499 - val_loss: 0.1905\n",
      "Epoch 976/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9310 - loss: 0.2166 - val_accuracy: 0.9475 - val_loss: 0.1902\n",
      "Epoch 977/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.2091 - val_accuracy: 0.9479 - val_loss: 0.1906\n",
      "Epoch 978/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2162 - val_accuracy: 0.9475 - val_loss: 0.1889\n",
      "Epoch 979/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2137 - val_accuracy: 0.9475 - val_loss: 0.1879\n",
      "Epoch 980/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9327 - loss: 0.2142 - val_accuracy: 0.9485 - val_loss: 0.1859\n",
      "Epoch 981/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2204 - val_accuracy: 0.9463 - val_loss: 0.1900\n",
      "Epoch 982/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.2178 - val_accuracy: 0.9485 - val_loss: 0.1959\n",
      "Epoch 983/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.2110 - val_accuracy: 0.9469 - val_loss: 0.1935\n",
      "Epoch 984/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.2125 - val_accuracy: 0.9493 - val_loss: 0.1942\n",
      "Epoch 985/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2129 - val_accuracy: 0.9485 - val_loss: 0.1921\n",
      "Epoch 986/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2154 - val_accuracy: 0.9479 - val_loss: 0.1960\n",
      "Epoch 987/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.2179 - val_accuracy: 0.9489 - val_loss: 0.1888\n",
      "Epoch 988/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.2103 - val_accuracy: 0.9465 - val_loss: 0.1943\n",
      "Epoch 989/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9354 - loss: 0.2069 - val_accuracy: 0.9495 - val_loss: 0.1927\n",
      "Epoch 990/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.2122 - val_accuracy: 0.9445 - val_loss: 0.1953\n",
      "Epoch 991/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.2168 - val_accuracy: 0.9495 - val_loss: 0.1965\n",
      "Epoch 992/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.2126 - val_accuracy: 0.9493 - val_loss: 0.1913\n",
      "Epoch 993/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.2150 - val_accuracy: 0.9497 - val_loss: 0.1931\n",
      "Epoch 994/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.2066 - val_accuracy: 0.9507 - val_loss: 0.1923\n",
      "Epoch 995/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2157 - val_accuracy: 0.9499 - val_loss: 0.1948\n",
      "Epoch 996/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.1997 - val_accuracy: 0.9515 - val_loss: 0.1872\n",
      "Epoch 997/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.2115 - val_accuracy: 0.9503 - val_loss: 0.1866\n",
      "Epoch 998/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9318 - loss: 0.2135 - val_accuracy: 0.9449 - val_loss: 0.1993\n",
      "Epoch 999/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2269 - val_accuracy: 0.9469 - val_loss: 0.1946\n",
      "Epoch 1000/1000\n",
      "\u001b[1m627/627\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9331 - loss: 0.2025 - val_accuracy: 0.9431 - val_loss: 0.2111\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8619610d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90ded",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(f\"{model_name}.keras\")\n",
    "with open(f\"{model_name}_label.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0155f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpityif7oh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpityif7oh/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpityif7oh'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 126), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 26), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13427967952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13427969296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13427969872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13427968912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13427968720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13427970064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1760606326.356392 1210015 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1760606326.356637 1210015 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite file\n",
    "with open(f\"{model_name}.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
