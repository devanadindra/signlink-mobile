{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397381d5",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efbb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: tf2onnx in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (1.16.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (1.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (3.15.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: onnx>=1.4.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from tf2onnx) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Using cached tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Installing collected packages: protobuf, numpy, tf2onnx\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 3.20.3\n",
      "\u001b[2K    Uninstalling protobuf-3.20.3:\n",
      "\u001b[2K      Successfully uninstalled protobuf-3.20.3━━\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: numpy━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.4\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling numpy-2.3.4:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.4━━\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: tf2onnx\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: tf2onnx 1.16.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling tf2onnx-1.16.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled tf2onnx-1.16.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [tf2onnx]m2/3\u001b[0m [tf2onnx]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
      "mediapipe 0.10.21 requires protobuf<5,>=4.25.3, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 protobuf-6.33.0 tf2onnx-1.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tf2onnx matplotlib numpy opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed27fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.20-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.15-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.14-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.13-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: pip is still looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.16.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.14.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.11.4-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.3-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (192 kB)\n",
      "  Using cached scipy-1.11.1.tar.gz (56.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[53 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140 /private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140/.mesonpy-3w98ejez/build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140/.mesonpy-3w98ejez/build/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.9.1\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140/.mesonpy-3w98ejez/build\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: SciPy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.3)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1167.4.1\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.3)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1167.4.1\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 0.29.37)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/opt/anaconda3/envs/ai-rhn/bin/python)\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: YES (/opt/homebrew/bin/pkg-config) 2.4.3\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.12\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-build-env-bp4qv6tj/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../../meson.build:82:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/pip-install-0dbcqsx7/scipy_a35e85954aa04ca39bc552df1bd1c140/.mesonpy-3w98ejez/build/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall tensorflow tf2onnx matplotlib numpy opencv-python scipy mediapipe pandas tqdm scikit-learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908a35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18590",
   "metadata": {},
   "source": [
    "# import and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc1fbd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be719935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "model_name = 'sign_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13103e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766be0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0  114M    0 83232    0     0  54378      0  0:36:51  0:00:01  0:36:50 54378\n",
      "  8  114M    8 10.0M    0     0  4148k      0  0:00:28  0:00:02  0:00:26 10.5M\n",
      " 18  114M   18 21.2M    0     0  6273k      0  0:00:18  0:00:03  0:00:15 10.9M\n",
      " 28  114M   28 32.5M    0     0  7453k      0  0:00:15  0:00:04  0:00:11 11.0M\n",
      " 38  114M   38 43.8M    0     0  8198k      0  0:00:14  0:00:05  0:00:09 11.0M\n",
      " 48  114M   48 55.1M    0     0  8716k      0  0:00:13  0:00:06  0:00:07 11.1M\n",
      " 56  114M   56 65.1M    0     0  8920k      0  0:00:13  0:00:07  0:00:06 11.0M\n",
      " 66  114M   66 76.4M    0     0  9230k      0  0:00:12  0:00:08  0:00:04 11.0M\n",
      " 76  114M   76 87.6M    0     0  9475k      0  0:00:12  0:00:09  0:00:03 11.0M\n",
      " 86  114M   86 98.9M    0     0  9671k      0  0:00:12  0:00:10  0:00:02 11.0M\n",
      " 96  114M   96  110M    0     0  9834k      0  0:00:11  0:00:11 --:--:-- 11.0M\n",
      "100  114M  100  114M    0     0  9892k      0  0:00:11  0:00:11 --:--:-- 11.2M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./alfabet-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/achmadnoer/alfabet-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66037a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./alfabet-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./alfabet-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21028c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Memindahkan 'Citra BISINDO' ke './dataset' ...\n",
      "✅ Berhasil dipindahkan ke ./dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = \"Citra BISINDO\"\n",
    "dst_dir = \"./dataset\"\n",
    "\n",
    "if not os.path.exists(src_dir):\n",
    "    raise FileNotFoundError(f\"❌ Folder sumber tidak ditemukan: {src_dir}\")\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📂 Memindahkan '{src_dir}' ke '{dst_dir}' ...\")\n",
    "shutil.move(src_dir, dst_dir)\n",
    "print(f\"✅ Berhasil dipindahkan ke {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b1bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 1396M    0  110k    0     0  70686      0  5:45:23  0:00:01  5:45:22  111k\n",
      "  0 1396M    0 2528k    0     0   976k      0  0:24:25  0:00:02  0:24:23 1277k\n",
      "  0 1396M    0 7005k    0     0  1950k      0  0:12:13  0:00:03  0:12:10 2350k\n",
      "  0 1396M    0 11.4M    0     0  2551k      0  0:09:20  0:00:04  0:09:16 2942k\n",
      "  1 1396M    1 16.0M    0     0  2945k      0  0:08:05  0:00:05  0:08:00 3306k\n",
      "  1 1396M    1 20.4M    0     0  3179k      0  0:07:29  0:00:06  0:07:23 4178k\n",
      "  1 1396M    1 23.4M    0     0  3167k      0  0:07:31  0:00:07  0:07:24 4303k\n",
      "  1 1396M    1 27.1M    0     0  3238k      0  0:07:21  0:00:08  0:07:13 4164k\n",
      "  2 1396M    2 31.2M    0     0  3337k      0  0:07:08  0:00:09  0:06:59 4059k\n",
      "  2 1396M    2 35.2M    0     0  3403k      0  0:07:00  0:00:10  0:06:50 3915k\n",
      "  2 1396M    2 39.7M    0     0  3511k      0  0:06:47  0:00:11  0:06:36 3948k\n",
      "  3 1396M    3 43.8M    0     0  3566k      0  0:06:41  0:00:12  0:06:29 4172k\n",
      "  3 1396M    3 47.9M    0     0  3614k      0  0:06:35  0:00:13  0:06:22 4259k\n",
      "  3 1396M    3 52.5M    0     0  3688k      0  0:06:27  0:00:14  0:06:13 4361k\n",
      "  4 1396M    4 57.9M    0     0  3804k      0  0:06:16  0:00:15  0:06:01 4652k\n",
      "  4 1396M    4 62.7M    0     0  3871k      0  0:06:09  0:00:16  0:05:53 4708k\n",
      "  4 1396M    4 67.7M    0     0  3943k      0  0:06:02  0:00:17  0:05:45 4892k\n",
      "  5 1396M    5 72.7M    0     0  4004k      0  0:05:57  0:00:18  0:05:39 5064k\n",
      "  5 1396M    5 77.8M    0     0  4067k      0  0:05:51  0:00:19  0:05:32 5173k\n",
      "  5 1396M    5 82.9M    0     0  4124k      0  0:05:46  0:00:20  0:05:26 5123k\n",
      "  6 1396M    6 87.4M    0     0  4149k      0  0:05:44  0:00:21  0:05:23 5073k\n",
      "  6 1396M    6 92.4M    0     0  4191k      0  0:05:41  0:00:22  0:05:19 5061k\n",
      "  6 1396M    6 97.3M    0     0  4225k      0  0:05:38  0:00:23  0:05:15 5049k\n",
      "  7 1396M    7  102M    0     0  4260k      0  0:05:35  0:00:24  0:05:11 5016k\n",
      "  7 1396M    7  107M    0     0  4294k      0  0:05:33  0:00:25  0:05:08 4995k\n",
      "  8 1396M    8  112M    0     0  4318k      0  0:05:31  0:00:26  0:05:05 5046k\n",
      "  8 1396M    8  116M    0     0  4339k      0  0:05:29  0:00:27  0:05:02 5009k\n",
      "  8 1396M    8  121M    0     0  4360k      0  0:05:28  0:00:28  0:05:00 4992k\n",
      "  9 1396M    9  127M    0     0  4404k      0  0:05:24  0:00:29  0:04:55 5111k\n",
      "  9 1396M    9  132M    0     0  4437k      0  0:05:22  0:00:30  0:04:52 5171k\n",
      "  9 1396M    9  137M    0     0  4472k      0  0:05:19  0:00:31  0:04:48 5292k\n",
      " 10 1396M   10  142M    0     0  4486k      0  0:05:18  0:00:32  0:04:46 5299k\n",
      " 10 1396M   10  146M    0     0  4455k      0  0:05:21  0:00:33  0:04:48 5005k\n",
      " 10 1396M   10  150M    0     0  4445k      0  0:05:21  0:00:34  0:04:47 4690k\n",
      " 10 1396M   10  153M    0     0  4416k      0  0:05:23  0:00:35  0:04:48 4284k\n",
      " 11 1396M   11  157M    0     0  4399k      0  0:05:25  0:00:36  0:04:49 3939k\n",
      " 11 1396M   11  160M    0     0  4380k      0  0:05:26  0:00:37  0:04:49 3691k\n",
      " 11 1396M   11  164M    0     0  4364k      0  0:05:27  0:00:38  0:04:49 3750k\n",
      " 12 1396M   12  168M    0     0  4360k      0  0:05:28  0:00:39  0:04:49 3770k\n",
      " 12 1396M   12  172M    0     0  4364k      0  0:05:27  0:00:40  0:04:47 3993k\n",
      " 12 1396M   12  177M    0     0  4368k      0  0:05:27  0:00:41  0:04:46 4140k\n",
      " 12 1396M   12  181M    0     0  4363k      0  0:05:27  0:00:42  0:04:45 4231k\n",
      " 13 1396M   13  185M    0     0  4367k      0  0:05:27  0:00:43  0:04:44 4387k\n",
      " 13 1396M   13  190M    0     0  4370k      0  0:05:27  0:00:44  0:04:43 4454k\n",
      " 13 1396M   13  195M    0     0  4392k      0  0:05:25  0:00:45  0:04:40 4621k\n",
      " 14 1396M   14  202M    0     0  4448k      0  0:05:21  0:00:46  0:04:35 5116k\n",
      " 14 1396M   14  208M    0     0  4489k      0  0:05:18  0:00:47  0:04:31 5561k\n",
      " 15 1396M   15  214M    0     0  4514k      0  0:05:16  0:00:48  0:04:28 5802k\n",
      " 15 1396M   15  219M    0     0  4542k      0  0:05:14  0:00:49  0:04:25 6076k\n",
      " 16 1396M   16  225M    0     0  4567k      0  0:05:13  0:00:50  0:04:23 6166k\n",
      " 16 1396M   16  231M    0     0  4595k      0  0:05:11  0:00:51  0:04:20 5961k\n",
      " 16 1396M   16  237M    0     0  4622k      0  0:05:09  0:00:52  0:04:17 5886k\n",
      " 17 1396M   17  242M    0     0  4636k      0  0:05:08  0:00:53  0:04:15 5820k\n",
      " 17 1396M   17  248M    0     0  4661k      0  0:05:06  0:00:54  0:04:12 5840k\n",
      " 18 1396M   18  254M    0     0  4685k      0  0:05:05  0:00:55  0:04:10 5874k\n",
      " 18 1396M   18  260M    0     0  4720k      0  0:05:03  0:00:56  0:04:07 6006k\n",
      " 19 1396M   19  270M    0     0  4803k      0  0:04:57  0:00:57  0:04:00 6714k\n",
      " 20 1396M   20  281M    0     0  4918k      0  0:04:50  0:00:58  0:03:52 7942k\n",
      " 20 1396M   20  292M    0     0  5029k      0  0:04:44  0:00:59  0:03:45 9049k\n",
      " 21 1396M   21  303M    0     0  5137k      0  0:04:38  0:01:00  0:03:38  9.9M\n",
      " 22 1396M   22  315M    0     0  5241k      0  0:04:32  0:01:01  0:03:31 10.8M\n",
      " 23 1396M   23  325M    0     0  5320k      0  0:04:28  0:01:02  0:03:26 11.0M\n",
      " 24 1396M   24  336M    0     0  5418k      0  0:04:23  0:01:03  0:03:20 11.0M\n",
      " 24 1396M   24  347M    0     0  5513k      0  0:04:19  0:01:04  0:03:15 11.0M\n",
      " 25 1396M   25  359M    0     0  5605k      0  0:04:15  0:01:05  0:03:10 11.0M\n",
      " 26 1396M   26  370M    0     0  5694k      0  0:04:11  0:01:06  0:03:05 11.0M\n",
      " 27 1396M   27  380M    0     0  5762k      0  0:04:08  0:01:07  0:03:01 11.0M\n",
      " 28 1396M   28  391M    0     0  5846k      0  0:04:04  0:01:08  0:02:56 11.0M\n",
      " 28 1396M   28  402M    0     0  5928k      0  0:04:01  0:01:09  0:02:52 11.0M\n",
      " 29 1396M   29  414M    0     0  6008k      0  0:03:58  0:01:10  0:02:48 11.0M\n",
      " 30 1396M   30  425M    0     0  6085k      0  0:03:55  0:01:11  0:02:44 11.0M\n",
      " 31 1396M   31  436M    0     0  6159k      0  0:03:52  0:01:12  0:02:40 11.2M\n",
      " 31 1396M   31  446M    0     0  6216k      0  0:03:50  0:01:13  0:02:37 11.0M\n",
      " 32 1396M   32  458M    0     0  6287k      0  0:03:47  0:01:14  0:02:33 11.0M\n",
      " 33 1396M   33  469M    0     0  6357k      0  0:03:45  0:01:15  0:02:30 11.0M\n",
      " 34 1396M   34  480M    0     0  6424k      0  0:03:42  0:01:16  0:02:26 11.0M\n",
      " 35 1396M   35  490M    0     0  6466k      0  0:03:41  0:01:17  0:02:24 10.6M\n",
      " 35 1396M   35  496M    0     0  6463k      0  0:03:41  0:01:18  0:02:23  9.8M\n",
      " 36 1396M   36  504M    0     0  6494k      0  0:03:40  0:01:19  0:02:21 9580k\n",
      " 36 1396M   36  510M    0     0  6489k      0  0:03:40  0:01:20  0:02:20 8492k\n",
      " 37 1396M   37  521M    0     0  6549k      0  0:03:38  0:01:21  0:02:17 8464k\n",
      " 38 1396M   38  533M    0     0  6608k      0  0:03:36  0:01:22  0:02:14 8824k\n",
      " 38 1396M   38  544M    0     0  6664k      0  0:03:34  0:01:23  0:02:11 9815k\n",
      " 39 1396M   39  554M    0     0  6717k      0  0:03:32  0:01:24  0:02:08 10.0M\n",
      " 40 1396M   40  565M    0     0  6771k      0  0:03:31  0:01:25  0:02:06 11.0M\n",
      " 41 1396M   41  577M    0     0  6826k      0  0:03:29  0:01:26  0:02:03 11.0M\n",
      " 42 1396M   42  588M    0     0  6879k      0  0:03:27  0:01:27  0:02:00 11.0M\n",
      " 42 1396M   42  599M    0     0  6931k      0  0:03:26  0:01:28  0:01:58 11.1M\n",
      " 43 1396M   43  609M    0     0  6964k      0  0:03:25  0:01:29  0:01:56 10.8M\n",
      " 44 1396M   44  620M    0     0  7014k      0  0:03:23  0:01:30  0:01:53 10.9M\n",
      " 45 1396M   45  631M    0     0  7062k      0  0:03:22  0:01:31  0:01:51 10.8M\n",
      " 46 1396M   46  642M    0     0  7110k      0  0:03:21  0:01:32  0:01:49 10.8M\n",
      " 46 1396M   46  654M    0     0  7156k      0  0:03:19  0:01:33  0:01:46 10.8M\n",
      " 47 1396M   47  664M    0     0  7189k      0  0:03:18  0:01:34  0:01:44 10.9M\n",
      " 48 1396M   48  675M    0     0  7234k      0  0:03:17  0:01:35  0:01:42 10.9M\n",
      " 49 1396M   49  686M    0     0  7278k      0  0:03:16  0:01:36  0:01:40 10.9M\n",
      " 49 1396M   49  697M    0     0  7321k      0  0:03:15  0:01:37  0:01:38 10.9M\n",
      " 50 1396M   50  708M    0     0  7363k      0  0:03:14  0:01:38  0:01:36 10.9M\n",
      " 51 1396M   51  720M    0     0  7405k      0  0:03:13  0:01:39  0:01:34 11.2M\n",
      " 52 1396M   52  730M    0     0  7433k      0  0:03:12  0:01:40  0:01:32 10.9M\n",
      " 53 1396M   53  741M    0     0  7473k      0  0:03:11  0:01:41  0:01:30 10.9M\n",
      " 53 1396M   53  752M    0     0  7512k      0  0:03:10  0:01:42  0:01:28 10.9M\n",
      " 54 1396M   54  763M    0     0  7551k      0  0:03:09  0:01:43  0:01:26 10.9M\n",
      " 55 1396M   55  775M    0     0  7589k      0  0:03:08  0:01:44  0:01:24 10.9M\n",
      " 56 1396M   56  785M    0     0  7613k      0  0:03:07  0:01:45  0:01:22 10.9M\n",
      " 57 1396M   57  796M    0     0  7649k      0  0:03:06  0:01:46  0:01:20 10.9M\n",
      " 57 1396M   57  807M    0     0  7685k      0  0:03:06  0:01:47  0:01:19 10.9M\n",
      " 58 1396M   58  818M    0     0  7720k      0  0:03:05  0:01:48  0:01:17 10.9M\n",
      " 59 1396M   59  829M    0     0  7755k      0  0:03:04  0:01:49  0:01:15 10.9M\n",
      " 60 1396M   60  839M    0     0  7777k      0  0:03:03  0:01:50  0:01:13 10.9M\n",
      " 60 1396M   60  851M    0     0  7810k      0  0:03:03  0:01:51  0:01:12 10.9M\n",
      " 61 1396M   61  862M    0     0  7843k      0  0:03:02  0:01:52  0:01:10 10.9M\n",
      " 62 1396M   62  873M    0     0  7875k      0  0:03:01  0:01:53  0:01:08 10.9M\n",
      " 63 1396M   63  884M    0     0  7907k      0  0:03:00  0:01:54  0:01:06 10.9M\n",
      " 64 1396M   64  894M    0     0  7928k      0  0:03:00  0:01:55  0:01:05 11.0M\n",
      " 64 1396M   64  906M    0     0  7958k      0  0:02:59  0:01:56  0:01:03 10.9M\n",
      " 65 1396M   65  917M    0     0  7988k      0  0:02:59  0:01:57  0:01:02 10.9M\n",
      " 66 1396M   66  928M    0     0  8018k      0  0:02:58  0:01:58  0:01:00 10.9M\n",
      " 67 1396M   67  939M    0     0  8047k      0  0:02:57  0:01:59  0:00:58 10.9M\n",
      " 68 1396M   68  950M    0     0  8075k      0  0:02:57  0:02:00  0:00:57 11.2M\n",
      " 68 1396M   68  961M    0     0  8094k      0  0:02:56  0:02:01  0:00:55 10.9M\n",
      " 69 1396M   69  972M    0     0  8121k      0  0:02:56  0:02:02  0:00:54 10.9M\n",
      " 70 1396M   70  983M    0     0  8149k      0  0:02:55  0:02:03  0:00:52 10.9M\n",
      " 71 1396M   71  994M    0     0  8176k      0  0:02:54  0:02:04  0:00:50 10.9M\n",
      " 72 1396M   72 1006M    0     0  8202k      0  0:02:54  0:02:05  0:00:49 11.0M\n",
      " 72 1396M   72 1015M    0     0  8218k      0  0:02:54  0:02:06  0:00:48 10.9M\n",
      " 73 1396M   73 1027M    0     0  8244k      0  0:02:53  0:02:07  0:00:46 10.9M\n",
      " 74 1396M   74 1038M    0     0  8269k      0  0:02:52  0:02:08  0:00:44 10.9M\n",
      " 75 1396M   75 1049M    0     0  8294k      0  0:02:52  0:02:09  0:00:43 10.9M\n",
      " 75 1396M   75 1060M    0     0  8319k      0  0:02:51  0:02:10  0:00:41 10.9M\n",
      " 76 1396M   76 1070M    0     0  8332k      0  0:02:51  0:02:11  0:00:40 10.9M\n",
      " 77 1396M   77 1082M    0     0  8356k      0  0:02:51  0:02:12  0:00:39 10.9M\n",
      " 78 1396M   78 1093M    0     0  8380k      0  0:02:50  0:02:13  0:00:37 10.9M\n",
      " 79 1396M   79 1104M    0     0  8403k      0  0:02:50  0:02:14  0:00:36 10.9M\n",
      " 79 1396M   79 1115M    0     0  8426k      0  0:02:49  0:02:15  0:00:34 10.9M\n",
      " 80 1396M   80 1125M    0     0  8439k      0  0:02:49  0:02:16  0:00:33 10.9M\n",
      " 81 1396M   81 1136M    0     0  8461k      0  0:02:49  0:02:17  0:00:32 10.9M\n",
      " 82 1396M   82 1148M    0     0  8483k      0  0:02:48  0:02:18  0:00:30 10.9M\n",
      " 82 1396M   82 1159M    0     0  8505k      0  0:02:48  0:02:19  0:00:29 10.9M\n",
      " 83 1396M   83 1170M    0     0  8526k      0  0:02:47  0:02:20  0:00:27 10.9M\n",
      " 84 1396M   84 1181M    0     0  8545k      0  0:02:47  0:02:21  0:00:26 11.1M\n",
      " 85 1396M   85 1191M    0     0  8559k      0  0:02:47  0:02:22  0:00:25 10.9M\n",
      " 86 1396M   86 1203M    0     0  8579k      0  0:02:46  0:02:23  0:00:23 10.9M\n",
      " 86 1396M   86 1214M    0     0  8599k      0  0:02:46  0:02:24  0:00:22 10.9M\n",
      " 87 1396M   87 1225M    0     0  8619k      0  0:02:45  0:02:25  0:00:20 10.9M\n",
      " 88 1396M   88 1236M    0     0  8639k      0  0:02:45  0:02:26  0:00:19 11.0M\n",
      " 89 1396M   89 1246M    0     0  8650k      0  0:02:45  0:02:27  0:00:18 10.9M\n",
      " 90 1396M   90 1258M    0     0  8669k      0  0:02:45  0:02:28  0:00:17 10.9M\n",
      " 90 1396M   90 1269M    0     0  8688k      0  0:02:44  0:02:29  0:00:15 10.9M\n",
      " 91 1396M   91 1280M    0     0  8707k      0  0:02:44  0:02:30  0:00:14 10.9M\n",
      " 92 1396M   92 1291M    0     0  8725k      0  0:02:43  0:02:31  0:00:12 10.9M\n",
      " 93 1396M   93 1301M    0     0  8734k      0  0:02:43  0:02:32  0:00:11 10.9M\n",
      " 93 1396M   93 1312M    0     0  8752k      0  0:02:43  0:02:33  0:00:10 10.9M\n",
      " 94 1396M   94 1323M    0     0  8769k      0  0:02:43  0:02:34  0:00:09 10.9M\n",
      " 95 1396M   95 1335M    0     0  8787k      0  0:02:42  0:02:35  0:00:07 10.9M\n",
      " 96 1396M   96 1346M    0     0  8804k      0  0:02:42  0:02:36  0:00:06 10.9M\n",
      " 97 1396M   97 1356M    0     0  8813k      0  0:02:42  0:02:37  0:00:05 10.9M\n",
      " 97 1396M   97 1367M    0     0  8830k      0  0:02:41  0:02:38  0:00:03 10.9M\n",
      " 98 1396M   98 1378M    0     0  8847k      0  0:02:41  0:02:39  0:00:02 10.9M\n",
      " 99 1396M   99 1390M    0     0  8863k      0  0:02:41  0:02:40  0:00:01 10.9M\n",
      "100 1396M  100 1396M    0     0  8874k      0  0:02:41  0:02:41 --:--:-- 10.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/agungmrf/indonesian-sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    Example: src_folder/cat -> dataset/cat\n",
    "             src_folder/dog -> dataset/dog\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all label folders in the source\n",
    "    for label in os.listdir(src_folder):\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Skip if not a folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Move all files from src → dest\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Avoid overwriting files with same name\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_2{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./indonesian-sign-language-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61be52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/train' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/val' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1353535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./bisindo\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbeabb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/yunitayupratiwi/bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./bisindo-dataset.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, based on the first letter of the filename.\n",
    "    Example: src_folder/A.66ae97e2-c1e4-11eb-83d3-0008ca6b6d30.jpg -> dataset/A\n",
    "             src_folder/B.002d8fdf-c1e3-11eb-952a-0008ca6b6d30.jpg -> dataset/B\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all file folders in the source\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "\n",
    "        # Skip if a folder\n",
    "        if os.path.isdir(src_file):\n",
    "            continue\n",
    "        \n",
    "        # Skip if not a jpg\n",
    "        if not src_file.lower().endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        label = filename[0].upper()  # First character as label\n",
    "        dest = os.path.join(dataset_dir, label)\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        dst_file = os.path.join(dest, filename)\n",
    "\n",
    "        # Avoid overwriting files with same name\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            dst_file = os.path.join(dest, f\"{base}_3{ext}\")\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "    print(f\"successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b15a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf12b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e913a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./BISINDO - Dataset\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./BISINDO - Dataset\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca6282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  238M  100  238M    0     0  2646k      0  0:01:32  0:01:32 --:--:-- 2901k  2370k      0  0:01:43  0:00:05  0:01:38 3158k   0  0:01:35  0:00:47  0:00:48 2584k590k      0  0:01:34  0:00:54  0:00:40 2818k   0  0:01:34  0:01:02  0:00:32 2759k1:33  0:01:15  0:00:18 2674k0  2626k      0  0:01:33  0:01:16  0:00:17 2800k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/bonarsitorus/sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e87a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./sign-language-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_4(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure,\n",
    "    except folders with '_npy' in their name.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "        # Lewati folder yang mengandung '_npy'\n",
    "        if \"_npy\" in label:\n",
    "            continue\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_4{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debd9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './data_tambahan' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset_4('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3406b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./data_tambahan\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./data_tambahan\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da58f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1944M  100 1944M    0     0  2602k      0  0:12:45  0:12:45 --:--:-- 2673k   0     0  2393k      0  0:13:52  0:00:13  0:13:39 2692kk      0  0:12:47  0:00:39  0:12:08 2700k:00  0:11:38 2686k   0  0:12:32  0:01:23  0:11:09 2677k655k      0  0:12:29  0:01:38  0:10:51 2709k    0     0  2657k      0  0:12:29  0:01:42  0:10:47 2615k 2660k      0  0:12:28  0:02:05  0:10:23 2516k31  0:02:29  0:10:02 2710k 0  2644k      0  0:12:32  0:03:03  0:09:29 2612k11  0:09:20 2628k      0  0:12:32  0:03:25  0:09:07 2644k0:12:32  0:03:30  0:09:02 2652k 2642k      0  0:12:33  0:03:44  0:08:49 2555k7k      0  0:12:38  0:04:26  0:08:12 2576k      0  0:12:37  0:04:28  0:08:09 2770k:37  0:08:00 2650k      0  0:12:37  0:04:41  0:07:56 2721k    0  0:12:37  0:04:45  0:07:52 2650k      0  0:12:37  0:04:47  0:07:50 2730k 0  2629k      0  0:12:37  0:05:01  0:07:36 2608k0  2629k      0  0:12:37  0:05:07  0:07:30 2596k2631k      0  0:12:36  0:05:30  0:07:06 2813k 2629k      0  0:12:37  0:05:45  0:06:52 2698k:06:11  0:06:27 2694k 0  0:12:38  0:06:14  0:06:24 2622k:40  0:07:45  0:04:55 2442k2619k      0  0:12:40  0:08:05  0:04:35 2466k   0  2619k      0  0:12:40  0:08:06  0:04:34 2924k0     0  2619k      0  0:12:40  0:08:12  0:04:28 2607k   0  2619k      0  0:12:40  0:08:13  0:04:27 2608k   0     0  2620k      0  0:12:39  0:08:20  0:04:19 2749k     0  0:12:40  0:08:21  0:04:19 2662k 2614k      0  0:12:41  0:08:40  0:04:01 2584k5k      0  0:12:41  0:09:16  0:03:25 2512k 0  2613k      0  0:12:42  0:09:38  0:03:04 2670k   0     0  2614k      0  0:12:41  0:09:39  0:03:02 2765k 0:02:53 2649k  2614k      0  0:12:41  0:09:58  0:02:43 2727k2k      0  0:12:42  0:10:36  0:02:06 2544k    0  0:12:45  0:11:37  0:01:08 2370k602k      0  0:12:45  0:11:47  0:00:58 2643k    0  0:12:45  0:11:54  0:00:51 2613k 0  2602k      0  0:12:45  0:12:02  0:00:43 2562k    0  0:12:45  0:12:06  0:00:39 2605k5  0:12:06  0:00:39 2610k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-hand-sign-language-bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/kelsha/indonesian-hand-sign-language-bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc5d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./indonesian-hand-sign-language-bisindo-dataset.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-hand-sign-language-bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7388a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_5(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_5{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f31bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './dataset_bisindo/train/images' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset_5('./dataset_bisindo/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d39e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './dataset_bisindo/val/images' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset_5('./dataset_bisindo/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1beb708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./dataset_bisindo\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./dataset_bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24dcc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 2198M  100 2198M    0     0  2601k      0  0:14:25  0:14:25 --:--:-- 2626k0:14:30 2632k0     0  2594k      0  0:14:27  0:00:23  0:14:04 2692k0:14:18  0:00:37  0:13:41 2670k0     0  2596k      0  0:14:26  0:00:47  0:13:39 2372kM    0     0  2597k      0  0:14:26  0:01:03  0:13:23 2588k 0  2596k      0  0:14:26  0:01:07  0:13:19 2630k    0     0  2598k      0  0:14:26  0:01:14  0:13:12 2614k 0     0  2599k      0  0:14:26  0:01:18  0:13:08 2648kM    0     0  2600k      0  0:14:25  0:01:22  0:13:03 2618k    0  0:14:24  0:01:31  0:12:53 2583k  2604k      0  0:14:24  0:01:33  0:12:51 2620k1:35  0:12:48 2643k:36  0:12:49 2555k  0     0  2606k      0  0:14:23  0:01:51  0:12:32 2714k   0  0:14:24  0:01:52  0:12:32 2592k3  0:01:57  0:12:26 2669k:12:09 2645k  0  2606k      0  0:14:23  0:02:18  0:12:05 2605k0  0:14:23  0:02:37  0:11:46 2552k 2198M   18  403M    0     0  2608k      0  0:14:22  0:02:38  0:11:44 2636k8k      0  0:14:22  0:02:55  0:11:27 2581k 464M    0     0  2605k      0  0:14:23  0:03:02  0:11:21 2546k 0  2610k      0  0:14:22  0:03:06  0:11:16 2799k  2605k      0  0:14:23  0:03:11  0:11:12 2400k   0  0:14:23  0:03:24  0:10:59 2574k3k      0  0:14:24  0:03:27  0:10:57 2587k24  0:03:52  0:10:32 2463k  0:04:00  0:10:25 2474k2590k      0  0:14:28  0:04:19  0:10:09 2393kk      0  0:14:28  0:04:51  0:09:37 2561k    0  2593k      0  0:14:28  0:04:57  0:09:31 2632k  2593k      0  0:14:28  0:05:26  0:09:02 2432k 2484k595k      0  0:14:27  0:05:48  0:08:39 2594k07  0:08:19 2648k599k      0  0:14:25  0:06:13  0:08:12 2674k:24  0:08:01 2704k25  0:06:32  0:07:53 2714k    0  2598k      0  0:14:26  0:07:02  0:07:24 2622k  0  2601k      0  0:14:25  0:07:29  0:06:56 2663k0  0:14:25  0:07:39  0:06:46 2631k 2599k      0  0:14:25  0:08:10  0:06:15 2599k 2600k      0  0:14:25  0:08:22  0:06:03 2567k2600k      0  0:14:25  0:09:17  0:05:08 2616k09:27  0:04:57 2723k   0  2601k      0  0:14:25  0:09:39  0:04:46 2540k 2604k      0  0:14:24  0:10:27  0:03:57 2682k01k      0  0:14:25  0:11:18  0:03:07 2533k      0  0:14:25  0:11:29  0:02:56 2530k0  0:02:45 2579k2k      0  0:14:24  0:11:48  0:02:36 2675k 2603k      0  0:14:24  0:12:12  0:02:12 2706k    0  2602k      0  0:14:24  0:12:16  0:02:08 2589k:18  0:02:06 2541k    0  2602k      0  0:14:24  0:12:22  0:02:02 2621k:24  0:12:26  0:01:58 2562k2603k      0  0:14:24  0:12:29  0:01:55 2647k:01:52 2595k 0  0:14:24  0:12:53  0:01:31 2569k 2616k:13:05  0:01:19 2531k      0  0:14:24  0:13:18  0:01:06 2601k02k      0  0:14:24  0:13:21  0:01:03 2517k0:13:28  0:00:56 2729k  0:00:42 2449k4:24  0:13:46  0:00:38 2542k25  0:13:47  0:00:38 2539k14:02  0:00:23 2619k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-final.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/skripsiairlangga/bisindo-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a42ca9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./bisindo-final.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./bisindo_final\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-final.zip\"\n",
    "extract_dir = \"./bisindo_final\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "# Membuat folder extract_dir jika belum ada\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57255468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_6(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_6{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ce715f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo_final' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset_6('./bisindo_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afcd4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./bisindo_final\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo_final\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5e9ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760593484.973577 1027334 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760593484.983228 1027765 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760593484.988650 1027765 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4257553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    \n",
    "    if not result.multi_hand_landmarks:\n",
    "        return None\n",
    "    \n",
    "    # List semua tangan yang terdeteksi\n",
    "    coords_all = []\n",
    "    for landmarks in result.multi_hand_landmarks:\n",
    "        coords = []\n",
    "        for lm in landmarks.landmark:\n",
    "            coords.extend([lm.x, lm.y, lm.z])\n",
    "        coords_all.append(coords)\n",
    "    \n",
    "    # Jika hanya 1 tangan, tambahkan 0 agar panjang fitur tetap konsisten\n",
    "    if len(coords_all) == 1:\n",
    "        coords_all.append([0.0]*63)  # tangan kosong\n",
    "    \n",
    "    # Flatten dua tangan (kanan + kiri)\n",
    "    features = np.array(coords_all[0] + coords_all[1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d20d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1197 [00:00<?, ?it/s]W0000 00:00:1760593490.710060 1027765 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "100%|██████████| 1197/1197 [00:31<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1221/1221 [00:31<00:00, 38.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:26<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1189/1189 [00:34<00:00, 34.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1204/1204 [00:27<00:00, 43.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1235/1235 [00:31<00:00, 39.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1223/1223 [00:34<00:00, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1194/1194 [00:34<00:00, 35.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1222/1222 [00:29<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1220/1220 [00:28<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1193/1193 [00:34<00:00, 35.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1217/1217 [00:27<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:35<00:00, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [00:32<00:00, 36.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [00:28<00:00, 42.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1217/1217 [00:33<00:00, 36.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1192/1192 [00:35<00:00, 33.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [00:28<00:00, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1188/1188 [00:35<00:00, 33.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1224/1224 [00:34<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1215/1215 [00:28<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [00:28<00:00, 42.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1221/1221 [00:33<00:00, 35.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1214/1214 [00:35<00:00, 34.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [00:29<00:00, 39.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1223/1223 [00:27<00:00, 44.04it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label in sorted(os.listdir(dataset_dir)):\n",
    "    label_path = os.path.join(dataset_dir, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing label: {label}')\n",
    "    for img_name in tqdm(os.listdir(label_path)):\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        landmarks = extract_hand_landmarks(img_path)\n",
    "        if landmarks is not None:\n",
    "            data.append(landmarks)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e16017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dan label berhasil disimpan ke hand_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "# Ubah list menjadi DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "# Simpan ke CSV\n",
    "df.to_csv(\"hand_keypoints.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data dan label berhasil disimpan ke hand_keypoints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeba27f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9411987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 25305\n",
      "          0         1             2         3         4         5         6  \\\n",
      "0  0.589252  0.788577  7.732578e-08  0.540710  0.797574 -0.010122  0.494010   \n",
      "1  0.816977  0.762783 -9.139245e-08  0.801779  0.732191  0.003005  0.774102   \n",
      "2  0.725103  0.491935 -4.427249e-07  0.658864  0.500457 -0.027891  0.584359   \n",
      "3  0.188371  0.656543 -8.581127e-08  0.283549  0.646443 -0.036480  0.366026   \n",
      "4  0.113166  0.822599  5.401650e-07  0.195477  0.813338 -0.077608  0.288585   \n",
      "\n",
      "          7         8         9  ...       117       118       119       120  \\\n",
      "0  0.776065 -0.034902  0.458915  ...  0.259818  0.687959 -0.093514  0.256858   \n",
      "1  0.710470  0.000877  0.747481  ...  0.627653  0.740314 -0.056922  0.625121   \n",
      "2  0.476563 -0.053607  0.521293  ...  0.223792  0.330818 -0.103738  0.219856   \n",
      "3  0.589501 -0.066297  0.421726  ...  0.758943  0.368739 -0.107302  0.773216   \n",
      "4  0.775300 -0.115059  0.381177  ...  0.871711  0.542666 -0.079876  0.875374   \n",
      "\n",
      "        121       122       123       124       125  label  \n",
      "0  0.731087 -0.083111  0.242542  0.740920 -0.070938      A  \n",
      "1  0.737795 -0.057063  0.627400  0.744683 -0.054733      A  \n",
      "2  0.384147 -0.090373  0.220490  0.394726 -0.071387      A  \n",
      "3  0.424807 -0.090161  0.791487  0.425094 -0.069101      A  \n",
      "4  0.603269 -0.072792  0.862440  0.643383 -0.055686      A  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hand_keypoints.csv\")\n",
    "print(f\"Total data: {len(df)}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "X = df.drop('label', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f9fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "565b55f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,354</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m32,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m3,354\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9753c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.2532 - loss: 2.5028 - val_accuracy: 0.5060 - val_loss: 1.7814\n",
      "Epoch 2/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.5015 - loss: 1.6931 - val_accuracy: 0.6532 - val_loss: 1.2456\n",
      "Epoch 3/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6087 - loss: 1.3489 - val_accuracy: 0.7224 - val_loss: 1.0189\n",
      "Epoch 4/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.6616 - loss: 1.1866 - val_accuracy: 0.7338 - val_loss: 0.9202\n",
      "Epoch 5/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.6889 - loss: 1.0719 - val_accuracy: 0.7722 - val_loss: 0.8059\n",
      "Epoch 6/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7131 - loss: 0.9883 - val_accuracy: 0.8016 - val_loss: 0.7403\n",
      "Epoch 7/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.7297 - loss: 0.9325 - val_accuracy: 0.8113 - val_loss: 0.7016\n",
      "Epoch 8/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7453 - loss: 0.8811 - val_accuracy: 0.8105 - val_loss: 0.6698\n",
      "Epoch 9/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.7567 - loss: 0.8442 - val_accuracy: 0.8226 - val_loss: 0.6483\n",
      "Epoch 10/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7699 - loss: 0.7965 - val_accuracy: 0.8313 - val_loss: 0.5890\n",
      "Epoch 11/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.7788 - loss: 0.7752 - val_accuracy: 0.8522 - val_loss: 0.5549\n",
      "Epoch 12/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7869 - loss: 0.7293 - val_accuracy: 0.8564 - val_loss: 0.5229\n",
      "Epoch 13/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7910 - loss: 0.7111 - val_accuracy: 0.8526 - val_loss: 0.5364\n",
      "Epoch 14/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.7975 - loss: 0.6976 - val_accuracy: 0.8542 - val_loss: 0.5105\n",
      "Epoch 15/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8000 - loss: 0.6849 - val_accuracy: 0.8660 - val_loss: 0.4917\n",
      "Epoch 16/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8056 - loss: 0.6673 - val_accuracy: 0.8745 - val_loss: 0.4660\n",
      "Epoch 17/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8121 - loss: 0.6477 - val_accuracy: 0.8650 - val_loss: 0.4871\n",
      "Epoch 18/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.8183 - loss: 0.6297 - val_accuracy: 0.8763 - val_loss: 0.4501\n",
      "Epoch 19/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8158 - loss: 0.6214 - val_accuracy: 0.8797 - val_loss: 0.4305\n",
      "Epoch 20/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8194 - loss: 0.6147 - val_accuracy: 0.8824 - val_loss: 0.4336\n",
      "Epoch 21/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.8264 - loss: 0.5893 - val_accuracy: 0.8874 - val_loss: 0.4165\n",
      "Epoch 22/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8267 - loss: 0.5904 - val_accuracy: 0.8890 - val_loss: 0.3982\n",
      "Epoch 23/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.8279 - loss: 0.5821 - val_accuracy: 0.8866 - val_loss: 0.4083\n",
      "Epoch 24/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8352 - loss: 0.5646 - val_accuracy: 0.8909 - val_loss: 0.3858\n",
      "Epoch 25/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.8329 - loss: 0.5602 - val_accuracy: 0.8884 - val_loss: 0.4070\n",
      "Epoch 26/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8362 - loss: 0.5506 - val_accuracy: 0.8921 - val_loss: 0.3856\n",
      "Epoch 27/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8372 - loss: 0.5478 - val_accuracy: 0.8937 - val_loss: 0.3742\n",
      "Epoch 28/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8416 - loss: 0.5359 - val_accuracy: 0.9002 - val_loss: 0.3619\n",
      "Epoch 29/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.8399 - loss: 0.5386 - val_accuracy: 0.8929 - val_loss: 0.3738\n",
      "Epoch 30/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.8454 - loss: 0.5275 - val_accuracy: 0.8975 - val_loss: 0.3676\n",
      "Epoch 31/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8484 - loss: 0.5219 - val_accuracy: 0.9020 - val_loss: 0.3486\n",
      "Epoch 32/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8448 - loss: 0.5196 - val_accuracy: 0.9022 - val_loss: 0.3454\n",
      "Epoch 33/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8471 - loss: 0.5047 - val_accuracy: 0.8953 - val_loss: 0.3636\n",
      "Epoch 34/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.8495 - loss: 0.5061 - val_accuracy: 0.9022 - val_loss: 0.3531\n",
      "Epoch 35/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8537 - loss: 0.5001 - val_accuracy: 0.9022 - val_loss: 0.3463\n",
      "Epoch 36/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8477 - loss: 0.4982 - val_accuracy: 0.9048 - val_loss: 0.3388\n",
      "Epoch 37/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8511 - loss: 0.4930 - val_accuracy: 0.8975 - val_loss: 0.3506\n",
      "Epoch 38/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.8517 - loss: 0.4865 - val_accuracy: 0.9075 - val_loss: 0.3304\n",
      "Epoch 39/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8556 - loss: 0.4815 - val_accuracy: 0.9040 - val_loss: 0.3385\n",
      "Epoch 40/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8544 - loss: 0.4743 - val_accuracy: 0.9109 - val_loss: 0.3150\n",
      "Epoch 41/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8587 - loss: 0.4688 - val_accuracy: 0.9054 - val_loss: 0.3276\n",
      "Epoch 42/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8546 - loss: 0.4799 - val_accuracy: 0.9034 - val_loss: 0.3352\n",
      "Epoch 43/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8612 - loss: 0.4637 - val_accuracy: 0.9052 - val_loss: 0.3329\n",
      "Epoch 44/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8576 - loss: 0.4695 - val_accuracy: 0.8959 - val_loss: 0.3559\n",
      "Epoch 45/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8599 - loss: 0.4610 - val_accuracy: 0.9139 - val_loss: 0.3134\n",
      "Epoch 46/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8624 - loss: 0.4545 - val_accuracy: 0.9081 - val_loss: 0.3175\n",
      "Epoch 47/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.8612 - loss: 0.4606 - val_accuracy: 0.9059 - val_loss: 0.3140\n",
      "Epoch 48/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8633 - loss: 0.4495 - val_accuracy: 0.9113 - val_loss: 0.3173\n",
      "Epoch 49/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.8669 - loss: 0.4440 - val_accuracy: 0.9123 - val_loss: 0.3003\n",
      "Epoch 50/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8646 - loss: 0.4498 - val_accuracy: 0.9087 - val_loss: 0.3125\n",
      "Epoch 51/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8655 - loss: 0.4406 - val_accuracy: 0.9113 - val_loss: 0.3041\n",
      "Epoch 52/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.8630 - loss: 0.4446 - val_accuracy: 0.9024 - val_loss: 0.3157\n",
      "Epoch 53/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.8682 - loss: 0.4261 - val_accuracy: 0.9158 - val_loss: 0.2977\n",
      "Epoch 54/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8650 - loss: 0.4408 - val_accuracy: 0.9180 - val_loss: 0.2989\n",
      "Epoch 55/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8637 - loss: 0.4386 - val_accuracy: 0.9089 - val_loss: 0.3042\n",
      "Epoch 56/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8690 - loss: 0.4285 - val_accuracy: 0.9067 - val_loss: 0.3068\n",
      "Epoch 57/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8683 - loss: 0.4279 - val_accuracy: 0.9150 - val_loss: 0.2982\n",
      "Epoch 58/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.8751 - loss: 0.4134 - val_accuracy: 0.9184 - val_loss: 0.2856\n",
      "Epoch 59/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8676 - loss: 0.4289 - val_accuracy: 0.9218 - val_loss: 0.2817\n",
      "Epoch 60/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8689 - loss: 0.4181 - val_accuracy: 0.9210 - val_loss: 0.2742\n",
      "Epoch 61/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.8700 - loss: 0.4229 - val_accuracy: 0.9052 - val_loss: 0.3117\n",
      "Epoch 62/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8709 - loss: 0.4169 - val_accuracy: 0.9208 - val_loss: 0.2831\n",
      "Epoch 63/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8716 - loss: 0.4153 - val_accuracy: 0.9150 - val_loss: 0.2939\n",
      "Epoch 64/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8748 - loss: 0.4160 - val_accuracy: 0.9190 - val_loss: 0.2793\n",
      "Epoch 65/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8761 - loss: 0.4042 - val_accuracy: 0.9137 - val_loss: 0.2871\n",
      "Epoch 66/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8739 - loss: 0.4087 - val_accuracy: 0.9192 - val_loss: 0.2808\n",
      "Epoch 67/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.8711 - loss: 0.4192 - val_accuracy: 0.9176 - val_loss: 0.2835\n",
      "Epoch 68/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8743 - loss: 0.4032 - val_accuracy: 0.9202 - val_loss: 0.2737\n",
      "Epoch 69/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8768 - loss: 0.3994 - val_accuracy: 0.9168 - val_loss: 0.2847\n",
      "Epoch 70/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.8766 - loss: 0.4041 - val_accuracy: 0.9235 - val_loss: 0.2718\n",
      "Epoch 71/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.8766 - loss: 0.3994 - val_accuracy: 0.9178 - val_loss: 0.2872\n",
      "Epoch 72/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8767 - loss: 0.3928 - val_accuracy: 0.9140 - val_loss: 0.2897\n",
      "Epoch 73/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8745 - loss: 0.3967 - val_accuracy: 0.9212 - val_loss: 0.2716\n",
      "Epoch 74/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.8772 - loss: 0.3977 - val_accuracy: 0.9202 - val_loss: 0.2771\n",
      "Epoch 75/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8767 - loss: 0.3956 - val_accuracy: 0.9214 - val_loss: 0.2676\n",
      "Epoch 76/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8789 - loss: 0.3867 - val_accuracy: 0.9154 - val_loss: 0.2754\n",
      "Epoch 77/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8760 - loss: 0.3938 - val_accuracy: 0.9216 - val_loss: 0.2777\n",
      "Epoch 78/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.8812 - loss: 0.3879 - val_accuracy: 0.9269 - val_loss: 0.2581\n",
      "Epoch 79/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8777 - loss: 0.3934 - val_accuracy: 0.9243 - val_loss: 0.2607\n",
      "Epoch 80/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8818 - loss: 0.3852 - val_accuracy: 0.9212 - val_loss: 0.2717\n",
      "Epoch 81/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8769 - loss: 0.3868 - val_accuracy: 0.9196 - val_loss: 0.2762\n",
      "Epoch 82/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8858 - loss: 0.3704 - val_accuracy: 0.9247 - val_loss: 0.2605\n",
      "Epoch 83/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8806 - loss: 0.3813 - val_accuracy: 0.9223 - val_loss: 0.2646\n",
      "Epoch 84/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.8822 - loss: 0.3765 - val_accuracy: 0.9216 - val_loss: 0.2616\n",
      "Epoch 85/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8844 - loss: 0.3689 - val_accuracy: 0.9216 - val_loss: 0.2625\n",
      "Epoch 86/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8819 - loss: 0.3694 - val_accuracy: 0.9247 - val_loss: 0.2534\n",
      "Epoch 87/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8856 - loss: 0.3659 - val_accuracy: 0.9231 - val_loss: 0.2556\n",
      "Epoch 88/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8828 - loss: 0.3733 - val_accuracy: 0.9198 - val_loss: 0.2646\n",
      "Epoch 89/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8852 - loss: 0.3742 - val_accuracy: 0.9225 - val_loss: 0.2623\n",
      "Epoch 90/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.8832 - loss: 0.3808 - val_accuracy: 0.9253 - val_loss: 0.2557\n",
      "Epoch 91/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.8833 - loss: 0.3750 - val_accuracy: 0.9243 - val_loss: 0.2578\n",
      "Epoch 92/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8885 - loss: 0.3640 - val_accuracy: 0.9231 - val_loss: 0.2608\n",
      "Epoch 93/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8833 - loss: 0.3776 - val_accuracy: 0.9245 - val_loss: 0.2585\n",
      "Epoch 94/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.8894 - loss: 0.3626 - val_accuracy: 0.9229 - val_loss: 0.2519\n",
      "Epoch 95/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8876 - loss: 0.3606 - val_accuracy: 0.9277 - val_loss: 0.2534\n",
      "Epoch 96/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.8892 - loss: 0.3651 - val_accuracy: 0.9210 - val_loss: 0.2595\n",
      "Epoch 97/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.8840 - loss: 0.3727 - val_accuracy: 0.9273 - val_loss: 0.2501\n",
      "Epoch 98/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8871 - loss: 0.3665 - val_accuracy: 0.9241 - val_loss: 0.2538\n",
      "Epoch 99/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8865 - loss: 0.3613 - val_accuracy: 0.9229 - val_loss: 0.2647\n",
      "Epoch 100/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8821 - loss: 0.3747 - val_accuracy: 0.9249 - val_loss: 0.2499\n",
      "Epoch 101/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8896 - loss: 0.3568 - val_accuracy: 0.9257 - val_loss: 0.2508\n",
      "Epoch 102/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8884 - loss: 0.3532 - val_accuracy: 0.9172 - val_loss: 0.2733\n",
      "Epoch 103/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8871 - loss: 0.3622 - val_accuracy: 0.9265 - val_loss: 0.2450\n",
      "Epoch 104/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.8893 - loss: 0.3559 - val_accuracy: 0.9229 - val_loss: 0.2592\n",
      "Epoch 105/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8888 - loss: 0.3609 - val_accuracy: 0.9229 - val_loss: 0.2674\n",
      "Epoch 106/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8896 - loss: 0.3534 - val_accuracy: 0.9243 - val_loss: 0.2549\n",
      "Epoch 107/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8883 - loss: 0.3543 - val_accuracy: 0.9231 - val_loss: 0.2559\n",
      "Epoch 108/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8894 - loss: 0.3497 - val_accuracy: 0.9249 - val_loss: 0.2517\n",
      "Epoch 109/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8864 - loss: 0.3552 - val_accuracy: 0.9295 - val_loss: 0.2510\n",
      "Epoch 110/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8900 - loss: 0.3524 - val_accuracy: 0.9257 - val_loss: 0.2539\n",
      "Epoch 111/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8879 - loss: 0.3540 - val_accuracy: 0.9283 - val_loss: 0.2454\n",
      "Epoch 112/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.8874 - loss: 0.3539 - val_accuracy: 0.9251 - val_loss: 0.2566\n",
      "Epoch 113/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8883 - loss: 0.3544 - val_accuracy: 0.9231 - val_loss: 0.2574\n",
      "Epoch 114/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.8919 - loss: 0.3444 - val_accuracy: 0.9267 - val_loss: 0.2488\n",
      "Epoch 115/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.8870 - loss: 0.3591 - val_accuracy: 0.9233 - val_loss: 0.2607\n",
      "Epoch 116/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.8892 - loss: 0.3548 - val_accuracy: 0.9263 - val_loss: 0.2486\n",
      "Epoch 117/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8937 - loss: 0.3504 - val_accuracy: 0.9297 - val_loss: 0.2410\n",
      "Epoch 118/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8875 - loss: 0.3606 - val_accuracy: 0.9301 - val_loss: 0.2377\n",
      "Epoch 119/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8916 - loss: 0.3482 - val_accuracy: 0.9247 - val_loss: 0.2467\n",
      "Epoch 120/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8915 - loss: 0.3428 - val_accuracy: 0.9283 - val_loss: 0.2404\n",
      "Epoch 121/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8908 - loss: 0.3503 - val_accuracy: 0.9263 - val_loss: 0.2442\n",
      "Epoch 122/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8955 - loss: 0.3360 - val_accuracy: 0.9261 - val_loss: 0.2445\n",
      "Epoch 123/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8890 - loss: 0.3507 - val_accuracy: 0.9241 - val_loss: 0.2581\n",
      "Epoch 124/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8887 - loss: 0.3520 - val_accuracy: 0.9324 - val_loss: 0.2452\n",
      "Epoch 125/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8935 - loss: 0.3374 - val_accuracy: 0.9271 - val_loss: 0.2530\n",
      "Epoch 126/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.8929 - loss: 0.3404 - val_accuracy: 0.9289 - val_loss: 0.2451\n",
      "Epoch 127/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8934 - loss: 0.3483 - val_accuracy: 0.9279 - val_loss: 0.2372\n",
      "Epoch 128/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8926 - loss: 0.3358 - val_accuracy: 0.9253 - val_loss: 0.2455\n",
      "Epoch 129/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8939 - loss: 0.3348 - val_accuracy: 0.9273 - val_loss: 0.2518\n",
      "Epoch 130/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8967 - loss: 0.3343 - val_accuracy: 0.9287 - val_loss: 0.2442\n",
      "Epoch 131/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8952 - loss: 0.3384 - val_accuracy: 0.9194 - val_loss: 0.2538\n",
      "Epoch 132/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8931 - loss: 0.3357 - val_accuracy: 0.9229 - val_loss: 0.2606\n",
      "Epoch 133/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8924 - loss: 0.3450 - val_accuracy: 0.9297 - val_loss: 0.2341\n",
      "Epoch 134/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8933 - loss: 0.3382 - val_accuracy: 0.9293 - val_loss: 0.2415\n",
      "Epoch 135/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8942 - loss: 0.3297 - val_accuracy: 0.9285 - val_loss: 0.2405\n",
      "Epoch 136/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8945 - loss: 0.3382 - val_accuracy: 0.9306 - val_loss: 0.2335\n",
      "Epoch 137/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.8976 - loss: 0.3270 - val_accuracy: 0.9275 - val_loss: 0.2362\n",
      "Epoch 138/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9009 - loss: 0.3201 - val_accuracy: 0.9295 - val_loss: 0.2415\n",
      "Epoch 139/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8944 - loss: 0.3352 - val_accuracy: 0.9285 - val_loss: 0.2362\n",
      "Epoch 140/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8915 - loss: 0.3371 - val_accuracy: 0.9301 - val_loss: 0.2319\n",
      "Epoch 141/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8956 - loss: 0.3295 - val_accuracy: 0.9320 - val_loss: 0.2304\n",
      "Epoch 142/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.8965 - loss: 0.3289 - val_accuracy: 0.9301 - val_loss: 0.2344\n",
      "Epoch 143/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8974 - loss: 0.3354 - val_accuracy: 0.9314 - val_loss: 0.2366\n",
      "Epoch 144/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8939 - loss: 0.3284 - val_accuracy: 0.9277 - val_loss: 0.2428\n",
      "Epoch 145/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.8993 - loss: 0.3208 - val_accuracy: 0.9318 - val_loss: 0.2412\n",
      "Epoch 146/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8960 - loss: 0.3314 - val_accuracy: 0.9243 - val_loss: 0.2462\n",
      "Epoch 147/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8968 - loss: 0.3316 - val_accuracy: 0.9338 - val_loss: 0.2353\n",
      "Epoch 148/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.8995 - loss: 0.3199 - val_accuracy: 0.9306 - val_loss: 0.2381\n",
      "Epoch 149/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8972 - loss: 0.3263 - val_accuracy: 0.9334 - val_loss: 0.2339\n",
      "Epoch 150/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8964 - loss: 0.3236 - val_accuracy: 0.9218 - val_loss: 0.2613\n",
      "Epoch 151/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.8921 - loss: 0.3379 - val_accuracy: 0.9299 - val_loss: 0.2426\n",
      "Epoch 152/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8981 - loss: 0.3255 - val_accuracy: 0.9332 - val_loss: 0.2349\n",
      "Epoch 153/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8971 - loss: 0.3233 - val_accuracy: 0.9312 - val_loss: 0.2360\n",
      "Epoch 154/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9008 - loss: 0.3164 - val_accuracy: 0.9308 - val_loss: 0.2372\n",
      "Epoch 155/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8977 - loss: 0.3273 - val_accuracy: 0.9320 - val_loss: 0.2355\n",
      "Epoch 156/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8962 - loss: 0.3239 - val_accuracy: 0.9303 - val_loss: 0.2355\n",
      "Epoch 157/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9003 - loss: 0.3191 - val_accuracy: 0.9304 - val_loss: 0.2364\n",
      "Epoch 158/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.8994 - loss: 0.3200 - val_accuracy: 0.9330 - val_loss: 0.2240\n",
      "Epoch 159/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.8982 - loss: 0.3203 - val_accuracy: 0.9275 - val_loss: 0.2410\n",
      "Epoch 160/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.8984 - loss: 0.3182 - val_accuracy: 0.9308 - val_loss: 0.2407\n",
      "Epoch 161/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9016 - loss: 0.3162 - val_accuracy: 0.9324 - val_loss: 0.2340\n",
      "Epoch 162/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9003 - loss: 0.3180 - val_accuracy: 0.9301 - val_loss: 0.2311\n",
      "Epoch 163/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.8968 - loss: 0.3183 - val_accuracy: 0.9293 - val_loss: 0.2319\n",
      "Epoch 164/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9014 - loss: 0.3113 - val_accuracy: 0.9310 - val_loss: 0.2234\n",
      "Epoch 165/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8973 - loss: 0.3271 - val_accuracy: 0.9324 - val_loss: 0.2297\n",
      "Epoch 166/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.8976 - loss: 0.3192 - val_accuracy: 0.9269 - val_loss: 0.2393\n",
      "Epoch 167/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8957 - loss: 0.3237 - val_accuracy: 0.9291 - val_loss: 0.2287\n",
      "Epoch 168/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9011 - loss: 0.3224 - val_accuracy: 0.9326 - val_loss: 0.2266\n",
      "Epoch 169/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9017 - loss: 0.3149 - val_accuracy: 0.9322 - val_loss: 0.2280\n",
      "Epoch 170/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9033 - loss: 0.3078 - val_accuracy: 0.9269 - val_loss: 0.2340\n",
      "Epoch 171/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8988 - loss: 0.3210 - val_accuracy: 0.9297 - val_loss: 0.2316\n",
      "Epoch 172/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8995 - loss: 0.3201 - val_accuracy: 0.9316 - val_loss: 0.2340\n",
      "Epoch 173/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9001 - loss: 0.3110 - val_accuracy: 0.9304 - val_loss: 0.2319\n",
      "Epoch 174/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9018 - loss: 0.3112 - val_accuracy: 0.9314 - val_loss: 0.2260\n",
      "Epoch 175/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9027 - loss: 0.3080 - val_accuracy: 0.9318 - val_loss: 0.2355\n",
      "Epoch 176/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9002 - loss: 0.3161 - val_accuracy: 0.9330 - val_loss: 0.2288\n",
      "Epoch 177/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8999 - loss: 0.3114 - val_accuracy: 0.9312 - val_loss: 0.2301\n",
      "Epoch 178/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9008 - loss: 0.3095 - val_accuracy: 0.9299 - val_loss: 0.2300\n",
      "Epoch 179/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9003 - loss: 0.3107 - val_accuracy: 0.9297 - val_loss: 0.2384\n",
      "Epoch 180/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9013 - loss: 0.3129 - val_accuracy: 0.9308 - val_loss: 0.2308\n",
      "Epoch 181/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.8976 - loss: 0.3284 - val_accuracy: 0.9322 - val_loss: 0.2374\n",
      "Epoch 182/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9004 - loss: 0.3150 - val_accuracy: 0.9255 - val_loss: 0.2440\n",
      "Epoch 183/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9034 - loss: 0.3042 - val_accuracy: 0.9332 - val_loss: 0.2180\n",
      "Epoch 184/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9033 - loss: 0.3054 - val_accuracy: 0.9324 - val_loss: 0.2294\n",
      "Epoch 185/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.8998 - loss: 0.3110 - val_accuracy: 0.9326 - val_loss: 0.2290\n",
      "Epoch 186/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9015 - loss: 0.3128 - val_accuracy: 0.9378 - val_loss: 0.2171\n",
      "Epoch 187/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9032 - loss: 0.3083 - val_accuracy: 0.9312 - val_loss: 0.2249\n",
      "Epoch 188/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9000 - loss: 0.3152 - val_accuracy: 0.9279 - val_loss: 0.2332\n",
      "Epoch 189/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9009 - loss: 0.3120 - val_accuracy: 0.9314 - val_loss: 0.2267\n",
      "Epoch 190/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.8986 - loss: 0.3143 - val_accuracy: 0.9308 - val_loss: 0.2347\n",
      "Epoch 191/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9034 - loss: 0.3096 - val_accuracy: 0.9330 - val_loss: 0.2261\n",
      "Epoch 192/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.3125 - val_accuracy: 0.9304 - val_loss: 0.2410\n",
      "Epoch 193/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9047 - loss: 0.3021 - val_accuracy: 0.9318 - val_loss: 0.2316\n",
      "Epoch 194/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.9028 - loss: 0.3074 - val_accuracy: 0.9287 - val_loss: 0.2335\n",
      "Epoch 195/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9035 - loss: 0.3016 - val_accuracy: 0.9332 - val_loss: 0.2245\n",
      "Epoch 196/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9029 - loss: 0.3090 - val_accuracy: 0.9332 - val_loss: 0.2275\n",
      "Epoch 197/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9068 - loss: 0.2995 - val_accuracy: 0.9316 - val_loss: 0.2288\n",
      "Epoch 198/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9028 - loss: 0.3044 - val_accuracy: 0.9261 - val_loss: 0.2282\n",
      "Epoch 199/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9052 - loss: 0.3000 - val_accuracy: 0.9297 - val_loss: 0.2319\n",
      "Epoch 200/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9048 - loss: 0.2963 - val_accuracy: 0.9277 - val_loss: 0.2344\n",
      "Epoch 201/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9033 - loss: 0.3075 - val_accuracy: 0.9354 - val_loss: 0.2201\n",
      "Epoch 202/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9010 - loss: 0.3042 - val_accuracy: 0.9358 - val_loss: 0.2278\n",
      "Epoch 203/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9051 - loss: 0.2970 - val_accuracy: 0.9273 - val_loss: 0.2301\n",
      "Epoch 204/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9036 - loss: 0.3040 - val_accuracy: 0.9324 - val_loss: 0.2257\n",
      "Epoch 205/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9035 - loss: 0.3036 - val_accuracy: 0.9336 - val_loss: 0.2235\n",
      "Epoch 206/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9058 - loss: 0.2965 - val_accuracy: 0.9342 - val_loss: 0.2209\n",
      "Epoch 207/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9068 - loss: 0.3012 - val_accuracy: 0.9358 - val_loss: 0.2243\n",
      "Epoch 208/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9043 - loss: 0.2984 - val_accuracy: 0.9322 - val_loss: 0.2292\n",
      "Epoch 209/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9068 - loss: 0.2967 - val_accuracy: 0.9338 - val_loss: 0.2277\n",
      "Epoch 210/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9070 - loss: 0.2974 - val_accuracy: 0.9338 - val_loss: 0.2240\n",
      "Epoch 211/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9055 - loss: 0.2896 - val_accuracy: 0.9352 - val_loss: 0.2244\n",
      "Epoch 212/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9065 - loss: 0.2964 - val_accuracy: 0.9352 - val_loss: 0.2206\n",
      "Epoch 213/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9027 - loss: 0.2989 - val_accuracy: 0.9344 - val_loss: 0.2307\n",
      "Epoch 214/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9047 - loss: 0.2930 - val_accuracy: 0.9334 - val_loss: 0.2299\n",
      "Epoch 215/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9035 - loss: 0.3065 - val_accuracy: 0.9340 - val_loss: 0.2308\n",
      "Epoch 216/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9045 - loss: 0.3049 - val_accuracy: 0.9330 - val_loss: 0.2290\n",
      "Epoch 217/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9054 - loss: 0.3000 - val_accuracy: 0.9316 - val_loss: 0.2273\n",
      "Epoch 218/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9057 - loss: 0.2958 - val_accuracy: 0.9287 - val_loss: 0.2345\n",
      "Epoch 219/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9052 - loss: 0.2969 - val_accuracy: 0.9291 - val_loss: 0.2338\n",
      "Epoch 220/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9078 - loss: 0.2898 - val_accuracy: 0.9303 - val_loss: 0.2328\n",
      "Epoch 221/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9070 - loss: 0.2947 - val_accuracy: 0.9336 - val_loss: 0.2306\n",
      "Epoch 222/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9071 - loss: 0.2879 - val_accuracy: 0.9346 - val_loss: 0.2292\n",
      "Epoch 223/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9085 - loss: 0.2935 - val_accuracy: 0.9348 - val_loss: 0.2235\n",
      "Epoch 224/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.9010 - loss: 0.3039 - val_accuracy: 0.9340 - val_loss: 0.2287\n",
      "Epoch 225/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9077 - loss: 0.2919 - val_accuracy: 0.9285 - val_loss: 0.2366\n",
      "Epoch 226/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9052 - loss: 0.2977 - val_accuracy: 0.9372 - val_loss: 0.2199\n",
      "Epoch 227/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9045 - loss: 0.2990 - val_accuracy: 0.9352 - val_loss: 0.2217\n",
      "Epoch 228/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9080 - loss: 0.2882 - val_accuracy: 0.9372 - val_loss: 0.2161\n",
      "Epoch 229/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9077 - loss: 0.2937 - val_accuracy: 0.9356 - val_loss: 0.2214\n",
      "Epoch 230/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9047 - loss: 0.2966 - val_accuracy: 0.9304 - val_loss: 0.2291\n",
      "Epoch 231/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9060 - loss: 0.2936 - val_accuracy: 0.9340 - val_loss: 0.2227\n",
      "Epoch 232/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9076 - loss: 0.2928 - val_accuracy: 0.9352 - val_loss: 0.2229\n",
      "Epoch 233/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9115 - loss: 0.2874 - val_accuracy: 0.9352 - val_loss: 0.2158\n",
      "Epoch 234/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9061 - loss: 0.2979 - val_accuracy: 0.9301 - val_loss: 0.2240\n",
      "Epoch 235/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9084 - loss: 0.2845 - val_accuracy: 0.9348 - val_loss: 0.2207\n",
      "Epoch 236/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9060 - loss: 0.2929 - val_accuracy: 0.9354 - val_loss: 0.2230\n",
      "Epoch 237/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9048 - loss: 0.2990 - val_accuracy: 0.9299 - val_loss: 0.2270\n",
      "Epoch 238/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9043 - loss: 0.3029 - val_accuracy: 0.9314 - val_loss: 0.2290\n",
      "Epoch 239/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.9073 - loss: 0.2911 - val_accuracy: 0.9364 - val_loss: 0.2162\n",
      "Epoch 240/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9083 - loss: 0.2895 - val_accuracy: 0.9316 - val_loss: 0.2227\n",
      "Epoch 241/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9074 - loss: 0.2906 - val_accuracy: 0.9336 - val_loss: 0.2192\n",
      "Epoch 242/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9050 - loss: 0.3010 - val_accuracy: 0.9348 - val_loss: 0.2225\n",
      "Epoch 243/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9089 - loss: 0.2869 - val_accuracy: 0.9370 - val_loss: 0.2154\n",
      "Epoch 244/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9083 - loss: 0.2824 - val_accuracy: 0.9350 - val_loss: 0.2199\n",
      "Epoch 245/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9047 - loss: 0.3018 - val_accuracy: 0.9332 - val_loss: 0.2238\n",
      "Epoch 246/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9086 - loss: 0.2832 - val_accuracy: 0.9314 - val_loss: 0.2276\n",
      "Epoch 247/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9095 - loss: 0.2804 - val_accuracy: 0.9328 - val_loss: 0.2195\n",
      "Epoch 248/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9081 - loss: 0.2844 - val_accuracy: 0.9336 - val_loss: 0.2208\n",
      "Epoch 249/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9093 - loss: 0.2821 - val_accuracy: 0.9322 - val_loss: 0.2211\n",
      "Epoch 250/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9077 - loss: 0.2926 - val_accuracy: 0.9362 - val_loss: 0.2164\n",
      "Epoch 251/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9108 - loss: 0.2857 - val_accuracy: 0.9352 - val_loss: 0.2271\n",
      "Epoch 252/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9072 - loss: 0.2935 - val_accuracy: 0.9358 - val_loss: 0.2218\n",
      "Epoch 253/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.9065 - loss: 0.2897 - val_accuracy: 0.9352 - val_loss: 0.2136\n",
      "Epoch 254/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.9098 - loss: 0.2827 - val_accuracy: 0.9322 - val_loss: 0.2262\n",
      "Epoch 255/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9078 - loss: 0.2856 - val_accuracy: 0.9385 - val_loss: 0.2113\n",
      "Epoch 256/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9096 - loss: 0.2957 - val_accuracy: 0.9344 - val_loss: 0.2203\n",
      "Epoch 257/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9103 - loss: 0.2791 - val_accuracy: 0.9380 - val_loss: 0.2198\n",
      "Epoch 258/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9093 - loss: 0.2916 - val_accuracy: 0.9348 - val_loss: 0.2271\n",
      "Epoch 259/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9084 - loss: 0.2781 - val_accuracy: 0.9372 - val_loss: 0.2190\n",
      "Epoch 260/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9098 - loss: 0.2859 - val_accuracy: 0.9368 - val_loss: 0.2144\n",
      "Epoch 261/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9117 - loss: 0.2703 - val_accuracy: 0.9348 - val_loss: 0.2187\n",
      "Epoch 262/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9097 - loss: 0.2837 - val_accuracy: 0.9354 - val_loss: 0.2219\n",
      "Epoch 263/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9094 - loss: 0.2895 - val_accuracy: 0.9380 - val_loss: 0.2141\n",
      "Epoch 264/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9072 - loss: 0.2885 - val_accuracy: 0.9348 - val_loss: 0.2253\n",
      "Epoch 265/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9093 - loss: 0.2812 - val_accuracy: 0.9385 - val_loss: 0.2218\n",
      "Epoch 266/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9129 - loss: 0.2775 - val_accuracy: 0.9370 - val_loss: 0.2150\n",
      "Epoch 267/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9119 - loss: 0.2818 - val_accuracy: 0.9376 - val_loss: 0.2183\n",
      "Epoch 268/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.9100 - loss: 0.2890 - val_accuracy: 0.9348 - val_loss: 0.2230\n",
      "Epoch 269/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9102 - loss: 0.2762 - val_accuracy: 0.9354 - val_loss: 0.2146\n",
      "Epoch 270/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9153 - loss: 0.2632 - val_accuracy: 0.9348 - val_loss: 0.2243\n",
      "Epoch 271/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9117 - loss: 0.2873 - val_accuracy: 0.9318 - val_loss: 0.2216\n",
      "Epoch 272/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9107 - loss: 0.2830 - val_accuracy: 0.9368 - val_loss: 0.2176\n",
      "Epoch 273/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9120 - loss: 0.2865 - val_accuracy: 0.9380 - val_loss: 0.2192\n",
      "Epoch 274/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9104 - loss: 0.2815 - val_accuracy: 0.9370 - val_loss: 0.2205\n",
      "Epoch 275/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9152 - loss: 0.2680 - val_accuracy: 0.9358 - val_loss: 0.2109\n",
      "Epoch 276/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9122 - loss: 0.2799 - val_accuracy: 0.9314 - val_loss: 0.2298\n",
      "Epoch 277/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9083 - loss: 0.2810 - val_accuracy: 0.9338 - val_loss: 0.2268\n",
      "Epoch 278/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9118 - loss: 0.2820 - val_accuracy: 0.9376 - val_loss: 0.2158\n",
      "Epoch 279/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9095 - loss: 0.2773 - val_accuracy: 0.9385 - val_loss: 0.2214\n",
      "Epoch 280/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9103 - loss: 0.2820 - val_accuracy: 0.9356 - val_loss: 0.2352\n",
      "Epoch 281/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9082 - loss: 0.2821 - val_accuracy: 0.9342 - val_loss: 0.2308\n",
      "Epoch 282/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9135 - loss: 0.2713 - val_accuracy: 0.9360 - val_loss: 0.2237\n",
      "Epoch 283/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9113 - loss: 0.2854 - val_accuracy: 0.9384 - val_loss: 0.2168\n",
      "Epoch 284/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9148 - loss: 0.2614 - val_accuracy: 0.9443 - val_loss: 0.2095\n",
      "Epoch 285/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9105 - loss: 0.2763 - val_accuracy: 0.9372 - val_loss: 0.2181\n",
      "Epoch 286/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9108 - loss: 0.2806 - val_accuracy: 0.9370 - val_loss: 0.2133\n",
      "Epoch 287/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9106 - loss: 0.2754 - val_accuracy: 0.9338 - val_loss: 0.2264\n",
      "Epoch 288/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9052 - loss: 0.2918 - val_accuracy: 0.9415 - val_loss: 0.2137\n",
      "Epoch 289/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9128 - loss: 0.2726 - val_accuracy: 0.9348 - val_loss: 0.2248\n",
      "Epoch 290/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9142 - loss: 0.2692 - val_accuracy: 0.9376 - val_loss: 0.2215\n",
      "Epoch 291/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9134 - loss: 0.2722 - val_accuracy: 0.9385 - val_loss: 0.2152\n",
      "Epoch 292/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9098 - loss: 0.2839 - val_accuracy: 0.9368 - val_loss: 0.2287\n",
      "Epoch 293/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9098 - loss: 0.2781 - val_accuracy: 0.9350 - val_loss: 0.2247\n",
      "Epoch 294/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9125 - loss: 0.2755 - val_accuracy: 0.9370 - val_loss: 0.2195\n",
      "Epoch 295/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9103 - loss: 0.2874 - val_accuracy: 0.9397 - val_loss: 0.2138\n",
      "Epoch 296/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9132 - loss: 0.2745 - val_accuracy: 0.9364 - val_loss: 0.2123\n",
      "Epoch 297/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9101 - loss: 0.2856 - val_accuracy: 0.9364 - val_loss: 0.2156\n",
      "Epoch 298/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9119 - loss: 0.2775 - val_accuracy: 0.9389 - val_loss: 0.2120\n",
      "Epoch 299/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9163 - loss: 0.2657 - val_accuracy: 0.9384 - val_loss: 0.2149\n",
      "Epoch 300/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9126 - loss: 0.2705 - val_accuracy: 0.9395 - val_loss: 0.2143\n",
      "Epoch 301/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9106 - loss: 0.2802 - val_accuracy: 0.9372 - val_loss: 0.2112\n",
      "Epoch 302/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9143 - loss: 0.2730 - val_accuracy: 0.9391 - val_loss: 0.2050\n",
      "Epoch 303/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9120 - loss: 0.2688 - val_accuracy: 0.9376 - val_loss: 0.2123\n",
      "Epoch 304/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9144 - loss: 0.2612 - val_accuracy: 0.9397 - val_loss: 0.2131\n",
      "Epoch 305/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9114 - loss: 0.2761 - val_accuracy: 0.9376 - val_loss: 0.2266\n",
      "Epoch 306/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9127 - loss: 0.2688 - val_accuracy: 0.9326 - val_loss: 0.2230\n",
      "Epoch 307/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9076 - loss: 0.2830 - val_accuracy: 0.9372 - val_loss: 0.2152\n",
      "Epoch 308/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9136 - loss: 0.2680 - val_accuracy: 0.9356 - val_loss: 0.2165\n",
      "Epoch 309/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9108 - loss: 0.2741 - val_accuracy: 0.9326 - val_loss: 0.2276\n",
      "Epoch 310/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9114 - loss: 0.2857 - val_accuracy: 0.9370 - val_loss: 0.2162\n",
      "Epoch 311/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9128 - loss: 0.2751 - val_accuracy: 0.9397 - val_loss: 0.2133\n",
      "Epoch 312/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9154 - loss: 0.2641 - val_accuracy: 0.9378 - val_loss: 0.2193\n",
      "Epoch 313/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9128 - loss: 0.2712 - val_accuracy: 0.9399 - val_loss: 0.2101\n",
      "Epoch 314/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9107 - loss: 0.2786 - val_accuracy: 0.9350 - val_loss: 0.2174\n",
      "Epoch 315/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9117 - loss: 0.2671 - val_accuracy: 0.9395 - val_loss: 0.2102\n",
      "Epoch 316/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9128 - loss: 0.2753 - val_accuracy: 0.9352 - val_loss: 0.2149\n",
      "Epoch 317/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9128 - loss: 0.2729 - val_accuracy: 0.9384 - val_loss: 0.2089\n",
      "Epoch 318/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9124 - loss: 0.2753 - val_accuracy: 0.9362 - val_loss: 0.2145\n",
      "Epoch 319/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9155 - loss: 0.2603 - val_accuracy: 0.9431 - val_loss: 0.1994\n",
      "Epoch 320/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9128 - loss: 0.2760 - val_accuracy: 0.9391 - val_loss: 0.2142\n",
      "Epoch 321/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9115 - loss: 0.2758 - val_accuracy: 0.9387 - val_loss: 0.2131\n",
      "Epoch 322/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9117 - loss: 0.2765 - val_accuracy: 0.9358 - val_loss: 0.2222\n",
      "Epoch 323/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9129 - loss: 0.2785 - val_accuracy: 0.9409 - val_loss: 0.2112\n",
      "Epoch 324/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9137 - loss: 0.2685 - val_accuracy: 0.9378 - val_loss: 0.2102\n",
      "Epoch 325/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9140 - loss: 0.2689 - val_accuracy: 0.9334 - val_loss: 0.2249\n",
      "Epoch 326/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9174 - loss: 0.2659 - val_accuracy: 0.9372 - val_loss: 0.2064\n",
      "Epoch 327/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9136 - loss: 0.2674 - val_accuracy: 0.9385 - val_loss: 0.2143\n",
      "Epoch 328/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9125 - loss: 0.2826 - val_accuracy: 0.9376 - val_loss: 0.2172\n",
      "Epoch 329/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9156 - loss: 0.2718 - val_accuracy: 0.9360 - val_loss: 0.2239\n",
      "Epoch 330/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9159 - loss: 0.2640 - val_accuracy: 0.9417 - val_loss: 0.2094\n",
      "Epoch 331/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9151 - loss: 0.2666 - val_accuracy: 0.9356 - val_loss: 0.2220\n",
      "Epoch 332/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9112 - loss: 0.2773 - val_accuracy: 0.9342 - val_loss: 0.2193\n",
      "Epoch 333/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9130 - loss: 0.2725 - val_accuracy: 0.9374 - val_loss: 0.2161\n",
      "Epoch 334/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9140 - loss: 0.2663 - val_accuracy: 0.9378 - val_loss: 0.2107\n",
      "Epoch 335/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9127 - loss: 0.2788 - val_accuracy: 0.9360 - val_loss: 0.2151\n",
      "Epoch 336/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9117 - loss: 0.2768 - val_accuracy: 0.9360 - val_loss: 0.2145\n",
      "Epoch 337/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9151 - loss: 0.2675 - val_accuracy: 0.9326 - val_loss: 0.2340\n",
      "Epoch 338/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9167 - loss: 0.2570 - val_accuracy: 0.9368 - val_loss: 0.2139\n",
      "Epoch 339/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9129 - loss: 0.2736 - val_accuracy: 0.9348 - val_loss: 0.2202\n",
      "Epoch 340/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9143 - loss: 0.2672 - val_accuracy: 0.9372 - val_loss: 0.2075\n",
      "Epoch 341/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9140 - loss: 0.2736 - val_accuracy: 0.9374 - val_loss: 0.2131\n",
      "Epoch 342/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9151 - loss: 0.2682 - val_accuracy: 0.9330 - val_loss: 0.2149\n",
      "Epoch 343/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9155 - loss: 0.2652 - val_accuracy: 0.9368 - val_loss: 0.2032\n",
      "Epoch 344/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9116 - loss: 0.2727 - val_accuracy: 0.9346 - val_loss: 0.2141\n",
      "Epoch 345/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9149 - loss: 0.2635 - val_accuracy: 0.9391 - val_loss: 0.2146\n",
      "Epoch 346/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9167 - loss: 0.2583 - val_accuracy: 0.9395 - val_loss: 0.2111\n",
      "Epoch 347/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9155 - loss: 0.2619 - val_accuracy: 0.9391 - val_loss: 0.2106\n",
      "Epoch 348/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9163 - loss: 0.2608 - val_accuracy: 0.9368 - val_loss: 0.2119\n",
      "Epoch 349/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9175 - loss: 0.2607 - val_accuracy: 0.9370 - val_loss: 0.2195\n",
      "Epoch 350/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9137 - loss: 0.2683 - val_accuracy: 0.9372 - val_loss: 0.2236\n",
      "Epoch 351/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9140 - loss: 0.2703 - val_accuracy: 0.9376 - val_loss: 0.2213\n",
      "Epoch 352/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9151 - loss: 0.2693 - val_accuracy: 0.9399 - val_loss: 0.2070\n",
      "Epoch 353/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9169 - loss: 0.2582 - val_accuracy: 0.9393 - val_loss: 0.2053\n",
      "Epoch 354/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9141 - loss: 0.2660 - val_accuracy: 0.9356 - val_loss: 0.2152\n",
      "Epoch 355/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9149 - loss: 0.2697 - val_accuracy: 0.9415 - val_loss: 0.2068\n",
      "Epoch 356/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9157 - loss: 0.2657 - val_accuracy: 0.9380 - val_loss: 0.2142\n",
      "Epoch 357/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9180 - loss: 0.2638 - val_accuracy: 0.9376 - val_loss: 0.2090\n",
      "Epoch 358/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9141 - loss: 0.2703 - val_accuracy: 0.9403 - val_loss: 0.2127\n",
      "Epoch 359/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9165 - loss: 0.2597 - val_accuracy: 0.9421 - val_loss: 0.2099\n",
      "Epoch 360/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9170 - loss: 0.2605 - val_accuracy: 0.9376 - val_loss: 0.2181\n",
      "Epoch 361/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9187 - loss: 0.2519 - val_accuracy: 0.9360 - val_loss: 0.2167\n",
      "Epoch 362/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9144 - loss: 0.2699 - val_accuracy: 0.9405 - val_loss: 0.2035\n",
      "Epoch 363/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.9186 - loss: 0.2545 - val_accuracy: 0.9389 - val_loss: 0.2146\n",
      "Epoch 364/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9187 - loss: 0.2625 - val_accuracy: 0.9385 - val_loss: 0.2062\n",
      "Epoch 365/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9167 - loss: 0.2528 - val_accuracy: 0.9385 - val_loss: 0.2095\n",
      "Epoch 366/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9132 - loss: 0.2710 - val_accuracy: 0.9405 - val_loss: 0.2096\n",
      "Epoch 367/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9152 - loss: 0.2599 - val_accuracy: 0.9403 - val_loss: 0.2118\n",
      "Epoch 368/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9159 - loss: 0.2609 - val_accuracy: 0.9385 - val_loss: 0.2137\n",
      "Epoch 369/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9178 - loss: 0.2622 - val_accuracy: 0.9385 - val_loss: 0.2105\n",
      "Epoch 370/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9161 - loss: 0.2628 - val_accuracy: 0.9346 - val_loss: 0.2139\n",
      "Epoch 371/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.9142 - loss: 0.2628 - val_accuracy: 0.9354 - val_loss: 0.2078\n",
      "Epoch 372/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9166 - loss: 0.2608 - val_accuracy: 0.9368 - val_loss: 0.2128\n",
      "Epoch 373/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9152 - loss: 0.2618 - val_accuracy: 0.9385 - val_loss: 0.2180\n",
      "Epoch 374/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9167 - loss: 0.2616 - val_accuracy: 0.9419 - val_loss: 0.2057\n",
      "Epoch 375/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9161 - loss: 0.2617 - val_accuracy: 0.9407 - val_loss: 0.2063\n",
      "Epoch 376/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9178 - loss: 0.2584 - val_accuracy: 0.9389 - val_loss: 0.2045\n",
      "Epoch 377/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9159 - loss: 0.2682 - val_accuracy: 0.9387 - val_loss: 0.2104\n",
      "Epoch 378/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9162 - loss: 0.2611 - val_accuracy: 0.9376 - val_loss: 0.2131\n",
      "Epoch 379/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9182 - loss: 0.2516 - val_accuracy: 0.9374 - val_loss: 0.2122\n",
      "Epoch 380/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9169 - loss: 0.2612 - val_accuracy: 0.9387 - val_loss: 0.2116\n",
      "Epoch 381/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9172 - loss: 0.2638 - val_accuracy: 0.9387 - val_loss: 0.2094\n",
      "Epoch 382/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9180 - loss: 0.2564 - val_accuracy: 0.9368 - val_loss: 0.2112\n",
      "Epoch 383/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9154 - loss: 0.2572 - val_accuracy: 0.9405 - val_loss: 0.2121\n",
      "Epoch 384/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9166 - loss: 0.2601 - val_accuracy: 0.9352 - val_loss: 0.2243\n",
      "Epoch 385/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9185 - loss: 0.2620 - val_accuracy: 0.9427 - val_loss: 0.2064\n",
      "Epoch 386/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9165 - loss: 0.2631 - val_accuracy: 0.9368 - val_loss: 0.2173\n",
      "Epoch 387/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9126 - loss: 0.2679 - val_accuracy: 0.9435 - val_loss: 0.2065\n",
      "Epoch 388/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9184 - loss: 0.2574 - val_accuracy: 0.9391 - val_loss: 0.2093\n",
      "Epoch 389/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9170 - loss: 0.2554 - val_accuracy: 0.9405 - val_loss: 0.2091\n",
      "Epoch 390/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9200 - loss: 0.2564 - val_accuracy: 0.9419 - val_loss: 0.2053\n",
      "Epoch 391/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9180 - loss: 0.2565 - val_accuracy: 0.9393 - val_loss: 0.2129\n",
      "Epoch 392/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9139 - loss: 0.2682 - val_accuracy: 0.9387 - val_loss: 0.2125\n",
      "Epoch 393/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9202 - loss: 0.2550 - val_accuracy: 0.9409 - val_loss: 0.2018\n",
      "Epoch 394/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9185 - loss: 0.2582 - val_accuracy: 0.9403 - val_loss: 0.2049\n",
      "Epoch 395/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9200 - loss: 0.2524 - val_accuracy: 0.9387 - val_loss: 0.2123\n",
      "Epoch 396/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9190 - loss: 0.2581 - val_accuracy: 0.9399 - val_loss: 0.2072\n",
      "Epoch 397/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9174 - loss: 0.2623 - val_accuracy: 0.9368 - val_loss: 0.2213\n",
      "Epoch 398/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9204 - loss: 0.2542 - val_accuracy: 0.9378 - val_loss: 0.2083\n",
      "Epoch 399/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9177 - loss: 0.2575 - val_accuracy: 0.9391 - val_loss: 0.2070\n",
      "Epoch 400/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9173 - loss: 0.2660 - val_accuracy: 0.9326 - val_loss: 0.2255\n",
      "Epoch 401/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9175 - loss: 0.2582 - val_accuracy: 0.9415 - val_loss: 0.2101\n",
      "Epoch 402/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9163 - loss: 0.2638 - val_accuracy: 0.9435 - val_loss: 0.2001\n",
      "Epoch 403/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9144 - loss: 0.2636 - val_accuracy: 0.9378 - val_loss: 0.2124\n",
      "Epoch 404/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9200 - loss: 0.2508 - val_accuracy: 0.9382 - val_loss: 0.2131\n",
      "Epoch 405/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9195 - loss: 0.2563 - val_accuracy: 0.9395 - val_loss: 0.2077\n",
      "Epoch 406/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9233 - loss: 0.2471 - val_accuracy: 0.9376 - val_loss: 0.2080\n",
      "Epoch 407/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9182 - loss: 0.2511 - val_accuracy: 0.9413 - val_loss: 0.2107\n",
      "Epoch 408/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9180 - loss: 0.2620 - val_accuracy: 0.9415 - val_loss: 0.2089\n",
      "Epoch 409/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9143 - loss: 0.2606 - val_accuracy: 0.9362 - val_loss: 0.2160\n",
      "Epoch 410/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9146 - loss: 0.2687 - val_accuracy: 0.9401 - val_loss: 0.2093\n",
      "Epoch 411/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9172 - loss: 0.2513 - val_accuracy: 0.9374 - val_loss: 0.2177\n",
      "Epoch 412/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9185 - loss: 0.2542 - val_accuracy: 0.9417 - val_loss: 0.2032\n",
      "Epoch 413/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9163 - loss: 0.2626 - val_accuracy: 0.9399 - val_loss: 0.2114\n",
      "Epoch 414/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9195 - loss: 0.2459 - val_accuracy: 0.9360 - val_loss: 0.2153\n",
      "Epoch 415/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9136 - loss: 0.2609 - val_accuracy: 0.9382 - val_loss: 0.2115\n",
      "Epoch 416/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9169 - loss: 0.2607 - val_accuracy: 0.9336 - val_loss: 0.2229\n",
      "Epoch 417/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9171 - loss: 0.2613 - val_accuracy: 0.9395 - val_loss: 0.2129\n",
      "Epoch 418/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9206 - loss: 0.2521 - val_accuracy: 0.9360 - val_loss: 0.2186\n",
      "Epoch 419/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9189 - loss: 0.2554 - val_accuracy: 0.9376 - val_loss: 0.2094\n",
      "Epoch 420/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.9210 - loss: 0.2538 - val_accuracy: 0.9354 - val_loss: 0.2203\n",
      "Epoch 421/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9200 - loss: 0.2534 - val_accuracy: 0.9403 - val_loss: 0.2009\n",
      "Epoch 422/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9187 - loss: 0.2524 - val_accuracy: 0.9384 - val_loss: 0.2093\n",
      "Epoch 423/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9176 - loss: 0.2539 - val_accuracy: 0.9399 - val_loss: 0.2103\n",
      "Epoch 424/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9182 - loss: 0.2585 - val_accuracy: 0.9358 - val_loss: 0.2057\n",
      "Epoch 425/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9186 - loss: 0.2542 - val_accuracy: 0.9389 - val_loss: 0.2041\n",
      "Epoch 426/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9175 - loss: 0.2577 - val_accuracy: 0.9415 - val_loss: 0.2047\n",
      "Epoch 427/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9164 - loss: 0.2588 - val_accuracy: 0.9405 - val_loss: 0.2090\n",
      "Epoch 428/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9194 - loss: 0.2443 - val_accuracy: 0.9407 - val_loss: 0.2049\n",
      "Epoch 429/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9181 - loss: 0.2507 - val_accuracy: 0.9405 - val_loss: 0.2072\n",
      "Epoch 430/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9167 - loss: 0.2558 - val_accuracy: 0.9403 - val_loss: 0.2063\n",
      "Epoch 431/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9215 - loss: 0.2477 - val_accuracy: 0.9403 - val_loss: 0.2119\n",
      "Epoch 432/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9181 - loss: 0.2532 - val_accuracy: 0.9358 - val_loss: 0.2126\n",
      "Epoch 433/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9174 - loss: 0.2576 - val_accuracy: 0.9429 - val_loss: 0.2038\n",
      "Epoch 434/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9212 - loss: 0.2470 - val_accuracy: 0.9376 - val_loss: 0.2214\n",
      "Epoch 435/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9161 - loss: 0.2499 - val_accuracy: 0.9389 - val_loss: 0.2123\n",
      "Epoch 436/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9191 - loss: 0.2541 - val_accuracy: 0.9385 - val_loss: 0.2088\n",
      "Epoch 437/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9187 - loss: 0.2484 - val_accuracy: 0.9378 - val_loss: 0.2103\n",
      "Epoch 438/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9180 - loss: 0.2538 - val_accuracy: 0.9370 - val_loss: 0.2120\n",
      "Epoch 439/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9128 - loss: 0.2699 - val_accuracy: 0.9385 - val_loss: 0.2027\n",
      "Epoch 440/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9210 - loss: 0.2482 - val_accuracy: 0.9403 - val_loss: 0.2089\n",
      "Epoch 441/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9178 - loss: 0.2561 - val_accuracy: 0.9391 - val_loss: 0.2135\n",
      "Epoch 442/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9184 - loss: 0.2591 - val_accuracy: 0.9384 - val_loss: 0.2171\n",
      "Epoch 443/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9173 - loss: 0.2500 - val_accuracy: 0.9393 - val_loss: 0.2028\n",
      "Epoch 444/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9190 - loss: 0.2523 - val_accuracy: 0.9403 - val_loss: 0.2057\n",
      "Epoch 445/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9231 - loss: 0.2432 - val_accuracy: 0.9380 - val_loss: 0.2113\n",
      "Epoch 446/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9211 - loss: 0.2483 - val_accuracy: 0.9405 - val_loss: 0.2166\n",
      "Epoch 447/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9164 - loss: 0.2560 - val_accuracy: 0.9362 - val_loss: 0.2035\n",
      "Epoch 448/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9198 - loss: 0.2473 - val_accuracy: 0.9350 - val_loss: 0.2089\n",
      "Epoch 449/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9222 - loss: 0.2444 - val_accuracy: 0.9399 - val_loss: 0.2097\n",
      "Epoch 450/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9202 - loss: 0.2556 - val_accuracy: 0.9330 - val_loss: 0.2252\n",
      "Epoch 451/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9205 - loss: 0.2508 - val_accuracy: 0.9385 - val_loss: 0.2120\n",
      "Epoch 452/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9201 - loss: 0.2436 - val_accuracy: 0.9372 - val_loss: 0.2129\n",
      "Epoch 453/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9220 - loss: 0.2451 - val_accuracy: 0.9421 - val_loss: 0.2031\n",
      "Epoch 454/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9225 - loss: 0.2424 - val_accuracy: 0.9403 - val_loss: 0.2086\n",
      "Epoch 455/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9199 - loss: 0.2455 - val_accuracy: 0.9407 - val_loss: 0.2117\n",
      "Epoch 456/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9202 - loss: 0.2567 - val_accuracy: 0.9411 - val_loss: 0.2053\n",
      "Epoch 457/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9199 - loss: 0.2529 - val_accuracy: 0.9378 - val_loss: 0.2140\n",
      "Epoch 458/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9178 - loss: 0.2603 - val_accuracy: 0.9419 - val_loss: 0.2068\n",
      "Epoch 459/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9221 - loss: 0.2499 - val_accuracy: 0.9411 - val_loss: 0.2006\n",
      "Epoch 460/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9213 - loss: 0.2493 - val_accuracy: 0.9378 - val_loss: 0.2123\n",
      "Epoch 461/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9240 - loss: 0.2377 - val_accuracy: 0.9405 - val_loss: 0.2046\n",
      "Epoch 462/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9203 - loss: 0.2446 - val_accuracy: 0.9411 - val_loss: 0.2018\n",
      "Epoch 463/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9222 - loss: 0.2445 - val_accuracy: 0.9385 - val_loss: 0.2159\n",
      "Epoch 464/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9218 - loss: 0.2449 - val_accuracy: 0.9370 - val_loss: 0.2121\n",
      "Epoch 465/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9201 - loss: 0.2472 - val_accuracy: 0.9387 - val_loss: 0.2151\n",
      "Epoch 466/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9186 - loss: 0.2563 - val_accuracy: 0.9401 - val_loss: 0.2045\n",
      "Epoch 467/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9228 - loss: 0.2422 - val_accuracy: 0.9364 - val_loss: 0.2163\n",
      "Epoch 468/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9216 - loss: 0.2415 - val_accuracy: 0.9372 - val_loss: 0.2191\n",
      "Epoch 469/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9185 - loss: 0.2600 - val_accuracy: 0.9387 - val_loss: 0.2144\n",
      "Epoch 470/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9196 - loss: 0.2477 - val_accuracy: 0.9409 - val_loss: 0.2096\n",
      "Epoch 471/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9188 - loss: 0.2541 - val_accuracy: 0.9393 - val_loss: 0.2058\n",
      "Epoch 472/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9190 - loss: 0.2487 - val_accuracy: 0.9376 - val_loss: 0.2072\n",
      "Epoch 473/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9192 - loss: 0.2512 - val_accuracy: 0.9425 - val_loss: 0.1970\n",
      "Epoch 474/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.9198 - loss: 0.2485 - val_accuracy: 0.9421 - val_loss: 0.2113\n",
      "Epoch 475/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9213 - loss: 0.2454 - val_accuracy: 0.9399 - val_loss: 0.2065\n",
      "Epoch 476/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9217 - loss: 0.2491 - val_accuracy: 0.9401 - val_loss: 0.2061\n",
      "Epoch 477/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9212 - loss: 0.2521 - val_accuracy: 0.9399 - val_loss: 0.2027\n",
      "Epoch 478/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9214 - loss: 0.2429 - val_accuracy: 0.9415 - val_loss: 0.2075\n",
      "Epoch 479/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9206 - loss: 0.2475 - val_accuracy: 0.9407 - val_loss: 0.2023\n",
      "Epoch 480/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9222 - loss: 0.2503 - val_accuracy: 0.9382 - val_loss: 0.2104\n",
      "Epoch 481/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9210 - loss: 0.2528 - val_accuracy: 0.9437 - val_loss: 0.2065\n",
      "Epoch 482/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9238 - loss: 0.2373 - val_accuracy: 0.9405 - val_loss: 0.2046\n",
      "Epoch 483/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9184 - loss: 0.2561 - val_accuracy: 0.9401 - val_loss: 0.2120\n",
      "Epoch 484/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9229 - loss: 0.2449 - val_accuracy: 0.9366 - val_loss: 0.2174\n",
      "Epoch 485/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9216 - loss: 0.2447 - val_accuracy: 0.9391 - val_loss: 0.2148\n",
      "Epoch 486/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9247 - loss: 0.2425 - val_accuracy: 0.9421 - val_loss: 0.2109\n",
      "Epoch 487/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9213 - loss: 0.2459 - val_accuracy: 0.9360 - val_loss: 0.2150\n",
      "Epoch 488/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9227 - loss: 0.2425 - val_accuracy: 0.9389 - val_loss: 0.2065\n",
      "Epoch 489/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9231 - loss: 0.2493 - val_accuracy: 0.9419 - val_loss: 0.2101\n",
      "Epoch 490/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9188 - loss: 0.2518 - val_accuracy: 0.9393 - val_loss: 0.2058\n",
      "Epoch 491/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9215 - loss: 0.2389 - val_accuracy: 0.9415 - val_loss: 0.2056\n",
      "Epoch 492/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9199 - loss: 0.2494 - val_accuracy: 0.9401 - val_loss: 0.2067\n",
      "Epoch 493/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9206 - loss: 0.2532 - val_accuracy: 0.9429 - val_loss: 0.2030\n",
      "Epoch 494/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9210 - loss: 0.2509 - val_accuracy: 0.9387 - val_loss: 0.2090\n",
      "Epoch 495/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9226 - loss: 0.2484 - val_accuracy: 0.9376 - val_loss: 0.2102\n",
      "Epoch 496/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9191 - loss: 0.2410 - val_accuracy: 0.9391 - val_loss: 0.2038\n",
      "Epoch 497/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9203 - loss: 0.2533 - val_accuracy: 0.9417 - val_loss: 0.2028\n",
      "Epoch 498/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9231 - loss: 0.2421 - val_accuracy: 0.9380 - val_loss: 0.2123\n",
      "Epoch 499/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9213 - loss: 0.2440 - val_accuracy: 0.9421 - val_loss: 0.2120\n",
      "Epoch 500/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9231 - loss: 0.2398 - val_accuracy: 0.9397 - val_loss: 0.2047\n",
      "Epoch 501/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9205 - loss: 0.2442 - val_accuracy: 0.9437 - val_loss: 0.2064\n",
      "Epoch 502/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9203 - loss: 0.2463 - val_accuracy: 0.9419 - val_loss: 0.2048\n",
      "Epoch 503/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9213 - loss: 0.2406 - val_accuracy: 0.9415 - val_loss: 0.2024\n",
      "Epoch 504/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9205 - loss: 0.2422 - val_accuracy: 0.9385 - val_loss: 0.2094\n",
      "Epoch 505/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9251 - loss: 0.2379 - val_accuracy: 0.9443 - val_loss: 0.1972\n",
      "Epoch 506/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9195 - loss: 0.2521 - val_accuracy: 0.9447 - val_loss: 0.1991\n",
      "Epoch 507/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9223 - loss: 0.2423 - val_accuracy: 0.9413 - val_loss: 0.2041\n",
      "Epoch 508/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9210 - loss: 0.2458 - val_accuracy: 0.9415 - val_loss: 0.2055\n",
      "Epoch 509/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9221 - loss: 0.2437 - val_accuracy: 0.9362 - val_loss: 0.2124\n",
      "Epoch 510/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9208 - loss: 0.2496 - val_accuracy: 0.9427 - val_loss: 0.1976\n",
      "Epoch 511/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9199 - loss: 0.2450 - val_accuracy: 0.9409 - val_loss: 0.2056\n",
      "Epoch 512/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9219 - loss: 0.2417 - val_accuracy: 0.9417 - val_loss: 0.1947\n",
      "Epoch 513/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9213 - loss: 0.2451 - val_accuracy: 0.9411 - val_loss: 0.1977\n",
      "Epoch 514/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9239 - loss: 0.2363 - val_accuracy: 0.9389 - val_loss: 0.2082\n",
      "Epoch 515/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9234 - loss: 0.2400 - val_accuracy: 0.9423 - val_loss: 0.2073\n",
      "Epoch 516/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9206 - loss: 0.2505 - val_accuracy: 0.9399 - val_loss: 0.2075\n",
      "Epoch 517/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9220 - loss: 0.2435 - val_accuracy: 0.9411 - val_loss: 0.2094\n",
      "Epoch 518/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9230 - loss: 0.2405 - val_accuracy: 0.9413 - val_loss: 0.2032\n",
      "Epoch 519/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9234 - loss: 0.2433 - val_accuracy: 0.9401 - val_loss: 0.2055\n",
      "Epoch 520/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9228 - loss: 0.2453 - val_accuracy: 0.9370 - val_loss: 0.2122\n",
      "Epoch 521/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9225 - loss: 0.2440 - val_accuracy: 0.9409 - val_loss: 0.2111\n",
      "Epoch 522/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9227 - loss: 0.2392 - val_accuracy: 0.9378 - val_loss: 0.2055\n",
      "Epoch 523/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9211 - loss: 0.2430 - val_accuracy: 0.9421 - val_loss: 0.2032\n",
      "Epoch 524/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9198 - loss: 0.2490 - val_accuracy: 0.9397 - val_loss: 0.2085\n",
      "Epoch 525/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9212 - loss: 0.2458 - val_accuracy: 0.9429 - val_loss: 0.2096\n",
      "Epoch 526/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9236 - loss: 0.2426 - val_accuracy: 0.9415 - val_loss: 0.2010\n",
      "Epoch 527/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9240 - loss: 0.2408 - val_accuracy: 0.9415 - val_loss: 0.1975\n",
      "Epoch 528/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9240 - loss: 0.2348 - val_accuracy: 0.9421 - val_loss: 0.2118\n",
      "Epoch 529/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9203 - loss: 0.2458 - val_accuracy: 0.9403 - val_loss: 0.2051\n",
      "Epoch 530/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9243 - loss: 0.2417 - val_accuracy: 0.9435 - val_loss: 0.2030\n",
      "Epoch 531/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9216 - loss: 0.2450 - val_accuracy: 0.9447 - val_loss: 0.2021\n",
      "Epoch 532/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9221 - loss: 0.2470 - val_accuracy: 0.9425 - val_loss: 0.1992\n",
      "Epoch 533/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9239 - loss: 0.2418 - val_accuracy: 0.9421 - val_loss: 0.2055\n",
      "Epoch 534/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9221 - loss: 0.2478 - val_accuracy: 0.9415 - val_loss: 0.2094\n",
      "Epoch 535/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9233 - loss: 0.2385 - val_accuracy: 0.9421 - val_loss: 0.2019\n",
      "Epoch 536/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9232 - loss: 0.2402 - val_accuracy: 0.9431 - val_loss: 0.2044\n",
      "Epoch 537/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9230 - loss: 0.2472 - val_accuracy: 0.9421 - val_loss: 0.2116\n",
      "Epoch 538/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9234 - loss: 0.2405 - val_accuracy: 0.9407 - val_loss: 0.2022\n",
      "Epoch 539/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9255 - loss: 0.2317 - val_accuracy: 0.9378 - val_loss: 0.2064\n",
      "Epoch 540/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9227 - loss: 0.2444 - val_accuracy: 0.9368 - val_loss: 0.2175\n",
      "Epoch 541/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9210 - loss: 0.2498 - val_accuracy: 0.9366 - val_loss: 0.2103\n",
      "Epoch 542/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9220 - loss: 0.2444 - val_accuracy: 0.9384 - val_loss: 0.2043\n",
      "Epoch 543/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9208 - loss: 0.2471 - val_accuracy: 0.9435 - val_loss: 0.2029\n",
      "Epoch 544/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9209 - loss: 0.2419 - val_accuracy: 0.9405 - val_loss: 0.2013\n",
      "Epoch 545/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9261 - loss: 0.2325 - val_accuracy: 0.9372 - val_loss: 0.2170\n",
      "Epoch 546/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9249 - loss: 0.2419 - val_accuracy: 0.9401 - val_loss: 0.2065\n",
      "Epoch 547/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9234 - loss: 0.2449 - val_accuracy: 0.9411 - val_loss: 0.2055\n",
      "Epoch 548/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9209 - loss: 0.2438 - val_accuracy: 0.9403 - val_loss: 0.2108\n",
      "Epoch 549/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9247 - loss: 0.2314 - val_accuracy: 0.9433 - val_loss: 0.2049\n",
      "Epoch 550/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9232 - loss: 0.2378 - val_accuracy: 0.9364 - val_loss: 0.2165\n",
      "Epoch 551/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9230 - loss: 0.2416 - val_accuracy: 0.9387 - val_loss: 0.2106\n",
      "Epoch 552/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9255 - loss: 0.2369 - val_accuracy: 0.9405 - val_loss: 0.2059\n",
      "Epoch 553/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9236 - loss: 0.2395 - val_accuracy: 0.9370 - val_loss: 0.2153\n",
      "Epoch 554/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9224 - loss: 0.2442 - val_accuracy: 0.9385 - val_loss: 0.2106\n",
      "Epoch 555/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9229 - loss: 0.2400 - val_accuracy: 0.9389 - val_loss: 0.2106\n",
      "Epoch 556/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9227 - loss: 0.2420 - val_accuracy: 0.9385 - val_loss: 0.2048\n",
      "Epoch 557/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9223 - loss: 0.2454 - val_accuracy: 0.9399 - val_loss: 0.2024\n",
      "Epoch 558/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9253 - loss: 0.2330 - val_accuracy: 0.9403 - val_loss: 0.1971\n",
      "Epoch 559/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9256 - loss: 0.2332 - val_accuracy: 0.9401 - val_loss: 0.1988\n",
      "Epoch 560/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9229 - loss: 0.2397 - val_accuracy: 0.9368 - val_loss: 0.2143\n",
      "Epoch 561/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9276 - loss: 0.2326 - val_accuracy: 0.9384 - val_loss: 0.2120\n",
      "Epoch 562/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9240 - loss: 0.2392 - val_accuracy: 0.9405 - val_loss: 0.2033\n",
      "Epoch 563/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9262 - loss: 0.2326 - val_accuracy: 0.9431 - val_loss: 0.2038\n",
      "Epoch 564/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9200 - loss: 0.2466 - val_accuracy: 0.9421 - val_loss: 0.2051\n",
      "Epoch 565/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9227 - loss: 0.2389 - val_accuracy: 0.9423 - val_loss: 0.2003\n",
      "Epoch 566/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9209 - loss: 0.2459 - val_accuracy: 0.9391 - val_loss: 0.2049\n",
      "Epoch 567/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9258 - loss: 0.2357 - val_accuracy: 0.9417 - val_loss: 0.1975\n",
      "Epoch 568/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9219 - loss: 0.2410 - val_accuracy: 0.9413 - val_loss: 0.2108\n",
      "Epoch 569/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9211 - loss: 0.2419 - val_accuracy: 0.9437 - val_loss: 0.1993\n",
      "Epoch 570/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9248 - loss: 0.2396 - val_accuracy: 0.9411 - val_loss: 0.1997\n",
      "Epoch 571/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9253 - loss: 0.2410 - val_accuracy: 0.9393 - val_loss: 0.2131\n",
      "Epoch 572/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9215 - loss: 0.2421 - val_accuracy: 0.9433 - val_loss: 0.1965\n",
      "Epoch 573/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9246 - loss: 0.2360 - val_accuracy: 0.9413 - val_loss: 0.2033\n",
      "Epoch 574/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9255 - loss: 0.2346 - val_accuracy: 0.9413 - val_loss: 0.1990\n",
      "Epoch 575/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9236 - loss: 0.2355 - val_accuracy: 0.9437 - val_loss: 0.1987\n",
      "Epoch 576/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9262 - loss: 0.2292 - val_accuracy: 0.9451 - val_loss: 0.2002\n",
      "Epoch 577/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9244 - loss: 0.2352 - val_accuracy: 0.9395 - val_loss: 0.2038\n",
      "Epoch 578/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9217 - loss: 0.2424 - val_accuracy: 0.9421 - val_loss: 0.2059\n",
      "Epoch 579/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9210 - loss: 0.2410 - val_accuracy: 0.9421 - val_loss: 0.1990\n",
      "Epoch 580/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9264 - loss: 0.2352 - val_accuracy: 0.9403 - val_loss: 0.2046\n",
      "Epoch 581/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9249 - loss: 0.2337 - val_accuracy: 0.9397 - val_loss: 0.2092\n",
      "Epoch 582/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9214 - loss: 0.2506 - val_accuracy: 0.9405 - val_loss: 0.2087\n",
      "Epoch 583/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9241 - loss: 0.2319 - val_accuracy: 0.9384 - val_loss: 0.2089\n",
      "Epoch 584/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9236 - loss: 0.2334 - val_accuracy: 0.9439 - val_loss: 0.2009\n",
      "Epoch 585/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9246 - loss: 0.2405 - val_accuracy: 0.9411 - val_loss: 0.2023\n",
      "Epoch 586/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9262 - loss: 0.2288 - val_accuracy: 0.9372 - val_loss: 0.2099\n",
      "Epoch 587/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9233 - loss: 0.2388 - val_accuracy: 0.9423 - val_loss: 0.2073\n",
      "Epoch 588/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9247 - loss: 0.2395 - val_accuracy: 0.9427 - val_loss: 0.2081\n",
      "Epoch 589/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9220 - loss: 0.2413 - val_accuracy: 0.9411 - val_loss: 0.2031\n",
      "Epoch 590/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9240 - loss: 0.2404 - val_accuracy: 0.9409 - val_loss: 0.2026\n",
      "Epoch 591/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9251 - loss: 0.2365 - val_accuracy: 0.9427 - val_loss: 0.2023\n",
      "Epoch 592/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9251 - loss: 0.2318 - val_accuracy: 0.9433 - val_loss: 0.1969\n",
      "Epoch 593/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9262 - loss: 0.2345 - val_accuracy: 0.9431 - val_loss: 0.1989\n",
      "Epoch 594/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9262 - loss: 0.2295 - val_accuracy: 0.9429 - val_loss: 0.1990\n",
      "Epoch 595/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9222 - loss: 0.2509 - val_accuracy: 0.9425 - val_loss: 0.2082\n",
      "Epoch 596/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9239 - loss: 0.2397 - val_accuracy: 0.9397 - val_loss: 0.2107\n",
      "Epoch 597/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9262 - loss: 0.2351 - val_accuracy: 0.9415 - val_loss: 0.2063\n",
      "Epoch 598/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9250 - loss: 0.2350 - val_accuracy: 0.9413 - val_loss: 0.2003\n",
      "Epoch 599/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9280 - loss: 0.2321 - val_accuracy: 0.9441 - val_loss: 0.1957\n",
      "Epoch 600/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9256 - loss: 0.2316 - val_accuracy: 0.9413 - val_loss: 0.2013\n",
      "Epoch 601/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9240 - loss: 0.2381 - val_accuracy: 0.9409 - val_loss: 0.2064\n",
      "Epoch 602/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9237 - loss: 0.2359 - val_accuracy: 0.9399 - val_loss: 0.2063\n",
      "Epoch 603/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9261 - loss: 0.2280 - val_accuracy: 0.9435 - val_loss: 0.2007\n",
      "Epoch 604/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9268 - loss: 0.2375 - val_accuracy: 0.9380 - val_loss: 0.2128\n",
      "Epoch 605/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9232 - loss: 0.2378 - val_accuracy: 0.9437 - val_loss: 0.2022\n",
      "Epoch 606/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9262 - loss: 0.2378 - val_accuracy: 0.9407 - val_loss: 0.2067\n",
      "Epoch 607/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9256 - loss: 0.2339 - val_accuracy: 0.9443 - val_loss: 0.2041\n",
      "Epoch 608/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9262 - loss: 0.2325 - val_accuracy: 0.9409 - val_loss: 0.2058\n",
      "Epoch 609/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9247 - loss: 0.2301 - val_accuracy: 0.9451 - val_loss: 0.2000\n",
      "Epoch 610/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9254 - loss: 0.2319 - val_accuracy: 0.9411 - val_loss: 0.2028\n",
      "Epoch 611/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9209 - loss: 0.2400 - val_accuracy: 0.9411 - val_loss: 0.2042\n",
      "Epoch 612/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.9255 - loss: 0.2323 - val_accuracy: 0.9449 - val_loss: 0.2046\n",
      "Epoch 613/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9240 - loss: 0.2386 - val_accuracy: 0.9399 - val_loss: 0.2028\n",
      "Epoch 614/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9221 - loss: 0.2377 - val_accuracy: 0.9427 - val_loss: 0.2063\n",
      "Epoch 615/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9239 - loss: 0.2370 - val_accuracy: 0.9425 - val_loss: 0.1986\n",
      "Epoch 616/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9238 - loss: 0.2354 - val_accuracy: 0.9409 - val_loss: 0.2033\n",
      "Epoch 617/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9246 - loss: 0.2345 - val_accuracy: 0.9378 - val_loss: 0.2082\n",
      "Epoch 618/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9231 - loss: 0.2355 - val_accuracy: 0.9415 - val_loss: 0.2040\n",
      "Epoch 619/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9246 - loss: 0.2370 - val_accuracy: 0.9407 - val_loss: 0.2072\n",
      "Epoch 620/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9248 - loss: 0.2329 - val_accuracy: 0.9425 - val_loss: 0.1976\n",
      "Epoch 621/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9260 - loss: 0.2288 - val_accuracy: 0.9391 - val_loss: 0.2057\n",
      "Epoch 622/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9247 - loss: 0.2312 - val_accuracy: 0.9433 - val_loss: 0.2007\n",
      "Epoch 623/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9263 - loss: 0.2301 - val_accuracy: 0.9391 - val_loss: 0.2085\n",
      "Epoch 624/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9280 - loss: 0.2265 - val_accuracy: 0.9419 - val_loss: 0.2083\n",
      "Epoch 625/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9254 - loss: 0.2290 - val_accuracy: 0.9409 - val_loss: 0.2080\n",
      "Epoch 626/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9205 - loss: 0.2460 - val_accuracy: 0.9423 - val_loss: 0.2029\n",
      "Epoch 627/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9254 - loss: 0.2318 - val_accuracy: 0.9385 - val_loss: 0.2130\n",
      "Epoch 628/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9269 - loss: 0.2313 - val_accuracy: 0.9417 - val_loss: 0.2069\n",
      "Epoch 629/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9251 - loss: 0.2365 - val_accuracy: 0.9443 - val_loss: 0.1935\n",
      "Epoch 630/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9233 - loss: 0.2423 - val_accuracy: 0.9425 - val_loss: 0.2066\n",
      "Epoch 631/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9249 - loss: 0.2318 - val_accuracy: 0.9455 - val_loss: 0.1991\n",
      "Epoch 632/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9245 - loss: 0.2365 - val_accuracy: 0.9451 - val_loss: 0.1986\n",
      "Epoch 633/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9258 - loss: 0.2351 - val_accuracy: 0.9395 - val_loss: 0.2000\n",
      "Epoch 634/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9246 - loss: 0.2312 - val_accuracy: 0.9399 - val_loss: 0.2002\n",
      "Epoch 635/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9271 - loss: 0.2266 - val_accuracy: 0.9409 - val_loss: 0.2022\n",
      "Epoch 636/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9256 - loss: 0.2312 - val_accuracy: 0.9407 - val_loss: 0.2035\n",
      "Epoch 637/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9279 - loss: 0.2277 - val_accuracy: 0.9435 - val_loss: 0.1939\n",
      "Epoch 638/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9238 - loss: 0.2423 - val_accuracy: 0.9443 - val_loss: 0.1969\n",
      "Epoch 639/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9219 - loss: 0.2338 - val_accuracy: 0.9463 - val_loss: 0.1950\n",
      "Epoch 640/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9292 - loss: 0.2221 - val_accuracy: 0.9461 - val_loss: 0.1900\n",
      "Epoch 641/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9260 - loss: 0.2329 - val_accuracy: 0.9429 - val_loss: 0.2007\n",
      "Epoch 642/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9255 - loss: 0.2320 - val_accuracy: 0.9393 - val_loss: 0.2108\n",
      "Epoch 643/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9277 - loss: 0.2240 - val_accuracy: 0.9425 - val_loss: 0.1995\n",
      "Epoch 644/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9231 - loss: 0.2365 - val_accuracy: 0.9372 - val_loss: 0.2138\n",
      "Epoch 645/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9262 - loss: 0.2314 - val_accuracy: 0.9429 - val_loss: 0.1944\n",
      "Epoch 646/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9297 - loss: 0.2161 - val_accuracy: 0.9342 - val_loss: 0.2250\n",
      "Epoch 647/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9225 - loss: 0.2443 - val_accuracy: 0.9421 - val_loss: 0.2012\n",
      "Epoch 648/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9278 - loss: 0.2256 - val_accuracy: 0.9425 - val_loss: 0.2021\n",
      "Epoch 649/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9222 - loss: 0.2377 - val_accuracy: 0.9449 - val_loss: 0.1965\n",
      "Epoch 650/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9266 - loss: 0.2276 - val_accuracy: 0.9431 - val_loss: 0.1965\n",
      "Epoch 651/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9256 - loss: 0.2270 - val_accuracy: 0.9429 - val_loss: 0.1989\n",
      "Epoch 652/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9263 - loss: 0.2309 - val_accuracy: 0.9393 - val_loss: 0.2039\n",
      "Epoch 653/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9250 - loss: 0.2345 - val_accuracy: 0.9415 - val_loss: 0.2031\n",
      "Epoch 654/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9255 - loss: 0.2356 - val_accuracy: 0.9429 - val_loss: 0.1991\n",
      "Epoch 655/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9226 - loss: 0.2406 - val_accuracy: 0.9405 - val_loss: 0.1983\n",
      "Epoch 656/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9250 - loss: 0.2418 - val_accuracy: 0.9411 - val_loss: 0.2010\n",
      "Epoch 657/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9277 - loss: 0.2220 - val_accuracy: 0.9431 - val_loss: 0.1951\n",
      "Epoch 658/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9263 - loss: 0.2318 - val_accuracy: 0.9447 - val_loss: 0.1976\n",
      "Epoch 659/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9256 - loss: 0.2350 - val_accuracy: 0.9407 - val_loss: 0.2003\n",
      "Epoch 660/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9242 - loss: 0.2317 - val_accuracy: 0.9413 - val_loss: 0.2027\n",
      "Epoch 661/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9245 - loss: 0.2342 - val_accuracy: 0.9441 - val_loss: 0.2001\n",
      "Epoch 662/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9273 - loss: 0.2253 - val_accuracy: 0.9417 - val_loss: 0.2057\n",
      "Epoch 663/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9241 - loss: 0.2330 - val_accuracy: 0.9413 - val_loss: 0.2013\n",
      "Epoch 664/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9297 - loss: 0.2221 - val_accuracy: 0.9431 - val_loss: 0.2026\n",
      "Epoch 665/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9260 - loss: 0.2304 - val_accuracy: 0.9431 - val_loss: 0.2080\n",
      "Epoch 666/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9289 - loss: 0.2263 - val_accuracy: 0.9441 - val_loss: 0.2004\n",
      "Epoch 667/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.9295 - loss: 0.2226 - val_accuracy: 0.9431 - val_loss: 0.1979\n",
      "Epoch 668/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9267 - loss: 0.2400 - val_accuracy: 0.9411 - val_loss: 0.2022\n",
      "Epoch 669/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9257 - loss: 0.2353 - val_accuracy: 0.9441 - val_loss: 0.1920\n",
      "Epoch 670/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9264 - loss: 0.2369 - val_accuracy: 0.9403 - val_loss: 0.1958\n",
      "Epoch 671/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9260 - loss: 0.2353 - val_accuracy: 0.9415 - val_loss: 0.1982\n",
      "Epoch 672/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9203 - loss: 0.2408 - val_accuracy: 0.9378 - val_loss: 0.2074\n",
      "Epoch 673/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9293 - loss: 0.2195 - val_accuracy: 0.9389 - val_loss: 0.2095\n",
      "Epoch 674/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9274 - loss: 0.2306 - val_accuracy: 0.9427 - val_loss: 0.1963\n",
      "Epoch 675/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9258 - loss: 0.2261 - val_accuracy: 0.9413 - val_loss: 0.2049\n",
      "Epoch 676/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9256 - loss: 0.2322 - val_accuracy: 0.9391 - val_loss: 0.2050\n",
      "Epoch 677/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9268 - loss: 0.2296 - val_accuracy: 0.9437 - val_loss: 0.1989\n",
      "Epoch 678/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9260 - loss: 0.2311 - val_accuracy: 0.9429 - val_loss: 0.2024\n",
      "Epoch 679/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9263 - loss: 0.2342 - val_accuracy: 0.9433 - val_loss: 0.2030\n",
      "Epoch 680/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9266 - loss: 0.2228 - val_accuracy: 0.9376 - val_loss: 0.2090\n",
      "Epoch 681/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9250 - loss: 0.2293 - val_accuracy: 0.9393 - val_loss: 0.2094\n",
      "Epoch 682/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9273 - loss: 0.2322 - val_accuracy: 0.9431 - val_loss: 0.2077\n",
      "Epoch 683/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9301 - loss: 0.2197 - val_accuracy: 0.9457 - val_loss: 0.1990\n",
      "Epoch 684/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9274 - loss: 0.2251 - val_accuracy: 0.9423 - val_loss: 0.2049\n",
      "Epoch 685/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9270 - loss: 0.2362 - val_accuracy: 0.9384 - val_loss: 0.2096\n",
      "Epoch 686/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9258 - loss: 0.2318 - val_accuracy: 0.9415 - val_loss: 0.2031\n",
      "Epoch 687/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9264 - loss: 0.2325 - val_accuracy: 0.9393 - val_loss: 0.2089\n",
      "Epoch 688/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9240 - loss: 0.2307 - val_accuracy: 0.9435 - val_loss: 0.2024\n",
      "Epoch 689/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9272 - loss: 0.2286 - val_accuracy: 0.9433 - val_loss: 0.2012\n",
      "Epoch 690/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9264 - loss: 0.2287 - val_accuracy: 0.9407 - val_loss: 0.2012\n",
      "Epoch 691/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9266 - loss: 0.2285 - val_accuracy: 0.9395 - val_loss: 0.1998\n",
      "Epoch 692/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9262 - loss: 0.2325 - val_accuracy: 0.9429 - val_loss: 0.1978\n",
      "Epoch 693/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9252 - loss: 0.2279 - val_accuracy: 0.9411 - val_loss: 0.2038\n",
      "Epoch 694/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9284 - loss: 0.2295 - val_accuracy: 0.9395 - val_loss: 0.2025\n",
      "Epoch 695/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9264 - loss: 0.2317 - val_accuracy: 0.9435 - val_loss: 0.2034\n",
      "Epoch 696/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9270 - loss: 0.2265 - val_accuracy: 0.9391 - val_loss: 0.2058\n",
      "Epoch 697/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9263 - loss: 0.2276 - val_accuracy: 0.9415 - val_loss: 0.2031\n",
      "Epoch 698/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9252 - loss: 0.2285 - val_accuracy: 0.9415 - val_loss: 0.1967\n",
      "Epoch 699/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9260 - loss: 0.2269 - val_accuracy: 0.9403 - val_loss: 0.2007\n",
      "Epoch 700/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9259 - loss: 0.2258 - val_accuracy: 0.9433 - val_loss: 0.2010\n",
      "Epoch 701/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9277 - loss: 0.2284 - val_accuracy: 0.9431 - val_loss: 0.1950\n",
      "Epoch 702/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9247 - loss: 0.2320 - val_accuracy: 0.9399 - val_loss: 0.2097\n",
      "Epoch 703/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9238 - loss: 0.2404 - val_accuracy: 0.9441 - val_loss: 0.2010\n",
      "Epoch 704/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9248 - loss: 0.2389 - val_accuracy: 0.9403 - val_loss: 0.2039\n",
      "Epoch 705/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9283 - loss: 0.2257 - val_accuracy: 0.9441 - val_loss: 0.1925\n",
      "Epoch 706/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9264 - loss: 0.2323 - val_accuracy: 0.9384 - val_loss: 0.2093\n",
      "Epoch 707/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9253 - loss: 0.2341 - val_accuracy: 0.9403 - val_loss: 0.2064\n",
      "Epoch 708/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9282 - loss: 0.2254 - val_accuracy: 0.9429 - val_loss: 0.1937\n",
      "Epoch 709/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9308 - loss: 0.2213 - val_accuracy: 0.9425 - val_loss: 0.1996\n",
      "Epoch 710/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9260 - loss: 0.2328 - val_accuracy: 0.9427 - val_loss: 0.1989\n",
      "Epoch 711/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9262 - loss: 0.2320 - val_accuracy: 0.9429 - val_loss: 0.2024\n",
      "Epoch 712/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9248 - loss: 0.2282 - val_accuracy: 0.9409 - val_loss: 0.2043\n",
      "Epoch 713/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9277 - loss: 0.2195 - val_accuracy: 0.9427 - val_loss: 0.2047\n",
      "Epoch 714/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9216 - loss: 0.2416 - val_accuracy: 0.9421 - val_loss: 0.2025\n",
      "Epoch 715/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9277 - loss: 0.2269 - val_accuracy: 0.9419 - val_loss: 0.1966\n",
      "Epoch 716/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9263 - loss: 0.2283 - val_accuracy: 0.9417 - val_loss: 0.2038\n",
      "Epoch 717/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9275 - loss: 0.2235 - val_accuracy: 0.9407 - val_loss: 0.1975\n",
      "Epoch 718/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9289 - loss: 0.2219 - val_accuracy: 0.9397 - val_loss: 0.2046\n",
      "Epoch 719/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9297 - loss: 0.2186 - val_accuracy: 0.9403 - val_loss: 0.2029\n",
      "Epoch 720/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9285 - loss: 0.2309 - val_accuracy: 0.9449 - val_loss: 0.2020\n",
      "Epoch 721/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9282 - loss: 0.2209 - val_accuracy: 0.9413 - val_loss: 0.2050\n",
      "Epoch 722/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9250 - loss: 0.2377 - val_accuracy: 0.9419 - val_loss: 0.2074\n",
      "Epoch 723/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9264 - loss: 0.2257 - val_accuracy: 0.9439 - val_loss: 0.1994\n",
      "Epoch 724/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9277 - loss: 0.2227 - val_accuracy: 0.9405 - val_loss: 0.1997\n",
      "Epoch 725/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9302 - loss: 0.2212 - val_accuracy: 0.9441 - val_loss: 0.1983\n",
      "Epoch 726/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9262 - loss: 0.2275 - val_accuracy: 0.9431 - val_loss: 0.1997\n",
      "Epoch 727/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9279 - loss: 0.2268 - val_accuracy: 0.9451 - val_loss: 0.1992\n",
      "Epoch 728/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9255 - loss: 0.2325 - val_accuracy: 0.9403 - val_loss: 0.2005\n",
      "Epoch 729/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9294 - loss: 0.2165 - val_accuracy: 0.9429 - val_loss: 0.2004\n",
      "Epoch 730/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9280 - loss: 0.2257 - val_accuracy: 0.9395 - val_loss: 0.2055\n",
      "Epoch 731/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9307 - loss: 0.2168 - val_accuracy: 0.9429 - val_loss: 0.2043\n",
      "Epoch 732/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9238 - loss: 0.2370 - val_accuracy: 0.9417 - val_loss: 0.2078\n",
      "Epoch 733/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9266 - loss: 0.2321 - val_accuracy: 0.9403 - val_loss: 0.2029\n",
      "Epoch 734/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9270 - loss: 0.2258 - val_accuracy: 0.9437 - val_loss: 0.2015\n",
      "Epoch 735/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9254 - loss: 0.2304 - val_accuracy: 0.9429 - val_loss: 0.1997\n",
      "Epoch 736/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9252 - loss: 0.2355 - val_accuracy: 0.9421 - val_loss: 0.2025\n",
      "Epoch 737/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9264 - loss: 0.2366 - val_accuracy: 0.9421 - val_loss: 0.1975\n",
      "Epoch 738/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9279 - loss: 0.2186 - val_accuracy: 0.9423 - val_loss: 0.1973\n",
      "Epoch 739/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9293 - loss: 0.2239 - val_accuracy: 0.9425 - val_loss: 0.2026\n",
      "Epoch 740/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9275 - loss: 0.2198 - val_accuracy: 0.9431 - val_loss: 0.1946\n",
      "Epoch 741/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9298 - loss: 0.2150 - val_accuracy: 0.9431 - val_loss: 0.2004\n",
      "Epoch 742/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9282 - loss: 0.2268 - val_accuracy: 0.9425 - val_loss: 0.2018\n",
      "Epoch 743/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9262 - loss: 0.2348 - val_accuracy: 0.9463 - val_loss: 0.1979\n",
      "Epoch 744/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9273 - loss: 0.2253 - val_accuracy: 0.9411 - val_loss: 0.2022\n",
      "Epoch 745/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9279 - loss: 0.2246 - val_accuracy: 0.9417 - val_loss: 0.2000\n",
      "Epoch 746/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9292 - loss: 0.2197 - val_accuracy: 0.9405 - val_loss: 0.2005\n",
      "Epoch 747/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9275 - loss: 0.2248 - val_accuracy: 0.9439 - val_loss: 0.1965\n",
      "Epoch 748/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9269 - loss: 0.2287 - val_accuracy: 0.9429 - val_loss: 0.2017\n",
      "Epoch 749/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9268 - loss: 0.2289 - val_accuracy: 0.9405 - val_loss: 0.1993\n",
      "Epoch 750/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9306 - loss: 0.2162 - val_accuracy: 0.9445 - val_loss: 0.1980\n",
      "Epoch 751/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9268 - loss: 0.2242 - val_accuracy: 0.9405 - val_loss: 0.2103\n",
      "Epoch 752/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9307 - loss: 0.2165 - val_accuracy: 0.9445 - val_loss: 0.1964\n",
      "Epoch 753/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9270 - loss: 0.2310 - val_accuracy: 0.9415 - val_loss: 0.2004\n",
      "Epoch 754/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9287 - loss: 0.2227 - val_accuracy: 0.9425 - val_loss: 0.1992\n",
      "Epoch 755/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9281 - loss: 0.2332 - val_accuracy: 0.9415 - val_loss: 0.2056\n",
      "Epoch 756/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9277 - loss: 0.2250 - val_accuracy: 0.9391 - val_loss: 0.2064\n",
      "Epoch 757/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9303 - loss: 0.2137 - val_accuracy: 0.9429 - val_loss: 0.2019\n",
      "Epoch 758/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9259 - loss: 0.2303 - val_accuracy: 0.9439 - val_loss: 0.2022\n",
      "Epoch 759/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9315 - loss: 0.2117 - val_accuracy: 0.9431 - val_loss: 0.2022\n",
      "Epoch 760/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9275 - loss: 0.2231 - val_accuracy: 0.9429 - val_loss: 0.2019\n",
      "Epoch 761/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9252 - loss: 0.2334 - val_accuracy: 0.9413 - val_loss: 0.2119\n",
      "Epoch 762/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9276 - loss: 0.2301 - val_accuracy: 0.9441 - val_loss: 0.2055\n",
      "Epoch 763/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9267 - loss: 0.2267 - val_accuracy: 0.9445 - val_loss: 0.1960\n",
      "Epoch 764/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9278 - loss: 0.2177 - val_accuracy: 0.9421 - val_loss: 0.1962\n",
      "Epoch 765/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9290 - loss: 0.2201 - val_accuracy: 0.9429 - val_loss: 0.2079\n",
      "Epoch 766/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9260 - loss: 0.2337 - val_accuracy: 0.9419 - val_loss: 0.2077\n",
      "Epoch 767/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9256 - loss: 0.2312 - val_accuracy: 0.9417 - val_loss: 0.2047\n",
      "Epoch 768/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9308 - loss: 0.2110 - val_accuracy: 0.9427 - val_loss: 0.2038\n",
      "Epoch 769/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9272 - loss: 0.2268 - val_accuracy: 0.9447 - val_loss: 0.2046\n",
      "Epoch 770/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9293 - loss: 0.2245 - val_accuracy: 0.9457 - val_loss: 0.2098\n",
      "Epoch 771/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9276 - loss: 0.2248 - val_accuracy: 0.9435 - val_loss: 0.1952\n",
      "Epoch 772/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9278 - loss: 0.2304 - val_accuracy: 0.9433 - val_loss: 0.1995\n",
      "Epoch 773/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9279 - loss: 0.2249 - val_accuracy: 0.9421 - val_loss: 0.2015\n",
      "Epoch 774/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9263 - loss: 0.2332 - val_accuracy: 0.9421 - val_loss: 0.1963\n",
      "Epoch 775/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9270 - loss: 0.2261 - val_accuracy: 0.9441 - val_loss: 0.1901\n",
      "Epoch 776/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9290 - loss: 0.2190 - val_accuracy: 0.9427 - val_loss: 0.2065\n",
      "Epoch 777/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9272 - loss: 0.2336 - val_accuracy: 0.9419 - val_loss: 0.2076\n",
      "Epoch 778/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.9268 - loss: 0.2238 - val_accuracy: 0.9433 - val_loss: 0.2028\n",
      "Epoch 779/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9258 - loss: 0.2339 - val_accuracy: 0.9439 - val_loss: 0.2024\n",
      "Epoch 780/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9273 - loss: 0.2275 - val_accuracy: 0.9429 - val_loss: 0.2033\n",
      "Epoch 781/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9302 - loss: 0.2211 - val_accuracy: 0.9455 - val_loss: 0.1980\n",
      "Epoch 782/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9259 - loss: 0.2317 - val_accuracy: 0.9429 - val_loss: 0.2011\n",
      "Epoch 783/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9312 - loss: 0.2139 - val_accuracy: 0.9419 - val_loss: 0.1978\n",
      "Epoch 784/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9251 - loss: 0.2346 - val_accuracy: 0.9439 - val_loss: 0.1988\n",
      "Epoch 785/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9273 - loss: 0.2299 - val_accuracy: 0.9433 - val_loss: 0.2009\n",
      "Epoch 786/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9310 - loss: 0.2126 - val_accuracy: 0.9415 - val_loss: 0.1948\n",
      "Epoch 787/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9292 - loss: 0.2216 - val_accuracy: 0.9393 - val_loss: 0.2037\n",
      "Epoch 788/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9270 - loss: 0.2288 - val_accuracy: 0.9439 - val_loss: 0.1987\n",
      "Epoch 789/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9279 - loss: 0.2271 - val_accuracy: 0.9439 - val_loss: 0.2017\n",
      "Epoch 790/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9308 - loss: 0.2139 - val_accuracy: 0.9399 - val_loss: 0.2063\n",
      "Epoch 791/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9300 - loss: 0.2195 - val_accuracy: 0.9393 - val_loss: 0.2057\n",
      "Epoch 792/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9319 - loss: 0.2106 - val_accuracy: 0.9429 - val_loss: 0.2087\n",
      "Epoch 793/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9306 - loss: 0.2154 - val_accuracy: 0.9443 - val_loss: 0.2015\n",
      "Epoch 794/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9284 - loss: 0.2253 - val_accuracy: 0.9467 - val_loss: 0.2027\n",
      "Epoch 795/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9272 - loss: 0.2318 - val_accuracy: 0.9403 - val_loss: 0.2058\n",
      "Epoch 796/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9261 - loss: 0.2342 - val_accuracy: 0.9433 - val_loss: 0.2000\n",
      "Epoch 797/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9277 - loss: 0.2236 - val_accuracy: 0.9425 - val_loss: 0.1952\n",
      "Epoch 798/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9260 - loss: 0.2259 - val_accuracy: 0.9419 - val_loss: 0.1995\n",
      "Epoch 799/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9264 - loss: 0.2297 - val_accuracy: 0.9441 - val_loss: 0.1949\n",
      "Epoch 800/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9276 - loss: 0.2228 - val_accuracy: 0.9419 - val_loss: 0.1992\n",
      "Epoch 801/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9284 - loss: 0.2232 - val_accuracy: 0.9465 - val_loss: 0.2006\n",
      "Epoch 802/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9277 - loss: 0.2322 - val_accuracy: 0.9465 - val_loss: 0.1972\n",
      "Epoch 803/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9293 - loss: 0.2181 - val_accuracy: 0.9441 - val_loss: 0.2021\n",
      "Epoch 804/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9318 - loss: 0.2122 - val_accuracy: 0.9435 - val_loss: 0.2036\n",
      "Epoch 805/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9314 - loss: 0.2166 - val_accuracy: 0.9449 - val_loss: 0.2036\n",
      "Epoch 806/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9262 - loss: 0.2268 - val_accuracy: 0.9380 - val_loss: 0.2095\n",
      "Epoch 807/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9289 - loss: 0.2165 - val_accuracy: 0.9457 - val_loss: 0.2012\n",
      "Epoch 808/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9306 - loss: 0.2166 - val_accuracy: 0.9476 - val_loss: 0.1978\n",
      "Epoch 809/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9280 - loss: 0.2249 - val_accuracy: 0.9435 - val_loss: 0.2085\n",
      "Epoch 810/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9284 - loss: 0.2208 - val_accuracy: 0.9441 - val_loss: 0.2040\n",
      "Epoch 811/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9311 - loss: 0.2163 - val_accuracy: 0.9417 - val_loss: 0.2045\n",
      "Epoch 812/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9282 - loss: 0.2218 - val_accuracy: 0.9417 - val_loss: 0.2040\n",
      "Epoch 813/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9295 - loss: 0.2193 - val_accuracy: 0.9451 - val_loss: 0.1979\n",
      "Epoch 814/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9297 - loss: 0.2131 - val_accuracy: 0.9439 - val_loss: 0.1947\n",
      "Epoch 815/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9283 - loss: 0.2217 - val_accuracy: 0.9465 - val_loss: 0.1993\n",
      "Epoch 816/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9288 - loss: 0.2221 - val_accuracy: 0.9453 - val_loss: 0.2098\n",
      "Epoch 817/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9281 - loss: 0.2301 - val_accuracy: 0.9463 - val_loss: 0.2008\n",
      "Epoch 818/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9303 - loss: 0.2157 - val_accuracy: 0.9411 - val_loss: 0.2130\n",
      "Epoch 819/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9318 - loss: 0.2142 - val_accuracy: 0.9459 - val_loss: 0.2030\n",
      "Epoch 820/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9258 - loss: 0.2316 - val_accuracy: 0.9441 - val_loss: 0.2025\n",
      "Epoch 821/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9307 - loss: 0.2134 - val_accuracy: 0.9374 - val_loss: 0.2139\n",
      "Epoch 822/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9291 - loss: 0.2176 - val_accuracy: 0.9443 - val_loss: 0.2073\n",
      "Epoch 823/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9268 - loss: 0.2310 - val_accuracy: 0.9433 - val_loss: 0.2033\n",
      "Epoch 824/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9293 - loss: 0.2262 - val_accuracy: 0.9421 - val_loss: 0.2035\n",
      "Epoch 825/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9320 - loss: 0.2107 - val_accuracy: 0.9457 - val_loss: 0.2028\n",
      "Epoch 826/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9281 - loss: 0.2283 - val_accuracy: 0.9427 - val_loss: 0.2059\n",
      "Epoch 827/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9297 - loss: 0.2198 - val_accuracy: 0.9441 - val_loss: 0.2017\n",
      "Epoch 828/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9268 - loss: 0.2300 - val_accuracy: 0.9429 - val_loss: 0.2093\n",
      "Epoch 829/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9272 - loss: 0.2280 - val_accuracy: 0.9425 - val_loss: 0.2057\n",
      "Epoch 830/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9291 - loss: 0.2277 - val_accuracy: 0.9445 - val_loss: 0.2065\n",
      "Epoch 831/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9303 - loss: 0.2188 - val_accuracy: 0.9417 - val_loss: 0.2102\n",
      "Epoch 832/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9303 - loss: 0.2159 - val_accuracy: 0.9449 - val_loss: 0.2081\n",
      "Epoch 833/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9288 - loss: 0.2247 - val_accuracy: 0.9419 - val_loss: 0.2102\n",
      "Epoch 834/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9297 - loss: 0.2164 - val_accuracy: 0.9453 - val_loss: 0.2038\n",
      "Epoch 835/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9290 - loss: 0.2210 - val_accuracy: 0.9413 - val_loss: 0.2134\n",
      "Epoch 836/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9297 - loss: 0.2223 - val_accuracy: 0.9415 - val_loss: 0.2105\n",
      "Epoch 837/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.9294 - loss: 0.2252 - val_accuracy: 0.9431 - val_loss: 0.2019\n",
      "Epoch 838/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9296 - loss: 0.2224 - val_accuracy: 0.9441 - val_loss: 0.1990\n",
      "Epoch 839/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9297 - loss: 0.2186 - val_accuracy: 0.9443 - val_loss: 0.2083\n",
      "Epoch 840/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9283 - loss: 0.2253 - val_accuracy: 0.9419 - val_loss: 0.2085\n",
      "Epoch 841/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9294 - loss: 0.2191 - val_accuracy: 0.9443 - val_loss: 0.2008\n",
      "Epoch 842/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9301 - loss: 0.2197 - val_accuracy: 0.9449 - val_loss: 0.2019\n",
      "Epoch 843/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9292 - loss: 0.2210 - val_accuracy: 0.9427 - val_loss: 0.2063\n",
      "Epoch 844/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9275 - loss: 0.2231 - val_accuracy: 0.9451 - val_loss: 0.2010\n",
      "Epoch 845/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9285 - loss: 0.2237 - val_accuracy: 0.9433 - val_loss: 0.2037\n",
      "Epoch 846/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9266 - loss: 0.2232 - val_accuracy: 0.9399 - val_loss: 0.2123\n",
      "Epoch 847/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9271 - loss: 0.2234 - val_accuracy: 0.9425 - val_loss: 0.2018\n",
      "Epoch 848/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9287 - loss: 0.2238 - val_accuracy: 0.9441 - val_loss: 0.2056\n",
      "Epoch 849/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9310 - loss: 0.2141 - val_accuracy: 0.9453 - val_loss: 0.1970\n",
      "Epoch 850/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9288 - loss: 0.2214 - val_accuracy: 0.9467 - val_loss: 0.1895\n",
      "Epoch 851/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9318 - loss: 0.2166 - val_accuracy: 0.9407 - val_loss: 0.1942\n",
      "Epoch 852/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9316 - loss: 0.2116 - val_accuracy: 0.9443 - val_loss: 0.2029\n",
      "Epoch 853/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9236 - loss: 0.2394 - val_accuracy: 0.9443 - val_loss: 0.1988\n",
      "Epoch 854/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9307 - loss: 0.2145 - val_accuracy: 0.9439 - val_loss: 0.2001\n",
      "Epoch 855/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9289 - loss: 0.2221 - val_accuracy: 0.9447 - val_loss: 0.1994\n",
      "Epoch 856/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9273 - loss: 0.2227 - val_accuracy: 0.9423 - val_loss: 0.2119\n",
      "Epoch 857/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9299 - loss: 0.2226 - val_accuracy: 0.9465 - val_loss: 0.1998\n",
      "Epoch 858/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9304 - loss: 0.2096 - val_accuracy: 0.9421 - val_loss: 0.1990\n",
      "Epoch 859/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9269 - loss: 0.2209 - val_accuracy: 0.9465 - val_loss: 0.1980\n",
      "Epoch 860/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9333 - loss: 0.2141 - val_accuracy: 0.9470 - val_loss: 0.2011\n",
      "Epoch 861/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9311 - loss: 0.2162 - val_accuracy: 0.9441 - val_loss: 0.1965\n",
      "Epoch 862/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9297 - loss: 0.2127 - val_accuracy: 0.9433 - val_loss: 0.1982\n",
      "Epoch 863/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9302 - loss: 0.2150 - val_accuracy: 0.9439 - val_loss: 0.2025\n",
      "Epoch 864/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9278 - loss: 0.2208 - val_accuracy: 0.9451 - val_loss: 0.2045\n",
      "Epoch 865/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9296 - loss: 0.2203 - val_accuracy: 0.9437 - val_loss: 0.2002\n",
      "Epoch 866/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9285 - loss: 0.2263 - val_accuracy: 0.9476 - val_loss: 0.1978\n",
      "Epoch 867/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9293 - loss: 0.2221 - val_accuracy: 0.9453 - val_loss: 0.2043\n",
      "Epoch 868/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9287 - loss: 0.2217 - val_accuracy: 0.9449 - val_loss: 0.1896\n",
      "Epoch 869/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9295 - loss: 0.2169 - val_accuracy: 0.9425 - val_loss: 0.1992\n",
      "Epoch 870/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9320 - loss: 0.2157 - val_accuracy: 0.9443 - val_loss: 0.2018\n",
      "Epoch 871/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9300 - loss: 0.2220 - val_accuracy: 0.9465 - val_loss: 0.1981\n",
      "Epoch 872/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9297 - loss: 0.2115 - val_accuracy: 0.9449 - val_loss: 0.1949\n",
      "Epoch 873/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9296 - loss: 0.2187 - val_accuracy: 0.9447 - val_loss: 0.2050\n",
      "Epoch 874/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9280 - loss: 0.2276 - val_accuracy: 0.9468 - val_loss: 0.1977\n",
      "Epoch 875/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9272 - loss: 0.2339 - val_accuracy: 0.9463 - val_loss: 0.1989\n",
      "Epoch 876/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9284 - loss: 0.2228 - val_accuracy: 0.9433 - val_loss: 0.2034\n",
      "Epoch 877/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9321 - loss: 0.2096 - val_accuracy: 0.9417 - val_loss: 0.2016\n",
      "Epoch 878/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9291 - loss: 0.2186 - val_accuracy: 0.9429 - val_loss: 0.1999\n",
      "Epoch 879/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9293 - loss: 0.2172 - val_accuracy: 0.9455 - val_loss: 0.1950\n",
      "Epoch 880/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9273 - loss: 0.2237 - val_accuracy: 0.9427 - val_loss: 0.2047\n",
      "Epoch 881/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9306 - loss: 0.2185 - val_accuracy: 0.9425 - val_loss: 0.2105\n",
      "Epoch 882/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9277 - loss: 0.2269 - val_accuracy: 0.9449 - val_loss: 0.2028\n",
      "Epoch 883/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9346 - loss: 0.2082 - val_accuracy: 0.9435 - val_loss: 0.1978\n",
      "Epoch 884/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9305 - loss: 0.2189 - val_accuracy: 0.9407 - val_loss: 0.2103\n",
      "Epoch 885/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9270 - loss: 0.2279 - val_accuracy: 0.9437 - val_loss: 0.1947\n",
      "Epoch 886/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9319 - loss: 0.2095 - val_accuracy: 0.9439 - val_loss: 0.1982\n",
      "Epoch 887/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9308 - loss: 0.2170 - val_accuracy: 0.9409 - val_loss: 0.2041\n",
      "Epoch 888/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9308 - loss: 0.2176 - val_accuracy: 0.9443 - val_loss: 0.2103\n",
      "Epoch 889/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9323 - loss: 0.2098 - val_accuracy: 0.9445 - val_loss: 0.2090\n",
      "Epoch 890/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9289 - loss: 0.2206 - val_accuracy: 0.9405 - val_loss: 0.2107\n",
      "Epoch 891/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9300 - loss: 0.2141 - val_accuracy: 0.9461 - val_loss: 0.1962\n",
      "Epoch 892/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9291 - loss: 0.2219 - val_accuracy: 0.9431 - val_loss: 0.2097\n",
      "Epoch 893/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9323 - loss: 0.2133 - val_accuracy: 0.9459 - val_loss: 0.2046\n",
      "Epoch 894/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9295 - loss: 0.2180 - val_accuracy: 0.9429 - val_loss: 0.2030\n",
      "Epoch 895/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9289 - loss: 0.2193 - val_accuracy: 0.9435 - val_loss: 0.2004\n",
      "Epoch 896/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9316 - loss: 0.2124 - val_accuracy: 0.9409 - val_loss: 0.2030\n",
      "Epoch 897/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9325 - loss: 0.2089 - val_accuracy: 0.9425 - val_loss: 0.1964\n",
      "Epoch 898/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9291 - loss: 0.2187 - val_accuracy: 0.9480 - val_loss: 0.2011\n",
      "Epoch 899/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9302 - loss: 0.2182 - val_accuracy: 0.9482 - val_loss: 0.1962\n",
      "Epoch 900/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9290 - loss: 0.2255 - val_accuracy: 0.9465 - val_loss: 0.2015\n",
      "Epoch 901/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9297 - loss: 0.2207 - val_accuracy: 0.9415 - val_loss: 0.2013\n",
      "Epoch 902/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9312 - loss: 0.2168 - val_accuracy: 0.9445 - val_loss: 0.1954\n",
      "Epoch 903/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9298 - loss: 0.2213 - val_accuracy: 0.9387 - val_loss: 0.2090\n",
      "Epoch 904/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9323 - loss: 0.2127 - val_accuracy: 0.9447 - val_loss: 0.2003\n",
      "Epoch 905/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9344 - loss: 0.2105 - val_accuracy: 0.9429 - val_loss: 0.2071\n",
      "Epoch 906/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9303 - loss: 0.2126 - val_accuracy: 0.9453 - val_loss: 0.1992\n",
      "Epoch 907/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9303 - loss: 0.2172 - val_accuracy: 0.9427 - val_loss: 0.2054\n",
      "Epoch 908/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9318 - loss: 0.2189 - val_accuracy: 0.9431 - val_loss: 0.2020\n",
      "Epoch 909/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9313 - loss: 0.2131 - val_accuracy: 0.9425 - val_loss: 0.2049\n",
      "Epoch 910/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9314 - loss: 0.2200 - val_accuracy: 0.9441 - val_loss: 0.2045\n",
      "Epoch 911/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9311 - loss: 0.2148 - val_accuracy: 0.9421 - val_loss: 0.1962\n",
      "Epoch 912/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9270 - loss: 0.2258 - val_accuracy: 0.9413 - val_loss: 0.2053\n",
      "Epoch 913/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9316 - loss: 0.2144 - val_accuracy: 0.9405 - val_loss: 0.2075\n",
      "Epoch 914/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9304 - loss: 0.2191 - val_accuracy: 0.9419 - val_loss: 0.2092\n",
      "Epoch 915/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.9293 - loss: 0.2184 - val_accuracy: 0.9423 - val_loss: 0.2046\n",
      "Epoch 916/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9293 - loss: 0.2125 - val_accuracy: 0.9445 - val_loss: 0.1969\n",
      "Epoch 917/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9310 - loss: 0.2168 - val_accuracy: 0.9431 - val_loss: 0.2033\n",
      "Epoch 918/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9319 - loss: 0.2108 - val_accuracy: 0.9453 - val_loss: 0.2049\n",
      "Epoch 919/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9298 - loss: 0.2187 - val_accuracy: 0.9443 - val_loss: 0.2000\n",
      "Epoch 920/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9308 - loss: 0.2154 - val_accuracy: 0.9443 - val_loss: 0.2029\n",
      "Epoch 921/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9298 - loss: 0.2170 - val_accuracy: 0.9423 - val_loss: 0.1975\n",
      "Epoch 922/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9288 - loss: 0.2171 - val_accuracy: 0.9447 - val_loss: 0.2039\n",
      "Epoch 923/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9304 - loss: 0.2202 - val_accuracy: 0.9445 - val_loss: 0.1965\n",
      "Epoch 924/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9295 - loss: 0.2141 - val_accuracy: 0.9403 - val_loss: 0.2038\n",
      "Epoch 925/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9266 - loss: 0.2231 - val_accuracy: 0.9429 - val_loss: 0.2028\n",
      "Epoch 926/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9309 - loss: 0.2147 - val_accuracy: 0.9480 - val_loss: 0.1870\n",
      "Epoch 927/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9320 - loss: 0.2105 - val_accuracy: 0.9441 - val_loss: 0.1956\n",
      "Epoch 928/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9317 - loss: 0.2130 - val_accuracy: 0.9465 - val_loss: 0.1905\n",
      "Epoch 929/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9280 - loss: 0.2152 - val_accuracy: 0.9429 - val_loss: 0.2074\n",
      "Epoch 930/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9333 - loss: 0.2112 - val_accuracy: 0.9439 - val_loss: 0.2013\n",
      "Epoch 931/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9326 - loss: 0.2151 - val_accuracy: 0.9445 - val_loss: 0.1953\n",
      "Epoch 932/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9313 - loss: 0.2116 - val_accuracy: 0.9445 - val_loss: 0.1985\n",
      "Epoch 933/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9292 - loss: 0.2221 - val_accuracy: 0.9433 - val_loss: 0.2091\n",
      "Epoch 934/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9293 - loss: 0.2216 - val_accuracy: 0.9413 - val_loss: 0.2029\n",
      "Epoch 935/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9308 - loss: 0.2143 - val_accuracy: 0.9439 - val_loss: 0.2047\n",
      "Epoch 936/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9316 - loss: 0.2156 - val_accuracy: 0.9417 - val_loss: 0.2079\n",
      "Epoch 937/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9303 - loss: 0.2166 - val_accuracy: 0.9425 - val_loss: 0.2029\n",
      "Epoch 938/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9301 - loss: 0.2168 - val_accuracy: 0.9409 - val_loss: 0.2074\n",
      "Epoch 939/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9314 - loss: 0.2155 - val_accuracy: 0.9415 - val_loss: 0.2072\n",
      "Epoch 940/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9320 - loss: 0.2062 - val_accuracy: 0.9445 - val_loss: 0.1977\n",
      "Epoch 941/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9319 - loss: 0.2146 - val_accuracy: 0.9453 - val_loss: 0.2029\n",
      "Epoch 942/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9290 - loss: 0.2210 - val_accuracy: 0.9447 - val_loss: 0.1976\n",
      "Epoch 943/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9319 - loss: 0.2078 - val_accuracy: 0.9399 - val_loss: 0.2035\n",
      "Epoch 944/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9302 - loss: 0.2151 - val_accuracy: 0.9445 - val_loss: 0.2046\n",
      "Epoch 945/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9303 - loss: 0.2207 - val_accuracy: 0.9445 - val_loss: 0.2006\n",
      "Epoch 946/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9306 - loss: 0.2164 - val_accuracy: 0.9419 - val_loss: 0.2042\n",
      "Epoch 947/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9335 - loss: 0.2084 - val_accuracy: 0.9457 - val_loss: 0.2074\n",
      "Epoch 948/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9325 - loss: 0.2133 - val_accuracy: 0.9391 - val_loss: 0.2045\n",
      "Epoch 949/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9300 - loss: 0.2152 - val_accuracy: 0.9431 - val_loss: 0.2013\n",
      "Epoch 950/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.9333 - loss: 0.2150 - val_accuracy: 0.9431 - val_loss: 0.2120\n",
      "Epoch 951/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9304 - loss: 0.2172 - val_accuracy: 0.9437 - val_loss: 0.2007\n",
      "Epoch 952/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9299 - loss: 0.2206 - val_accuracy: 0.9441 - val_loss: 0.1997\n",
      "Epoch 953/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9322 - loss: 0.2078 - val_accuracy: 0.9413 - val_loss: 0.1997\n",
      "Epoch 954/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9332 - loss: 0.2137 - val_accuracy: 0.9437 - val_loss: 0.2057\n",
      "Epoch 955/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9333 - loss: 0.2116 - val_accuracy: 0.9415 - val_loss: 0.2049\n",
      "Epoch 956/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9310 - loss: 0.2159 - val_accuracy: 0.9429 - val_loss: 0.2034\n",
      "Epoch 957/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9303 - loss: 0.2185 - val_accuracy: 0.9437 - val_loss: 0.2021\n",
      "Epoch 958/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9304 - loss: 0.2194 - val_accuracy: 0.9405 - val_loss: 0.2092\n",
      "Epoch 959/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9298 - loss: 0.2142 - val_accuracy: 0.9403 - val_loss: 0.2057\n",
      "Epoch 960/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9319 - loss: 0.2134 - val_accuracy: 0.9437 - val_loss: 0.2014\n",
      "Epoch 961/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9309 - loss: 0.2165 - val_accuracy: 0.9415 - val_loss: 0.2035\n",
      "Epoch 962/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9294 - loss: 0.2203 - val_accuracy: 0.9407 - val_loss: 0.2112\n",
      "Epoch 963/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9285 - loss: 0.2122 - val_accuracy: 0.9439 - val_loss: 0.2029\n",
      "Epoch 964/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9342 - loss: 0.2110 - val_accuracy: 0.9437 - val_loss: 0.2020\n",
      "Epoch 965/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9309 - loss: 0.2143 - val_accuracy: 0.9397 - val_loss: 0.2042\n",
      "Epoch 966/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9287 - loss: 0.2244 - val_accuracy: 0.9433 - val_loss: 0.2050\n",
      "Epoch 967/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9295 - loss: 0.2220 - val_accuracy: 0.9449 - val_loss: 0.2002\n",
      "Epoch 968/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9317 - loss: 0.2128 - val_accuracy: 0.9435 - val_loss: 0.2049\n",
      "Epoch 969/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9334 - loss: 0.2127 - val_accuracy: 0.9455 - val_loss: 0.1981\n",
      "Epoch 970/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9303 - loss: 0.2189 - val_accuracy: 0.9413 - val_loss: 0.2095\n",
      "Epoch 971/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9283 - loss: 0.2214 - val_accuracy: 0.9437 - val_loss: 0.2029\n",
      "Epoch 972/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9310 - loss: 0.2165 - val_accuracy: 0.9445 - val_loss: 0.2008\n",
      "Epoch 973/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9291 - loss: 0.2187 - val_accuracy: 0.9431 - val_loss: 0.2030\n",
      "Epoch 974/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9317 - loss: 0.2106 - val_accuracy: 0.9437 - val_loss: 0.2025\n",
      "Epoch 975/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9300 - loss: 0.2192 - val_accuracy: 0.9451 - val_loss: 0.2009\n",
      "Epoch 976/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9320 - loss: 0.2132 - val_accuracy: 0.9433 - val_loss: 0.1989\n",
      "Epoch 977/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9342 - loss: 0.2040 - val_accuracy: 0.9421 - val_loss: 0.2051\n",
      "Epoch 978/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9310 - loss: 0.2184 - val_accuracy: 0.9439 - val_loss: 0.1961\n",
      "Epoch 979/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9337 - loss: 0.2094 - val_accuracy: 0.9449 - val_loss: 0.1991\n",
      "Epoch 980/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9303 - loss: 0.2165 - val_accuracy: 0.9443 - val_loss: 0.2032\n",
      "Epoch 981/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9340 - loss: 0.1990 - val_accuracy: 0.9441 - val_loss: 0.2024\n",
      "Epoch 982/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9317 - loss: 0.2237 - val_accuracy: 0.9399 - val_loss: 0.2069\n",
      "Epoch 983/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9333 - loss: 0.2077 - val_accuracy: 0.9437 - val_loss: 0.1984\n",
      "Epoch 984/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9326 - loss: 0.2161 - val_accuracy: 0.9423 - val_loss: 0.2017\n",
      "Epoch 985/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9323 - loss: 0.2147 - val_accuracy: 0.9441 - val_loss: 0.1979\n",
      "Epoch 986/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9306 - loss: 0.2148 - val_accuracy: 0.9427 - val_loss: 0.2133\n",
      "Epoch 987/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9325 - loss: 0.2090 - val_accuracy: 0.9411 - val_loss: 0.2036\n",
      "Epoch 988/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9320 - loss: 0.2115 - val_accuracy: 0.9429 - val_loss: 0.1995\n",
      "Epoch 989/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9323 - loss: 0.2082 - val_accuracy: 0.9453 - val_loss: 0.1978\n",
      "Epoch 990/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9316 - loss: 0.2130 - val_accuracy: 0.9423 - val_loss: 0.1986\n",
      "Epoch 991/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9305 - loss: 0.2156 - val_accuracy: 0.9470 - val_loss: 0.1922\n",
      "Epoch 992/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9330 - loss: 0.2082 - val_accuracy: 0.9437 - val_loss: 0.2064\n",
      "Epoch 993/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9327 - loss: 0.2148 - val_accuracy: 0.9441 - val_loss: 0.2028\n",
      "Epoch 994/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9338 - loss: 0.2073 - val_accuracy: 0.9411 - val_loss: 0.2056\n",
      "Epoch 995/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9296 - loss: 0.2140 - val_accuracy: 0.9429 - val_loss: 0.2089\n",
      "Epoch 996/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9353 - loss: 0.2042 - val_accuracy: 0.9451 - val_loss: 0.1999\n",
      "Epoch 997/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9310 - loss: 0.2188 - val_accuracy: 0.9427 - val_loss: 0.2025\n",
      "Epoch 998/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.9305 - loss: 0.2138 - val_accuracy: 0.9457 - val_loss: 0.1985\n",
      "Epoch 999/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9334 - loss: 0.2073 - val_accuracy: 0.9435 - val_loss: 0.2012\n",
      "Epoch 1000/1000\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.9327 - loss: 0.2094 - val_accuracy: 0.9451 - val_loss: 0.2020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8619610d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90ded",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(f\"{model_name}.keras\")\n",
    "with open(f\"{model_name}_label.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0155f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/tmpvpnp1v_9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/tmpvpnp1v_9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/jr/p2wykk054vn53_ltf2kxs8s80000gn/T/tmpvpnp1v_9'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 126), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 26), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6311294928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6311296848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6311296272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13784825936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13784826128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13784827472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1760596056.954787 1027334 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1760596056.954797 1027334 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "I0000 00:00:1760596056.957118 1027334 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite file\n",
    "with open(f\"{model_name}.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-rhn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
