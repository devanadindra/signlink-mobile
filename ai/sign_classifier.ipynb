{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397381d5",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow tf2onnx matplotlib numpy opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed27fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall tensorflow tf2onnx matplotlib numpy opencv-python scipy mediapipe pandas tqdm scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18590",
   "metadata": {},
   "source": [
    "# import and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc1fbd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be719935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "model_name = 'sign_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13103e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766be0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./alfabet-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/achmadnoer/alfabet-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66037a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./alfabet-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21028c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = \"Citra BISINDO\"\n",
    "dst_dir = \"./dataset\"\n",
    "\n",
    "if not os.path.exists(src_dir):\n",
    "    raise FileNotFoundError(f\"‚ùå Folder sumber tidak ditemukan: {src_dir}\")\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Memindahkan '{src_dir}' ke '{dst_dir}' ...\")\n",
    "shutil.move(src_dir, dst_dir)\n",
    "print(f\"‚úÖ Berhasil dipindahkan ke {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./indonesian-sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/agungmrf/indonesian-sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    Example: src_folder/cat -> dataset/cat\n",
    "             src_folder/dog -> dataset/dog\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all label folders in the source\n",
    "    for label in os.listdir(src_folder):\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Skip if not a folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Move all files from src ‚Üí dest\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Avoid overwriting files with same name\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_2{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"‚úÖ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset('./bisindo/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset('./bisindo/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1353535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"üóëÔ∏è Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"‚úÖ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeabb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/yunitayupratiwi/bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, based on the first letter of the filename.\n",
    "    Example: src_folder/A.66ae97e2-c1e4-11eb-83d3-0008ca6b6d30.jpg -> dataset/A\n",
    "             src_folder/B.002d8fdf-c1e3-11eb-952a-0008ca6b6d30.jpg -> dataset/B\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all file folders in the source\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "\n",
    "        # Skip if a folder\n",
    "        if os.path.isdir(src_file):\n",
    "            continue\n",
    "        \n",
    "        # Skip if not a jpg\n",
    "        if not src_file.lower().endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        label = filename[0].upper()  # First character as label\n",
    "        dest = os.path.join(dataset_dir, label)\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        dst_file = os.path.join(dest, filename)\n",
    "\n",
    "        # Avoid overwriting files with same name\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            dst_file = os.path.join(dest, f\"{base}_3{ext}\")\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "    print(f\"successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b15a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf12b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./BISINDO - Dataset\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"üóëÔ∏è Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"‚úÖ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/bonarsitorus/sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e87a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_4(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure,\n",
    "    except folders with '_npy' in their name.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "        # Lewati folder yang mengandung '_npy'\n",
    "        if \"_npy\" in label:\n",
    "            continue\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_4{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"‚úÖ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_4('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3406b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./data_tambahan\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"üóëÔ∏è Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"‚úÖ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./indonesian-hand-sign-language-bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/kelsha/indonesian-hand-sign-language-bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-hand-sign-language-bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_5(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_5{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"‚úÖ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bisindo/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d39e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bisindo/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1beb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./dataset_bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"üóëÔ∏è Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"‚úÖ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./bisindo-final.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/skripsiairlangga/bisindo-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ca9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-final.zip\"\n",
    "extract_dir = \"./bisindo_final\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "# Membuat folder extract_dir jika belum ada\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üì¶ Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"‚úÖ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57255468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_6(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_6{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"‚úÖ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_6('./bisindo_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo_final\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"üóëÔ∏è Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"‚úÖ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4257553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    \n",
    "    if not result.multi_hand_landmarks:\n",
    "        return None\n",
    "    \n",
    "    # List semua tangan yang terdeteksi\n",
    "    coords_all = []\n",
    "    for landmarks in result.multi_hand_landmarks:\n",
    "        coords = []\n",
    "        for lm in landmarks.landmark:\n",
    "            coords.extend([lm.x, lm.y, lm.z])\n",
    "        coords_all.append(coords)\n",
    "    \n",
    "    # Jika hanya 1 tangan, tambahkan 0 agar panjang fitur tetap konsisten\n",
    "    if len(coords_all) == 1:\n",
    "        coords_all.append([0.0]*63)  # tangan kosong\n",
    "    \n",
    "    # Flatten dua tangan (kanan + kiri)\n",
    "    features = np.array(coords_all[0] + coords_all[1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label in sorted(os.listdir(dataset_dir)):\n",
    "    label_path = os.path.join(dataset_dir, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing label: {label}')\n",
    "    for img_name in tqdm(os.listdir(label_path)):\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        landmarks = extract_hand_landmarks(img_path)\n",
    "        if landmarks is not None:\n",
    "            data.append(landmarks)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e16017",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"preprocessing\", exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "csv_path = os.path.join(\"preprocessing\", \"hand_keypoints.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Data dan label berhasil disimpan ke {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeba27f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9411987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 25305\n",
      "          0         1             2         3         4         5         6  \\\n",
      "0  0.589252  0.788577  7.732578e-08  0.540710  0.797574 -0.010122  0.494010   \n",
      "1  0.816977  0.762783 -9.139245e-08  0.801779  0.732191  0.003005  0.774102   \n",
      "2  0.725103  0.491935 -4.427249e-07  0.658864  0.500457 -0.027891  0.584359   \n",
      "3  0.188371  0.656543 -8.581127e-08  0.283549  0.646443 -0.036480  0.366026   \n",
      "4  0.113166  0.822599  5.401650e-07  0.195477  0.813338 -0.077608  0.288585   \n",
      "\n",
      "          7         8         9  ...       117       118       119       120  \\\n",
      "0  0.776065 -0.034902  0.458915  ...  0.259818  0.687959 -0.093514  0.256858   \n",
      "1  0.710470  0.000877  0.747481  ...  0.627653  0.740314 -0.056922  0.625121   \n",
      "2  0.476563 -0.053607  0.521293  ...  0.223792  0.330818 -0.103738  0.219856   \n",
      "3  0.589501 -0.066297  0.421726  ...  0.758943  0.368739 -0.107302  0.773216   \n",
      "4  0.775300 -0.115059  0.381177  ...  0.871711  0.542666 -0.079876  0.875374   \n",
      "\n",
      "        121       122       123       124       125  label  \n",
      "0  0.731087 -0.083111  0.242542  0.740920 -0.070938      A  \n",
      "1  0.737795 -0.057063  0.627400  0.744683 -0.054733      A  \n",
      "2  0.384147 -0.090373  0.220490  0.394726 -0.071387      A  \n",
      "3  0.424807 -0.090161  0.791487  0.425094 -0.069101      A  \n",
      "4  0.603269 -0.072792  0.862440  0.643383 -0.055686      A  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_input_path = os.path.join(\"preprocessing\", \"hand_keypoints.csv\")\n",
    "df = pd.read_csv(csv_input_path)\n",
    "print(f\"Total data: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "X = df.drop('label', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9753c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90ded",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(\"models\", f\"{model_name}.keras\")\n",
    "label_path = os.path.join(\"models\", f\"{model_name}_label.pkl\")\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "with open(label_path, \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(f\"‚úÖ Model disimpan di {model_path}\")\n",
    "print(f\"‚úÖ Label encoder disimpan di {label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = os.path.join(\"models\", f\"{model_name}.tflite\")\n",
    "\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"‚úÖ Model TFLite disimpan di {tflite_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "label_path = os.path.join(\"models\", f\"{model_name}_label.pkl\")\n",
    "with open(label_path, \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "labels = le.classes_\n",
    "\n",
    "txt_path = os.path.join(\"models\", \"labels.txt\")\n",
    "with open(txt_path, \"w\") as f:\n",
    "    for label in labels:\n",
    "        f.write(label + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Labels berhasil disimpan di {txt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-rhn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
