{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397381d5",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5efbb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.9 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl (16.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt_einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, idna, grpcio, google_pasta, gast, fonttools, cycler, charset_normalizer, certifi, astunparse, absl-py, werkzeug, scipy, requests, opencv-python, ml_dtypes, markdown-it-py, h5py, contourpy, tensorboard, rich, onnx, matplotlib, tf2onnx, keras, tensorflow\n",
      "\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "   -- -------------------------------------  3/42 [wrapt]\n",
      "   ---- -----------------------------------  5/42 [termcolor]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   --------- ------------------------------ 10/42 [optree]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ------------- -------------------------- 14/42 [MarkupSafe]\n",
      "   ---------------- ----------------------- 17/42 [idna]\n",
      "   ----------------- ---------------------- 18/42 [grpcio]\n",
      "   ------------------ --------------------- 19/42 [google_pasta]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   --------------------- ------------------ 23/42 [charset_normalizer]\n",
      "   ------------------------ --------------- 26/42 [absl-py]\n",
      "   ------------------------- -------------- 27/42 [werkzeug]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   --------------------------- ------------ 29/42 [requests]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ------------------------------ --------- 32/42 [markdown-it-py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------- 42/42 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.10.5 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.9.23 fonttools-4.60.1 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.15.0 idna-3.11 keras-3.11.3 kiwisolver-1.4.9 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.2.6 onnx-1.19.1 opencv-python-4.12.0.88 opt_einsum-3.4.0 optree-0.17.0 pillow-12.0.0 protobuf-6.33.0 pyparsing-3.2.5 requests-2.32.5 rich-14.2.0 scipy-1.16.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 tf2onnx-1.8.4 urllib3-2.5.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tf2onnx matplotlib numpy opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed27fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.20-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.18-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.15-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "  Using cached mediapipe-0.10.14-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.13-cp312-cp312-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: pip is still looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.16.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.15.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.14.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached scipy-1.11.4-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.3-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "  Using cached scipy-1.11.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (192 kB)\n",
      "  Using cached scipy-1.11.1.tar.gz (56.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2 /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.9.1\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: SciPy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 0.29.37)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/usr/local/bin/python3)\n",
      "  \u001b[31m   \u001b[0m Did not find pkg-config by name 'pkg-config'\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: NO\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.12\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-build-env-whd2yr7w/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../../meson.build:82:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/pip-install-7ltpzwj2/scipy_4899f49fa3c74cd79e20f98a23d3ffc2/.mesonpy-lfc2d001/build/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall tensorflow tf2onnx matplotlib numpy opencv-python scipy mediapipe pandas tqdm scikit-learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "908a35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m959.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18590",
   "metadata": {},
   "source": [
    "# import and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbc1fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be719935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "model_name = 'sign_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13103e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766be0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0  114M    0 83232    0     0  54378      0  0:36:51  0:00:01  0:36:50 54378\n",
      "  8  114M    8 10.0M    0     0  4148k      0  0:00:28  0:00:02  0:00:26 10.5M\n",
      " 18  114M   18 21.2M    0     0  6273k      0  0:00:18  0:00:03  0:00:15 10.9M\n",
      " 28  114M   28 32.5M    0     0  7453k      0  0:00:15  0:00:04  0:00:11 11.0M\n",
      " 38  114M   38 43.8M    0     0  8198k      0  0:00:14  0:00:05  0:00:09 11.0M\n",
      " 48  114M   48 55.1M    0     0  8716k      0  0:00:13  0:00:06  0:00:07 11.1M\n",
      " 56  114M   56 65.1M    0     0  8920k      0  0:00:13  0:00:07  0:00:06 11.0M\n",
      " 66  114M   66 76.4M    0     0  9230k      0  0:00:12  0:00:08  0:00:04 11.0M\n",
      " 76  114M   76 87.6M    0     0  9475k      0  0:00:12  0:00:09  0:00:03 11.0M\n",
      " 86  114M   86 98.9M    0     0  9671k      0  0:00:12  0:00:10  0:00:02 11.0M\n",
      " 96  114M   96  110M    0     0  9834k      0  0:00:11  0:00:11 --:--:-- 11.0M\n",
      "100  114M  100  114M    0     0  9892k      0  0:00:11  0:00:11 --:--:-- 11.2M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./alfabet-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/achmadnoer/alfabet-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66037a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./alfabet-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./alfabet-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21028c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Memindahkan 'Citra BISINDO' ke './dataset' ...\n",
      "✅ Berhasil dipindahkan ke ./dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = \"Citra BISINDO\"\n",
    "dst_dir = \"./dataset\"\n",
    "\n",
    "if not os.path.exists(src_dir):\n",
    "    raise FileNotFoundError(f\"❌ Folder sumber tidak ditemukan: {src_dir}\")\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📂 Memindahkan '{src_dir}' ke '{dst_dir}' ...\")\n",
    "shutil.move(src_dir, dst_dir)\n",
    "print(f\"✅ Berhasil dipindahkan ke {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b1bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 1396M    0  110k    0     0  70686      0  5:45:23  0:00:01  5:45:22  111k\n",
      "  0 1396M    0 2528k    0     0   976k      0  0:24:25  0:00:02  0:24:23 1277k\n",
      "  0 1396M    0 7005k    0     0  1950k      0  0:12:13  0:00:03  0:12:10 2350k\n",
      "  0 1396M    0 11.4M    0     0  2551k      0  0:09:20  0:00:04  0:09:16 2942k\n",
      "  1 1396M    1 16.0M    0     0  2945k      0  0:08:05  0:00:05  0:08:00 3306k\n",
      "  1 1396M    1 20.4M    0     0  3179k      0  0:07:29  0:00:06  0:07:23 4178k\n",
      "  1 1396M    1 23.4M    0     0  3167k      0  0:07:31  0:00:07  0:07:24 4303k\n",
      "  1 1396M    1 27.1M    0     0  3238k      0  0:07:21  0:00:08  0:07:13 4164k\n",
      "  2 1396M    2 31.2M    0     0  3337k      0  0:07:08  0:00:09  0:06:59 4059k\n",
      "  2 1396M    2 35.2M    0     0  3403k      0  0:07:00  0:00:10  0:06:50 3915k\n",
      "  2 1396M    2 39.7M    0     0  3511k      0  0:06:47  0:00:11  0:06:36 3948k\n",
      "  3 1396M    3 43.8M    0     0  3566k      0  0:06:41  0:00:12  0:06:29 4172k\n",
      "  3 1396M    3 47.9M    0     0  3614k      0  0:06:35  0:00:13  0:06:22 4259k\n",
      "  3 1396M    3 52.5M    0     0  3688k      0  0:06:27  0:00:14  0:06:13 4361k\n",
      "  4 1396M    4 57.9M    0     0  3804k      0  0:06:16  0:00:15  0:06:01 4652k\n",
      "  4 1396M    4 62.7M    0     0  3871k      0  0:06:09  0:00:16  0:05:53 4708k\n",
      "  4 1396M    4 67.7M    0     0  3943k      0  0:06:02  0:00:17  0:05:45 4892k\n",
      "  5 1396M    5 72.7M    0     0  4004k      0  0:05:57  0:00:18  0:05:39 5064k\n",
      "  5 1396M    5 77.8M    0     0  4067k      0  0:05:51  0:00:19  0:05:32 5173k\n",
      "  5 1396M    5 82.9M    0     0  4124k      0  0:05:46  0:00:20  0:05:26 5123k\n",
      "  6 1396M    6 87.4M    0     0  4149k      0  0:05:44  0:00:21  0:05:23 5073k\n",
      "  6 1396M    6 92.4M    0     0  4191k      0  0:05:41  0:00:22  0:05:19 5061k\n",
      "  6 1396M    6 97.3M    0     0  4225k      0  0:05:38  0:00:23  0:05:15 5049k\n",
      "  7 1396M    7  102M    0     0  4260k      0  0:05:35  0:00:24  0:05:11 5016k\n",
      "  7 1396M    7  107M    0     0  4294k      0  0:05:33  0:00:25  0:05:08 4995k\n",
      "  8 1396M    8  112M    0     0  4318k      0  0:05:31  0:00:26  0:05:05 5046k\n",
      "  8 1396M    8  116M    0     0  4339k      0  0:05:29  0:00:27  0:05:02 5009k\n",
      "  8 1396M    8  121M    0     0  4360k      0  0:05:28  0:00:28  0:05:00 4992k\n",
      "  9 1396M    9  127M    0     0  4404k      0  0:05:24  0:00:29  0:04:55 5111k\n",
      "  9 1396M    9  132M    0     0  4437k      0  0:05:22  0:00:30  0:04:52 5171k\n",
      "  9 1396M    9  137M    0     0  4472k      0  0:05:19  0:00:31  0:04:48 5292k\n",
      " 10 1396M   10  142M    0     0  4486k      0  0:05:18  0:00:32  0:04:46 5299k\n",
      " 10 1396M   10  146M    0     0  4455k      0  0:05:21  0:00:33  0:04:48 5005k\n",
      " 10 1396M   10  150M    0     0  4445k      0  0:05:21  0:00:34  0:04:47 4690k\n",
      " 10 1396M   10  153M    0     0  4416k      0  0:05:23  0:00:35  0:04:48 4284k\n",
      " 11 1396M   11  157M    0     0  4399k      0  0:05:25  0:00:36  0:04:49 3939k\n",
      " 11 1396M   11  160M    0     0  4380k      0  0:05:26  0:00:37  0:04:49 3691k\n",
      " 11 1396M   11  164M    0     0  4364k      0  0:05:27  0:00:38  0:04:49 3750k\n",
      " 12 1396M   12  168M    0     0  4360k      0  0:05:28  0:00:39  0:04:49 3770k\n",
      " 12 1396M   12  172M    0     0  4364k      0  0:05:27  0:00:40  0:04:47 3993k\n",
      " 12 1396M   12  177M    0     0  4368k      0  0:05:27  0:00:41  0:04:46 4140k\n",
      " 12 1396M   12  181M    0     0  4363k      0  0:05:27  0:00:42  0:04:45 4231k\n",
      " 13 1396M   13  185M    0     0  4367k      0  0:05:27  0:00:43  0:04:44 4387k\n",
      " 13 1396M   13  190M    0     0  4370k      0  0:05:27  0:00:44  0:04:43 4454k\n",
      " 13 1396M   13  195M    0     0  4392k      0  0:05:25  0:00:45  0:04:40 4621k\n",
      " 14 1396M   14  202M    0     0  4448k      0  0:05:21  0:00:46  0:04:35 5116k\n",
      " 14 1396M   14  208M    0     0  4489k      0  0:05:18  0:00:47  0:04:31 5561k\n",
      " 15 1396M   15  214M    0     0  4514k      0  0:05:16  0:00:48  0:04:28 5802k\n",
      " 15 1396M   15  219M    0     0  4542k      0  0:05:14  0:00:49  0:04:25 6076k\n",
      " 16 1396M   16  225M    0     0  4567k      0  0:05:13  0:00:50  0:04:23 6166k\n",
      " 16 1396M   16  231M    0     0  4595k      0  0:05:11  0:00:51  0:04:20 5961k\n",
      " 16 1396M   16  237M    0     0  4622k      0  0:05:09  0:00:52  0:04:17 5886k\n",
      " 17 1396M   17  242M    0     0  4636k      0  0:05:08  0:00:53  0:04:15 5820k\n",
      " 17 1396M   17  248M    0     0  4661k      0  0:05:06  0:00:54  0:04:12 5840k\n",
      " 18 1396M   18  254M    0     0  4685k      0  0:05:05  0:00:55  0:04:10 5874k\n",
      " 18 1396M   18  260M    0     0  4720k      0  0:05:03  0:00:56  0:04:07 6006k\n",
      " 19 1396M   19  270M    0     0  4803k      0  0:04:57  0:00:57  0:04:00 6714k\n",
      " 20 1396M   20  281M    0     0  4918k      0  0:04:50  0:00:58  0:03:52 7942k\n",
      " 20 1396M   20  292M    0     0  5029k      0  0:04:44  0:00:59  0:03:45 9049k\n",
      " 21 1396M   21  303M    0     0  5137k      0  0:04:38  0:01:00  0:03:38  9.9M\n",
      " 22 1396M   22  315M    0     0  5241k      0  0:04:32  0:01:01  0:03:31 10.8M\n",
      " 23 1396M   23  325M    0     0  5320k      0  0:04:28  0:01:02  0:03:26 11.0M\n",
      " 24 1396M   24  336M    0     0  5418k      0  0:04:23  0:01:03  0:03:20 11.0M\n",
      " 24 1396M   24  347M    0     0  5513k      0  0:04:19  0:01:04  0:03:15 11.0M\n",
      " 25 1396M   25  359M    0     0  5605k      0  0:04:15  0:01:05  0:03:10 11.0M\n",
      " 26 1396M   26  370M    0     0  5694k      0  0:04:11  0:01:06  0:03:05 11.0M\n",
      " 27 1396M   27  380M    0     0  5762k      0  0:04:08  0:01:07  0:03:01 11.0M\n",
      " 28 1396M   28  391M    0     0  5846k      0  0:04:04  0:01:08  0:02:56 11.0M\n",
      " 28 1396M   28  402M    0     0  5928k      0  0:04:01  0:01:09  0:02:52 11.0M\n",
      " 29 1396M   29  414M    0     0  6008k      0  0:03:58  0:01:10  0:02:48 11.0M\n",
      " 30 1396M   30  425M    0     0  6085k      0  0:03:55  0:01:11  0:02:44 11.0M\n",
      " 31 1396M   31  436M    0     0  6159k      0  0:03:52  0:01:12  0:02:40 11.2M\n",
      " 31 1396M   31  446M    0     0  6216k      0  0:03:50  0:01:13  0:02:37 11.0M\n",
      " 32 1396M   32  458M    0     0  6287k      0  0:03:47  0:01:14  0:02:33 11.0M\n",
      " 33 1396M   33  469M    0     0  6357k      0  0:03:45  0:01:15  0:02:30 11.0M\n",
      " 34 1396M   34  480M    0     0  6424k      0  0:03:42  0:01:16  0:02:26 11.0M\n",
      " 35 1396M   35  490M    0     0  6466k      0  0:03:41  0:01:17  0:02:24 10.6M\n",
      " 35 1396M   35  496M    0     0  6463k      0  0:03:41  0:01:18  0:02:23  9.8M\n",
      " 36 1396M   36  504M    0     0  6494k      0  0:03:40  0:01:19  0:02:21 9580k\n",
      " 36 1396M   36  510M    0     0  6489k      0  0:03:40  0:01:20  0:02:20 8492k\n",
      " 37 1396M   37  521M    0     0  6549k      0  0:03:38  0:01:21  0:02:17 8464k\n",
      " 38 1396M   38  533M    0     0  6608k      0  0:03:36  0:01:22  0:02:14 8824k\n",
      " 38 1396M   38  544M    0     0  6664k      0  0:03:34  0:01:23  0:02:11 9815k\n",
      " 39 1396M   39  554M    0     0  6717k      0  0:03:32  0:01:24  0:02:08 10.0M\n",
      " 40 1396M   40  565M    0     0  6771k      0  0:03:31  0:01:25  0:02:06 11.0M\n",
      " 41 1396M   41  577M    0     0  6826k      0  0:03:29  0:01:26  0:02:03 11.0M\n",
      " 42 1396M   42  588M    0     0  6879k      0  0:03:27  0:01:27  0:02:00 11.0M\n",
      " 42 1396M   42  599M    0     0  6931k      0  0:03:26  0:01:28  0:01:58 11.1M\n",
      " 43 1396M   43  609M    0     0  6964k      0  0:03:25  0:01:29  0:01:56 10.8M\n",
      " 44 1396M   44  620M    0     0  7014k      0  0:03:23  0:01:30  0:01:53 10.9M\n",
      " 45 1396M   45  631M    0     0  7062k      0  0:03:22  0:01:31  0:01:51 10.8M\n",
      " 46 1396M   46  642M    0     0  7110k      0  0:03:21  0:01:32  0:01:49 10.8M\n",
      " 46 1396M   46  654M    0     0  7156k      0  0:03:19  0:01:33  0:01:46 10.8M\n",
      " 47 1396M   47  664M    0     0  7189k      0  0:03:18  0:01:34  0:01:44 10.9M\n",
      " 48 1396M   48  675M    0     0  7234k      0  0:03:17  0:01:35  0:01:42 10.9M\n",
      " 49 1396M   49  686M    0     0  7278k      0  0:03:16  0:01:36  0:01:40 10.9M\n",
      " 49 1396M   49  697M    0     0  7321k      0  0:03:15  0:01:37  0:01:38 10.9M\n",
      " 50 1396M   50  708M    0     0  7363k      0  0:03:14  0:01:38  0:01:36 10.9M\n",
      " 51 1396M   51  720M    0     0  7405k      0  0:03:13  0:01:39  0:01:34 11.2M\n",
      " 52 1396M   52  730M    0     0  7433k      0  0:03:12  0:01:40  0:01:32 10.9M\n",
      " 53 1396M   53  741M    0     0  7473k      0  0:03:11  0:01:41  0:01:30 10.9M\n",
      " 53 1396M   53  752M    0     0  7512k      0  0:03:10  0:01:42  0:01:28 10.9M\n",
      " 54 1396M   54  763M    0     0  7551k      0  0:03:09  0:01:43  0:01:26 10.9M\n",
      " 55 1396M   55  775M    0     0  7589k      0  0:03:08  0:01:44  0:01:24 10.9M\n",
      " 56 1396M   56  785M    0     0  7613k      0  0:03:07  0:01:45  0:01:22 10.9M\n",
      " 57 1396M   57  796M    0     0  7649k      0  0:03:06  0:01:46  0:01:20 10.9M\n",
      " 57 1396M   57  807M    0     0  7685k      0  0:03:06  0:01:47  0:01:19 10.9M\n",
      " 58 1396M   58  818M    0     0  7720k      0  0:03:05  0:01:48  0:01:17 10.9M\n",
      " 59 1396M   59  829M    0     0  7755k      0  0:03:04  0:01:49  0:01:15 10.9M\n",
      " 60 1396M   60  839M    0     0  7777k      0  0:03:03  0:01:50  0:01:13 10.9M\n",
      " 60 1396M   60  851M    0     0  7810k      0  0:03:03  0:01:51  0:01:12 10.9M\n",
      " 61 1396M   61  862M    0     0  7843k      0  0:03:02  0:01:52  0:01:10 10.9M\n",
      " 62 1396M   62  873M    0     0  7875k      0  0:03:01  0:01:53  0:01:08 10.9M\n",
      " 63 1396M   63  884M    0     0  7907k      0  0:03:00  0:01:54  0:01:06 10.9M\n",
      " 64 1396M   64  894M    0     0  7928k      0  0:03:00  0:01:55  0:01:05 11.0M\n",
      " 64 1396M   64  906M    0     0  7958k      0  0:02:59  0:01:56  0:01:03 10.9M\n",
      " 65 1396M   65  917M    0     0  7988k      0  0:02:59  0:01:57  0:01:02 10.9M\n",
      " 66 1396M   66  928M    0     0  8018k      0  0:02:58  0:01:58  0:01:00 10.9M\n",
      " 67 1396M   67  939M    0     0  8047k      0  0:02:57  0:01:59  0:00:58 10.9M\n",
      " 68 1396M   68  950M    0     0  8075k      0  0:02:57  0:02:00  0:00:57 11.2M\n",
      " 68 1396M   68  961M    0     0  8094k      0  0:02:56  0:02:01  0:00:55 10.9M\n",
      " 69 1396M   69  972M    0     0  8121k      0  0:02:56  0:02:02  0:00:54 10.9M\n",
      " 70 1396M   70  983M    0     0  8149k      0  0:02:55  0:02:03  0:00:52 10.9M\n",
      " 71 1396M   71  994M    0     0  8176k      0  0:02:54  0:02:04  0:00:50 10.9M\n",
      " 72 1396M   72 1006M    0     0  8202k      0  0:02:54  0:02:05  0:00:49 11.0M\n",
      " 72 1396M   72 1015M    0     0  8218k      0  0:02:54  0:02:06  0:00:48 10.9M\n",
      " 73 1396M   73 1027M    0     0  8244k      0  0:02:53  0:02:07  0:00:46 10.9M\n",
      " 74 1396M   74 1038M    0     0  8269k      0  0:02:52  0:02:08  0:00:44 10.9M\n",
      " 75 1396M   75 1049M    0     0  8294k      0  0:02:52  0:02:09  0:00:43 10.9M\n",
      " 75 1396M   75 1060M    0     0  8319k      0  0:02:51  0:02:10  0:00:41 10.9M\n",
      " 76 1396M   76 1070M    0     0  8332k      0  0:02:51  0:02:11  0:00:40 10.9M\n",
      " 77 1396M   77 1082M    0     0  8356k      0  0:02:51  0:02:12  0:00:39 10.9M\n",
      " 78 1396M   78 1093M    0     0  8380k      0  0:02:50  0:02:13  0:00:37 10.9M\n",
      " 79 1396M   79 1104M    0     0  8403k      0  0:02:50  0:02:14  0:00:36 10.9M\n",
      " 79 1396M   79 1115M    0     0  8426k      0  0:02:49  0:02:15  0:00:34 10.9M\n",
      " 80 1396M   80 1125M    0     0  8439k      0  0:02:49  0:02:16  0:00:33 10.9M\n",
      " 81 1396M   81 1136M    0     0  8461k      0  0:02:49  0:02:17  0:00:32 10.9M\n",
      " 82 1396M   82 1148M    0     0  8483k      0  0:02:48  0:02:18  0:00:30 10.9M\n",
      " 82 1396M   82 1159M    0     0  8505k      0  0:02:48  0:02:19  0:00:29 10.9M\n",
      " 83 1396M   83 1170M    0     0  8526k      0  0:02:47  0:02:20  0:00:27 10.9M\n",
      " 84 1396M   84 1181M    0     0  8545k      0  0:02:47  0:02:21  0:00:26 11.1M\n",
      " 85 1396M   85 1191M    0     0  8559k      0  0:02:47  0:02:22  0:00:25 10.9M\n",
      " 86 1396M   86 1203M    0     0  8579k      0  0:02:46  0:02:23  0:00:23 10.9M\n",
      " 86 1396M   86 1214M    0     0  8599k      0  0:02:46  0:02:24  0:00:22 10.9M\n",
      " 87 1396M   87 1225M    0     0  8619k      0  0:02:45  0:02:25  0:00:20 10.9M\n",
      " 88 1396M   88 1236M    0     0  8639k      0  0:02:45  0:02:26  0:00:19 11.0M\n",
      " 89 1396M   89 1246M    0     0  8650k      0  0:02:45  0:02:27  0:00:18 10.9M\n",
      " 90 1396M   90 1258M    0     0  8669k      0  0:02:45  0:02:28  0:00:17 10.9M\n",
      " 90 1396M   90 1269M    0     0  8688k      0  0:02:44  0:02:29  0:00:15 10.9M\n",
      " 91 1396M   91 1280M    0     0  8707k      0  0:02:44  0:02:30  0:00:14 10.9M\n",
      " 92 1396M   92 1291M    0     0  8725k      0  0:02:43  0:02:31  0:00:12 10.9M\n",
      " 93 1396M   93 1301M    0     0  8734k      0  0:02:43  0:02:32  0:00:11 10.9M\n",
      " 93 1396M   93 1312M    0     0  8752k      0  0:02:43  0:02:33  0:00:10 10.9M\n",
      " 94 1396M   94 1323M    0     0  8769k      0  0:02:43  0:02:34  0:00:09 10.9M\n",
      " 95 1396M   95 1335M    0     0  8787k      0  0:02:42  0:02:35  0:00:07 10.9M\n",
      " 96 1396M   96 1346M    0     0  8804k      0  0:02:42  0:02:36  0:00:06 10.9M\n",
      " 97 1396M   97 1356M    0     0  8813k      0  0:02:42  0:02:37  0:00:05 10.9M\n",
      " 97 1396M   97 1367M    0     0  8830k      0  0:02:41  0:02:38  0:00:03 10.9M\n",
      " 98 1396M   98 1378M    0     0  8847k      0  0:02:41  0:02:39  0:00:02 10.9M\n",
      " 99 1396M   99 1390M    0     0  8863k      0  0:02:41  0:02:40  0:00:01 10.9M\n",
      "100 1396M  100 1396M    0     0  8874k      0  0:02:41  0:02:41 --:--:-- 10.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/agungmrf/indonesian-sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    Example: src_folder/cat -> dataset/cat\n",
    "             src_folder/dog -> dataset/dog\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all label folders in the source\n",
    "    for label in os.listdir(src_folder):\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Skip if not a folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Move all files from src → dest\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Avoid overwriting files with same name\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_2{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./indonesian-sign-language-bisindo.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61be52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/train' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged './bisindo/images/val' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1353535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./bisindo\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbeabb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/yunitayupratiwi/bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ekstraksi dataset dari ./bisindo-dataset.zip ...\n",
      "✅ Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, based on the first letter of the filename.\n",
    "    Example: src_folder/A.66ae97e2-c1e4-11eb-83d3-0008ca6b6d30.jpg -> dataset/A\n",
    "             src_folder/B.002d8fdf-c1e3-11eb-952a-0008ca6b6d30.jpg -> dataset/B\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all file folders in the source\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "\n",
    "        # Skip if a folder\n",
    "        if os.path.isdir(src_file):\n",
    "            continue\n",
    "        \n",
    "        # Skip if not a jpg\n",
    "        if not src_file.lower().endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        label = filename[0].upper()  # First character as label\n",
    "        dest = os.path.join(dataset_dir, label)\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        dst_file = os.path.join(dest, filename)\n",
    "\n",
    "        # Avoid overwriting files with same name\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            dst_file = os.path.join(dest, f\"{base}_3{ext}\")\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "    print(f\"successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b15a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf12b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e913a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Menghapus folder: ./BISINDO - Dataset\n",
      "✅ Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./BISINDO - Dataset\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/bonarsitorus/sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_4(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure,\n",
    "    except folders with '_npy' in their name.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "        # Lewati folder yang mengandung '_npy'\n",
    "        if \"_npy\" in label:\n",
    "            continue\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_4{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_4('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3406b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./data_tambahan\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-hand-sign-language-bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/kelsha/indonesian-hand-sign-language-bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_5(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_5{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bsindo/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d39e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bsindo/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1beb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./dataset_bsindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-final.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/skripsiairlangga/bisindo-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ca9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-hand-sign-language-bisindo-dataset.zip\"\n",
    "extract_dir = \"./bisindo_final\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "# Membuat folder extract_dir jika belum ada\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📦 Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"✅ Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57255468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_6(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_6{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\"✅ Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_6('./bisindo_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo_final\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"🗑️ Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\"✅ Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\"⚠️ Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc5e9ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760542601.098126   52980 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760542601.117994  202073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760542601.124948  202073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2)  # dua tangan\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4257553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    \n",
    "    if not result.multi_hand_landmarks:\n",
    "        return None\n",
    "    \n",
    "    # List semua tangan yang terdeteksi\n",
    "    coords_all = []\n",
    "    for landmarks in result.multi_hand_landmarks:\n",
    "        coords = []\n",
    "        for lm in landmarks.landmark:\n",
    "            coords.extend([lm.x, lm.y, lm.z])\n",
    "        coords_all.append(coords)\n",
    "    \n",
    "    # Jika hanya 1 tangan, tambahkan 0 agar panjang fitur tetap konsisten\n",
    "    if len(coords_all) == 1:\n",
    "        coords_all.append([0.0]*63)  # tangan kosong\n",
    "    \n",
    "    # Flatten dua tangan (kanan + kiri)\n",
    "    features = np.array(coords_all[0] + coords_all[1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d20d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:14<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 466/466 [00:13<00:00, 33.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 456/456 [00:12<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:16<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:12<00:00, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:13<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:16<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:15<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:13<00:00, 35.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:13<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:15<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:12<00:00, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 471/471 [00:16<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:14<00:00, 31.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:12<00:00, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:15<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:16<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:12<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 456/456 [00:16<00:00, 28.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:16<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 471/471 [00:12<00:00, 37.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:13<00:00, 36.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 471/471 [00:16<00:00, 28.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [00:12<00:00, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:12<00:00, 37.89it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label in sorted(os.listdir(dataset_dir)):\n",
    "    label_path = os.path.join(dataset_dir, label)\n",
    "    if not os.path.isdir(label_path):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing label: {label}')\n",
    "    for img_name in tqdm(os.listdir(label_path)):\n",
    "        img_path = os.path.join(label_path, img_name)\n",
    "        landmarks = extract_hand_landmarks(img_path)\n",
    "        if landmarks is not None:\n",
    "            data.append(landmarks)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7e16017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dan label berhasil disimpan ke hand_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "# Ubah list menjadi DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['label'] = labels\n",
    "\n",
    "# Simpan ke CSV\n",
    "df.to_csv(\"hand_keypoints.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data dan label berhasil disimpan ke hand_keypoints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeba27f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9411987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 9756\n",
      "          0         1             2         3         4         5         6  \\\n",
      "0  0.113166  0.822599  5.401650e-07  0.195477  0.813338 -0.077608  0.288585   \n",
      "1  0.072315  0.750385  4.864663e-07  0.171043  0.754554 -0.077005  0.277623   \n",
      "2  0.114166  0.791155 -3.131314e-08  0.155205  0.775459 -0.035345  0.209606   \n",
      "3  0.757478  0.549036 -2.165960e-07  0.679337  0.564998 -0.018379  0.606947   \n",
      "4  0.718816  0.429549 -1.140924e-07  0.672385  0.437019 -0.020921  0.599781   \n",
      "\n",
      "          7         8         9  ...       117       118       119       120  \\\n",
      "0  0.775300 -0.115059  0.381177  ...  0.871711  0.542666 -0.079876  0.875374   \n",
      "1  0.734710 -0.111966  0.385013  ...  0.899605  0.648649 -0.107626  0.887502   \n",
      "2  0.740575 -0.053146  0.261552  ...  0.451656  0.736039 -0.074687  0.466103   \n",
      "3  0.546419 -0.040267  0.556414  ...  0.318229  0.503575 -0.194958  0.303473   \n",
      "4  0.394989 -0.038702  0.541812  ...  0.312410  0.353749 -0.133061  0.325894   \n",
      "\n",
      "        121       122       123       124       125  label  \n",
      "0  0.603269 -0.072792  0.862440  0.643383 -0.055686      A  \n",
      "1  0.700796 -0.097773  0.863031  0.732057 -0.081237      A  \n",
      "2  0.769476 -0.067641  0.481068  0.758819 -0.057257      A  \n",
      "3  0.528542 -0.174153  0.289089  0.516555 -0.159143      A  \n",
      "4  0.402785 -0.124902  0.330147  0.432855 -0.112889      A  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hand_keypoints.csv\")\n",
    "print(f\"Total data: {len(df)}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8db2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "X = df.drop('label', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84f130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3f9fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "565b55f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,354</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m32,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m3,354\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,762</span> (268.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,762\u001b[0m (268.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c9753c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1788 - loss: 2.7283 - val_accuracy: 0.4452 - val_loss: 2.1028\n",
      "Epoch 2/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4132 - loss: 1.9445 - val_accuracy: 0.6025 - val_loss: 1.5127\n",
      "Epoch 3/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5410 - loss: 1.5113 - val_accuracy: 0.6378 - val_loss: 1.2260\n",
      "Epoch 4/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6114 - loss: 1.2646 - val_accuracy: 0.7351 - val_loss: 0.9604\n",
      "Epoch 5/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6611 - loss: 1.0878 - val_accuracy: 0.7597 - val_loss: 0.8181\n",
      "Epoch 6/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7028 - loss: 0.9669 - val_accuracy: 0.7531 - val_loss: 0.7417\n",
      "Epoch 7/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7303 - loss: 0.8725 - val_accuracy: 0.7946 - val_loss: 0.6382\n",
      "Epoch 8/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7455 - loss: 0.8061 - val_accuracy: 0.8079 - val_loss: 0.6115\n",
      "Epoch 9/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7546 - loss: 0.7757 - val_accuracy: 0.8202 - val_loss: 0.5819\n",
      "Epoch 10/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7751 - loss: 0.7160 - val_accuracy: 0.8325 - val_loss: 0.5399\n",
      "Epoch 11/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7799 - loss: 0.6869 - val_accuracy: 0.8407 - val_loss: 0.5121\n",
      "Epoch 12/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.6500 - val_accuracy: 0.8514 - val_loss: 0.4900\n",
      "Epoch 13/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.6304 - val_accuracy: 0.8499 - val_loss: 0.4725\n",
      "Epoch 14/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8061 - loss: 0.6059 - val_accuracy: 0.8566 - val_loss: 0.4665\n",
      "Epoch 15/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.5789 - val_accuracy: 0.8607 - val_loss: 0.4331\n",
      "Epoch 16/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8141 - loss: 0.5726 - val_accuracy: 0.8699 - val_loss: 0.4271\n",
      "Epoch 17/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.5386 - val_accuracy: 0.8796 - val_loss: 0.4033\n",
      "Epoch 18/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.5143 - val_accuracy: 0.8699 - val_loss: 0.4179\n",
      "Epoch 19/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.5205 - val_accuracy: 0.8904 - val_loss: 0.3666\n",
      "Epoch 20/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.5011 - val_accuracy: 0.8842 - val_loss: 0.3838\n",
      "Epoch 21/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8432 - loss: 0.4973 - val_accuracy: 0.8991 - val_loss: 0.3625\n",
      "Epoch 22/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.4705 - val_accuracy: 0.8883 - val_loss: 0.3519\n",
      "Epoch 23/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.4535 - val_accuracy: 0.8899 - val_loss: 0.3341\n",
      "Epoch 24/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.4669 - val_accuracy: 0.8934 - val_loss: 0.3478\n",
      "Epoch 25/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8574 - loss: 0.4450 - val_accuracy: 0.8919 - val_loss: 0.3385\n",
      "Epoch 26/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.4267 - val_accuracy: 0.9011 - val_loss: 0.3249\n",
      "Epoch 27/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.4208 - val_accuracy: 0.8914 - val_loss: 0.3220\n",
      "Epoch 28/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.4105 - val_accuracy: 0.9144 - val_loss: 0.2866\n",
      "Epoch 29/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8706 - loss: 0.3990 - val_accuracy: 0.8919 - val_loss: 0.3359\n",
      "Epoch 30/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8684 - loss: 0.4043 - val_accuracy: 0.9134 - val_loss: 0.2850\n",
      "Epoch 31/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.3886 - val_accuracy: 0.9093 - val_loss: 0.2831\n",
      "Epoch 32/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8748 - loss: 0.3835 - val_accuracy: 0.9201 - val_loss: 0.2734\n",
      "Epoch 33/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8733 - loss: 0.3733 - val_accuracy: 0.9165 - val_loss: 0.2729\n",
      "Epoch 34/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8803 - loss: 0.3629 - val_accuracy: 0.9134 - val_loss: 0.2688\n",
      "Epoch 35/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.3678 - val_accuracy: 0.9267 - val_loss: 0.2424\n",
      "Epoch 36/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8833 - loss: 0.3621 - val_accuracy: 0.9165 - val_loss: 0.2594\n",
      "Epoch 37/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.3584 - val_accuracy: 0.9165 - val_loss: 0.2530\n",
      "Epoch 38/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.3561 - val_accuracy: 0.9232 - val_loss: 0.2550\n",
      "Epoch 39/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8889 - loss: 0.3390 - val_accuracy: 0.9247 - val_loss: 0.2406\n",
      "Epoch 40/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8865 - loss: 0.3399 - val_accuracy: 0.9247 - val_loss: 0.2391\n",
      "Epoch 41/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3357 - val_accuracy: 0.9339 - val_loss: 0.2269\n",
      "Epoch 42/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.3259 - val_accuracy: 0.9293 - val_loss: 0.2362\n",
      "Epoch 43/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8920 - loss: 0.3247 - val_accuracy: 0.9319 - val_loss: 0.2260\n",
      "Epoch 44/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.3281 - val_accuracy: 0.9283 - val_loss: 0.2269\n",
      "Epoch 45/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.3175 - val_accuracy: 0.9252 - val_loss: 0.2342\n",
      "Epoch 46/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.3143 - val_accuracy: 0.9293 - val_loss: 0.2278\n",
      "Epoch 47/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.3059 - val_accuracy: 0.9365 - val_loss: 0.2253\n",
      "Epoch 48/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8993 - loss: 0.3018 - val_accuracy: 0.9339 - val_loss: 0.2192\n",
      "Epoch 49/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8989 - loss: 0.2987 - val_accuracy: 0.9349 - val_loss: 0.2151\n",
      "Epoch 50/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8939 - loss: 0.3111 - val_accuracy: 0.9308 - val_loss: 0.2263\n",
      "Epoch 51/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3064 - val_accuracy: 0.9314 - val_loss: 0.2126\n",
      "Epoch 52/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2946 - val_accuracy: 0.9360 - val_loss: 0.2202\n",
      "Epoch 53/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.2977 - val_accuracy: 0.9380 - val_loss: 0.2122\n",
      "Epoch 54/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9011 - loss: 0.2965 - val_accuracy: 0.9360 - val_loss: 0.2165\n",
      "Epoch 55/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2856 - val_accuracy: 0.9355 - val_loss: 0.2027\n",
      "Epoch 56/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2897 - val_accuracy: 0.9298 - val_loss: 0.2258\n",
      "Epoch 57/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2953 - val_accuracy: 0.9457 - val_loss: 0.1899\n",
      "Epoch 58/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2858 - val_accuracy: 0.9467 - val_loss: 0.1977\n",
      "Epoch 59/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2690 - val_accuracy: 0.9395 - val_loss: 0.2097\n",
      "Epoch 60/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2748 - val_accuracy: 0.9416 - val_loss: 0.1899\n",
      "Epoch 61/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2805 - val_accuracy: 0.9334 - val_loss: 0.2079\n",
      "Epoch 62/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.2796 - val_accuracy: 0.9370 - val_loss: 0.2013\n",
      "Epoch 63/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2743 - val_accuracy: 0.9447 - val_loss: 0.1900\n",
      "Epoch 64/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2711 - val_accuracy: 0.9436 - val_loss: 0.1788\n",
      "Epoch 65/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2788 - val_accuracy: 0.9457 - val_loss: 0.1847\n",
      "Epoch 66/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2621 - val_accuracy: 0.9370 - val_loss: 0.1914\n",
      "Epoch 67/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2514 - val_accuracy: 0.9477 - val_loss: 0.1746\n",
      "Epoch 68/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2566 - val_accuracy: 0.9344 - val_loss: 0.1995\n",
      "Epoch 69/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2471 - val_accuracy: 0.9426 - val_loss: 0.1921\n",
      "Epoch 70/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2600 - val_accuracy: 0.9334 - val_loss: 0.2119\n",
      "Epoch 71/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2665 - val_accuracy: 0.9416 - val_loss: 0.1920\n",
      "Epoch 72/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2484 - val_accuracy: 0.9508 - val_loss: 0.1679\n",
      "Epoch 73/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2491 - val_accuracy: 0.9493 - val_loss: 0.1686\n",
      "Epoch 74/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2473 - val_accuracy: 0.9442 - val_loss: 0.1770\n",
      "Epoch 75/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2416 - val_accuracy: 0.9426 - val_loss: 0.1857\n",
      "Epoch 76/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2435 - val_accuracy: 0.9452 - val_loss: 0.1769\n",
      "Epoch 77/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2541 - val_accuracy: 0.9390 - val_loss: 0.1843\n",
      "Epoch 78/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2382 - val_accuracy: 0.9411 - val_loss: 0.1755\n",
      "Epoch 79/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2374 - val_accuracy: 0.9488 - val_loss: 0.1766\n",
      "Epoch 80/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9198 - loss: 0.2386 - val_accuracy: 0.9508 - val_loss: 0.1715\n",
      "Epoch 81/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.2377 - val_accuracy: 0.9436 - val_loss: 0.1884\n",
      "Epoch 82/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9226 - loss: 0.2344 - val_accuracy: 0.9457 - val_loss: 0.1786\n",
      "Epoch 83/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2360 - val_accuracy: 0.9493 - val_loss: 0.1692\n",
      "Epoch 84/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2308 - val_accuracy: 0.9457 - val_loss: 0.1721\n",
      "Epoch 85/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.2373 - val_accuracy: 0.9431 - val_loss: 0.1681\n",
      "Epoch 86/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.2380 - val_accuracy: 0.9442 - val_loss: 0.1861\n",
      "Epoch 87/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2383 - val_accuracy: 0.9534 - val_loss: 0.1628\n",
      "Epoch 88/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9207 - loss: 0.2408 - val_accuracy: 0.9442 - val_loss: 0.1764\n",
      "Epoch 89/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2405 - val_accuracy: 0.9477 - val_loss: 0.1706\n",
      "Epoch 90/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2275 - val_accuracy: 0.9554 - val_loss: 0.1569\n",
      "Epoch 91/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2249 - val_accuracy: 0.9503 - val_loss: 0.1678\n",
      "Epoch 92/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2223 - val_accuracy: 0.9524 - val_loss: 0.1588\n",
      "Epoch 93/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2231 - val_accuracy: 0.9385 - val_loss: 0.1922\n",
      "Epoch 94/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2319 - val_accuracy: 0.9462 - val_loss: 0.1708\n",
      "Epoch 95/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2233 - val_accuracy: 0.9549 - val_loss: 0.1605\n",
      "Epoch 96/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.2267 - val_accuracy: 0.9549 - val_loss: 0.1587\n",
      "Epoch 97/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2160 - val_accuracy: 0.9518 - val_loss: 0.1670\n",
      "Epoch 98/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2177 - val_accuracy: 0.9570 - val_loss: 0.1687\n",
      "Epoch 99/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2157 - val_accuracy: 0.9477 - val_loss: 0.1615\n",
      "Epoch 100/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2205 - val_accuracy: 0.9503 - val_loss: 0.1681\n",
      "Epoch 101/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.2147 - val_accuracy: 0.9544 - val_loss: 0.1562\n",
      "Epoch 102/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2223 - val_accuracy: 0.9544 - val_loss: 0.1664\n",
      "Epoch 103/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2040 - val_accuracy: 0.9457 - val_loss: 0.1700\n",
      "Epoch 104/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2185 - val_accuracy: 0.9534 - val_loss: 0.1672\n",
      "Epoch 105/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2134 - val_accuracy: 0.9554 - val_loss: 0.1614\n",
      "Epoch 106/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2167 - val_accuracy: 0.9539 - val_loss: 0.1546\n",
      "Epoch 107/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9236 - loss: 0.2235 - val_accuracy: 0.9575 - val_loss: 0.1421\n",
      "Epoch 108/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2153 - val_accuracy: 0.9549 - val_loss: 0.1492\n",
      "Epoch 109/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2101 - val_accuracy: 0.9600 - val_loss: 0.1524\n",
      "Epoch 110/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2039 - val_accuracy: 0.9580 - val_loss: 0.1437\n",
      "Epoch 111/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2119 - val_accuracy: 0.9503 - val_loss: 0.1566\n",
      "Epoch 112/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2079 - val_accuracy: 0.9595 - val_loss: 0.1440\n",
      "Epoch 113/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1961 - val_accuracy: 0.9534 - val_loss: 0.1699\n",
      "Epoch 114/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.1999 - val_accuracy: 0.9595 - val_loss: 0.1477\n",
      "Epoch 115/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2019 - val_accuracy: 0.9554 - val_loss: 0.1499\n",
      "Epoch 116/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2021 - val_accuracy: 0.9534 - val_loss: 0.1526\n",
      "Epoch 117/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2097 - val_accuracy: 0.9575 - val_loss: 0.1428\n",
      "Epoch 118/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.2176 - val_accuracy: 0.9565 - val_loss: 0.1591\n",
      "Epoch 119/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2062 - val_accuracy: 0.9544 - val_loss: 0.1556\n",
      "Epoch 120/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2058 - val_accuracy: 0.9544 - val_loss: 0.1539\n",
      "Epoch 121/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.1853 - val_accuracy: 0.9590 - val_loss: 0.1465\n",
      "Epoch 122/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.2031 - val_accuracy: 0.9590 - val_loss: 0.1483\n",
      "Epoch 123/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.2014 - val_accuracy: 0.9529 - val_loss: 0.1569\n",
      "Epoch 124/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1976 - val_accuracy: 0.9544 - val_loss: 0.1585\n",
      "Epoch 125/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9318 - loss: 0.2054 - val_accuracy: 0.9488 - val_loss: 0.1560\n",
      "Epoch 126/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1733 - val_accuracy: 0.9621 - val_loss: 0.1445\n",
      "Epoch 127/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2012 - val_accuracy: 0.9565 - val_loss: 0.1610\n",
      "Epoch 128/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9362 - loss: 0.1907 - val_accuracy: 0.9595 - val_loss: 0.1599\n",
      "Epoch 129/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1916 - val_accuracy: 0.9590 - val_loss: 0.1502\n",
      "Epoch 130/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1985 - val_accuracy: 0.9559 - val_loss: 0.1422\n",
      "Epoch 131/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1883 - val_accuracy: 0.9559 - val_loss: 0.1578\n",
      "Epoch 132/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.2072 - val_accuracy: 0.9590 - val_loss: 0.1416\n",
      "Epoch 133/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2010 - val_accuracy: 0.9580 - val_loss: 0.1441\n",
      "Epoch 134/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1834 - val_accuracy: 0.9590 - val_loss: 0.1547\n",
      "Epoch 135/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.1935 - val_accuracy: 0.9549 - val_loss: 0.1538\n",
      "Epoch 136/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1915 - val_accuracy: 0.9554 - val_loss: 0.1561\n",
      "Epoch 137/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1776 - val_accuracy: 0.9559 - val_loss: 0.1499\n",
      "Epoch 138/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.1954 - val_accuracy: 0.9544 - val_loss: 0.1483\n",
      "Epoch 139/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.1827 - val_accuracy: 0.9570 - val_loss: 0.1428\n",
      "Epoch 140/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.1795 - val_accuracy: 0.9585 - val_loss: 0.1438\n",
      "Epoch 141/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.1838 - val_accuracy: 0.9600 - val_loss: 0.1602\n",
      "Epoch 142/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1944 - val_accuracy: 0.9595 - val_loss: 0.1487\n",
      "Epoch 143/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1822 - val_accuracy: 0.9559 - val_loss: 0.1433\n",
      "Epoch 144/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1859 - val_accuracy: 0.9662 - val_loss: 0.1410\n",
      "Epoch 145/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.1805 - val_accuracy: 0.9652 - val_loss: 0.1385\n",
      "Epoch 146/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.1839 - val_accuracy: 0.9606 - val_loss: 0.1469\n",
      "Epoch 147/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1780 - val_accuracy: 0.9636 - val_loss: 0.1349\n",
      "Epoch 148/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1827 - val_accuracy: 0.9662 - val_loss: 0.1317\n",
      "Epoch 149/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1782 - val_accuracy: 0.9606 - val_loss: 0.1498\n",
      "Epoch 150/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.1780 - val_accuracy: 0.9590 - val_loss: 0.1412\n",
      "Epoch 151/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.1889 - val_accuracy: 0.9590 - val_loss: 0.1421\n",
      "Epoch 152/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.1827 - val_accuracy: 0.9693 - val_loss: 0.1385\n",
      "Epoch 153/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.1765 - val_accuracy: 0.9570 - val_loss: 0.1462\n",
      "Epoch 154/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1759 - val_accuracy: 0.9554 - val_loss: 0.1498\n",
      "Epoch 155/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1731 - val_accuracy: 0.9580 - val_loss: 0.1449\n",
      "Epoch 156/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.1893 - val_accuracy: 0.9631 - val_loss: 0.1352\n",
      "Epoch 157/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9380 - loss: 0.1757 - val_accuracy: 0.9575 - val_loss: 0.1393\n",
      "Epoch 158/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.1720 - val_accuracy: 0.9513 - val_loss: 0.1585\n",
      "Epoch 159/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1759 - val_accuracy: 0.9616 - val_loss: 0.1463\n",
      "Epoch 160/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.1760 - val_accuracy: 0.9544 - val_loss: 0.1533\n",
      "Epoch 161/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.1834 - val_accuracy: 0.9580 - val_loss: 0.1385\n",
      "Epoch 162/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1555 - val_accuracy: 0.9626 - val_loss: 0.1448\n",
      "Epoch 163/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.1768 - val_accuracy: 0.9606 - val_loss: 0.1428\n",
      "Epoch 164/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1929 - val_accuracy: 0.9641 - val_loss: 0.1359\n",
      "Epoch 165/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1650 - val_accuracy: 0.9600 - val_loss: 0.1454\n",
      "Epoch 166/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1653 - val_accuracy: 0.9657 - val_loss: 0.1302\n",
      "Epoch 167/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.1750 - val_accuracy: 0.9580 - val_loss: 0.1655\n",
      "Epoch 168/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1852 - val_accuracy: 0.9621 - val_loss: 0.1375\n",
      "Epoch 169/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.1727 - val_accuracy: 0.9616 - val_loss: 0.1401\n",
      "Epoch 170/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.1759 - val_accuracy: 0.9641 - val_loss: 0.1325\n",
      "Epoch 171/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1655 - val_accuracy: 0.9652 - val_loss: 0.1374\n",
      "Epoch 172/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.1662 - val_accuracy: 0.9611 - val_loss: 0.1432\n",
      "Epoch 173/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1808 - val_accuracy: 0.9677 - val_loss: 0.1261\n",
      "Epoch 174/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.1681 - val_accuracy: 0.9662 - val_loss: 0.1442\n",
      "Epoch 175/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1604 - val_accuracy: 0.9611 - val_loss: 0.1323\n",
      "Epoch 176/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1714 - val_accuracy: 0.9688 - val_loss: 0.1295\n",
      "Epoch 177/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.1790 - val_accuracy: 0.9621 - val_loss: 0.1315\n",
      "Epoch 178/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.1660 - val_accuracy: 0.9575 - val_loss: 0.1388\n",
      "Epoch 179/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.1661 - val_accuracy: 0.9641 - val_loss: 0.1328\n",
      "Epoch 180/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1548 - val_accuracy: 0.9693 - val_loss: 0.1206\n",
      "Epoch 181/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1554 - val_accuracy: 0.9606 - val_loss: 0.1381\n",
      "Epoch 182/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1601 - val_accuracy: 0.9672 - val_loss: 0.1327\n",
      "Epoch 183/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1728 - val_accuracy: 0.9667 - val_loss: 0.1326\n",
      "Epoch 184/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1616 - val_accuracy: 0.9652 - val_loss: 0.1303\n",
      "Epoch 185/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.1687 - val_accuracy: 0.9682 - val_loss: 0.1294\n",
      "Epoch 186/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.1702 - val_accuracy: 0.9636 - val_loss: 0.1325\n",
      "Epoch 187/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1774 - val_accuracy: 0.9606 - val_loss: 0.1393\n",
      "Epoch 188/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1626 - val_accuracy: 0.9641 - val_loss: 0.1397\n",
      "Epoch 189/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1597 - val_accuracy: 0.9667 - val_loss: 0.1254\n",
      "Epoch 190/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1647 - val_accuracy: 0.9611 - val_loss: 0.1365\n",
      "Epoch 191/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.1700 - val_accuracy: 0.9606 - val_loss: 0.1242\n",
      "Epoch 192/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1797 - val_accuracy: 0.9682 - val_loss: 0.1270\n",
      "Epoch 193/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1631 - val_accuracy: 0.9688 - val_loss: 0.1243\n",
      "Epoch 194/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1548 - val_accuracy: 0.9677 - val_loss: 0.1255\n",
      "Epoch 195/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1645 - val_accuracy: 0.9621 - val_loss: 0.1312\n",
      "Epoch 196/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.1728 - val_accuracy: 0.9631 - val_loss: 0.1293\n",
      "Epoch 197/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1673 - val_accuracy: 0.9631 - val_loss: 0.1387\n",
      "Epoch 198/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1546 - val_accuracy: 0.9682 - val_loss: 0.1253\n",
      "Epoch 199/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1544 - val_accuracy: 0.9652 - val_loss: 0.1296\n",
      "Epoch 200/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1559 - val_accuracy: 0.9631 - val_loss: 0.1371\n",
      "Epoch 201/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1533 - val_accuracy: 0.9688 - val_loss: 0.1279\n",
      "Epoch 202/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1438 - val_accuracy: 0.9647 - val_loss: 0.1374\n",
      "Epoch 203/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1678 - val_accuracy: 0.9657 - val_loss: 0.1432\n",
      "Epoch 204/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1436 - val_accuracy: 0.9677 - val_loss: 0.1216\n",
      "Epoch 205/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1492 - val_accuracy: 0.9652 - val_loss: 0.1387\n",
      "Epoch 206/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1603 - val_accuracy: 0.9606 - val_loss: 0.1430\n",
      "Epoch 207/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1586 - val_accuracy: 0.9682 - val_loss: 0.1256\n",
      "Epoch 208/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1538 - val_accuracy: 0.9590 - val_loss: 0.1493\n",
      "Epoch 209/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1575 - val_accuracy: 0.9657 - val_loss: 0.1394\n",
      "Epoch 210/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1583 - val_accuracy: 0.9647 - val_loss: 0.1299\n",
      "Epoch 211/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.1632 - val_accuracy: 0.9647 - val_loss: 0.1347\n",
      "Epoch 212/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1518 - val_accuracy: 0.9657 - val_loss: 0.1286\n",
      "Epoch 213/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1695 - val_accuracy: 0.9667 - val_loss: 0.1298\n",
      "Epoch 214/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1463 - val_accuracy: 0.9672 - val_loss: 0.1265\n",
      "Epoch 215/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1517 - val_accuracy: 0.9641 - val_loss: 0.1399\n",
      "Epoch 216/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1433 - val_accuracy: 0.9688 - val_loss: 0.1239\n",
      "Epoch 217/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.1642 - val_accuracy: 0.9636 - val_loss: 0.1360\n",
      "Epoch 218/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1539 - val_accuracy: 0.9677 - val_loss: 0.1267\n",
      "Epoch 219/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1406 - val_accuracy: 0.9703 - val_loss: 0.1268\n",
      "Epoch 220/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1485 - val_accuracy: 0.9585 - val_loss: 0.1518\n",
      "Epoch 221/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1512 - val_accuracy: 0.9703 - val_loss: 0.1298\n",
      "Epoch 222/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1596 - val_accuracy: 0.9677 - val_loss: 0.1329\n",
      "Epoch 223/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1486 - val_accuracy: 0.9647 - val_loss: 0.1462\n",
      "Epoch 224/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1494 - val_accuracy: 0.9703 - val_loss: 0.1293\n",
      "Epoch 225/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1475 - val_accuracy: 0.9677 - val_loss: 0.1261\n",
      "Epoch 226/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1596 - val_accuracy: 0.9754 - val_loss: 0.1178\n",
      "Epoch 227/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1570 - val_accuracy: 0.9647 - val_loss: 0.1375\n",
      "Epoch 228/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1438 - val_accuracy: 0.9723 - val_loss: 0.1195\n",
      "Epoch 229/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1490 - val_accuracy: 0.9631 - val_loss: 0.1347\n",
      "Epoch 230/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1716 - val_accuracy: 0.9682 - val_loss: 0.1243\n",
      "Epoch 231/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1419 - val_accuracy: 0.9682 - val_loss: 0.1252\n",
      "Epoch 232/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1513 - val_accuracy: 0.9667 - val_loss: 0.1236\n",
      "Epoch 233/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1470 - val_accuracy: 0.9641 - val_loss: 0.1298\n",
      "Epoch 234/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1446 - val_accuracy: 0.9606 - val_loss: 0.1295\n",
      "Epoch 235/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1471 - val_accuracy: 0.9682 - val_loss: 0.1365\n",
      "Epoch 236/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1600 - val_accuracy: 0.9641 - val_loss: 0.1254\n",
      "Epoch 237/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1484 - val_accuracy: 0.9636 - val_loss: 0.1391\n",
      "Epoch 238/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1512 - val_accuracy: 0.9667 - val_loss: 0.1305\n",
      "Epoch 239/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1502 - val_accuracy: 0.9688 - val_loss: 0.1278\n",
      "Epoch 240/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1370 - val_accuracy: 0.9713 - val_loss: 0.1272\n",
      "Epoch 241/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1392 - val_accuracy: 0.9698 - val_loss: 0.1221\n",
      "Epoch 242/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1513 - val_accuracy: 0.9652 - val_loss: 0.1317\n",
      "Epoch 243/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1465 - val_accuracy: 0.9652 - val_loss: 0.1333\n",
      "Epoch 244/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1556 - val_accuracy: 0.9667 - val_loss: 0.1298\n",
      "Epoch 245/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1549 - val_accuracy: 0.9693 - val_loss: 0.1147\n",
      "Epoch 246/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1615 - val_accuracy: 0.9723 - val_loss: 0.1156\n",
      "Epoch 247/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1532 - val_accuracy: 0.9657 - val_loss: 0.1304\n",
      "Epoch 248/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1464 - val_accuracy: 0.9718 - val_loss: 0.1238\n",
      "Epoch 249/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1573 - val_accuracy: 0.9698 - val_loss: 0.1209\n",
      "Epoch 250/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1369 - val_accuracy: 0.9662 - val_loss: 0.1274\n",
      "Epoch 251/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1363 - val_accuracy: 0.9682 - val_loss: 0.1248\n",
      "Epoch 252/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1410 - val_accuracy: 0.9713 - val_loss: 0.1195\n",
      "Epoch 253/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1478 - val_accuracy: 0.9647 - val_loss: 0.1425\n",
      "Epoch 254/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1369 - val_accuracy: 0.9693 - val_loss: 0.1306\n",
      "Epoch 255/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1513 - val_accuracy: 0.9631 - val_loss: 0.1406\n",
      "Epoch 256/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1497 - val_accuracy: 0.9713 - val_loss: 0.1236\n",
      "Epoch 257/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1422 - val_accuracy: 0.9708 - val_loss: 0.1230\n",
      "Epoch 258/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1416 - val_accuracy: 0.9708 - val_loss: 0.1112\n",
      "Epoch 259/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1469 - val_accuracy: 0.9728 - val_loss: 0.1221\n",
      "Epoch 260/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1523 - val_accuracy: 0.9703 - val_loss: 0.1241\n",
      "Epoch 261/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1356 - val_accuracy: 0.9728 - val_loss: 0.1135\n",
      "Epoch 262/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1376 - val_accuracy: 0.9688 - val_loss: 0.1360\n",
      "Epoch 263/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1426 - val_accuracy: 0.9703 - val_loss: 0.1241\n",
      "Epoch 264/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1323 - val_accuracy: 0.9652 - val_loss: 0.1402\n",
      "Epoch 265/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1431 - val_accuracy: 0.9703 - val_loss: 0.1211\n",
      "Epoch 266/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1350 - val_accuracy: 0.9713 - val_loss: 0.1239\n",
      "Epoch 267/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1537 - val_accuracy: 0.9641 - val_loss: 0.1401\n",
      "Epoch 268/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1474 - val_accuracy: 0.9652 - val_loss: 0.1281\n",
      "Epoch 269/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1428 - val_accuracy: 0.9636 - val_loss: 0.1403\n",
      "Epoch 270/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1439 - val_accuracy: 0.9713 - val_loss: 0.1197\n",
      "Epoch 271/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1535 - val_accuracy: 0.9682 - val_loss: 0.1290\n",
      "Epoch 272/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1187 - val_accuracy: 0.9723 - val_loss: 0.1263\n",
      "Epoch 273/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1353 - val_accuracy: 0.9636 - val_loss: 0.1272\n",
      "Epoch 274/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1276 - val_accuracy: 0.9672 - val_loss: 0.1279\n",
      "Epoch 275/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1507 - val_accuracy: 0.9652 - val_loss: 0.1294\n",
      "Epoch 276/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1408 - val_accuracy: 0.9657 - val_loss: 0.1352\n",
      "Epoch 277/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1320 - val_accuracy: 0.9698 - val_loss: 0.1366\n",
      "Epoch 278/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1322 - val_accuracy: 0.9713 - val_loss: 0.1264\n",
      "Epoch 279/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1408 - val_accuracy: 0.9718 - val_loss: 0.1209\n",
      "Epoch 280/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1355 - val_accuracy: 0.9631 - val_loss: 0.1317\n",
      "Epoch 281/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1409 - val_accuracy: 0.9693 - val_loss: 0.1218\n",
      "Epoch 282/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1335 - val_accuracy: 0.9667 - val_loss: 0.1408\n",
      "Epoch 283/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1526 - val_accuracy: 0.9672 - val_loss: 0.1317\n",
      "Epoch 284/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1479 - val_accuracy: 0.9698 - val_loss: 0.1230\n",
      "Epoch 285/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1533 - val_accuracy: 0.9682 - val_loss: 0.1343\n",
      "Epoch 286/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1341 - val_accuracy: 0.9606 - val_loss: 0.1467\n",
      "Epoch 287/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1462 - val_accuracy: 0.9682 - val_loss: 0.1244\n",
      "Epoch 288/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1491 - val_accuracy: 0.9723 - val_loss: 0.1333\n",
      "Epoch 289/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1428 - val_accuracy: 0.9688 - val_loss: 0.1380\n",
      "Epoch 290/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1261 - val_accuracy: 0.9718 - val_loss: 0.1327\n",
      "Epoch 291/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1433 - val_accuracy: 0.9713 - val_loss: 0.1267\n",
      "Epoch 292/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1325 - val_accuracy: 0.9723 - val_loss: 0.1216\n",
      "Epoch 293/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1253 - val_accuracy: 0.9734 - val_loss: 0.1156\n",
      "Epoch 294/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1302 - val_accuracy: 0.9672 - val_loss: 0.1367\n",
      "Epoch 295/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1562 - val_accuracy: 0.9708 - val_loss: 0.1218\n",
      "Epoch 296/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1388 - val_accuracy: 0.9698 - val_loss: 0.1225\n",
      "Epoch 297/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.1381 - val_accuracy: 0.9606 - val_loss: 0.1427\n",
      "Epoch 298/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1349 - val_accuracy: 0.9657 - val_loss: 0.1301\n",
      "Epoch 299/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1233 - val_accuracy: 0.9734 - val_loss: 0.1224\n",
      "Epoch 300/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1161 - val_accuracy: 0.9708 - val_loss: 0.1309\n",
      "Epoch 301/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1533 - val_accuracy: 0.9744 - val_loss: 0.1257\n",
      "Epoch 302/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1238 - val_accuracy: 0.9708 - val_loss: 0.1316\n",
      "Epoch 303/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1327 - val_accuracy: 0.9688 - val_loss: 0.1383\n",
      "Epoch 304/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1262 - val_accuracy: 0.9672 - val_loss: 0.1384\n",
      "Epoch 305/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1294 - val_accuracy: 0.9723 - val_loss: 0.1188\n",
      "Epoch 306/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1472 - val_accuracy: 0.9708 - val_loss: 0.1186\n",
      "Epoch 307/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1358 - val_accuracy: 0.9657 - val_loss: 0.1352\n",
      "Epoch 308/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1444 - val_accuracy: 0.9682 - val_loss: 0.1386\n",
      "Epoch 309/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1208 - val_accuracy: 0.9688 - val_loss: 0.1369\n",
      "Epoch 310/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1377 - val_accuracy: 0.9723 - val_loss: 0.1139\n",
      "Epoch 311/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1287 - val_accuracy: 0.9744 - val_loss: 0.1111\n",
      "Epoch 312/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1293 - val_accuracy: 0.9703 - val_loss: 0.1290\n",
      "Epoch 313/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1379 - val_accuracy: 0.9698 - val_loss: 0.1272\n",
      "Epoch 314/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1260 - val_accuracy: 0.9626 - val_loss: 0.1334\n",
      "Epoch 315/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1357 - val_accuracy: 0.9626 - val_loss: 0.1371\n",
      "Epoch 316/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1383 - val_accuracy: 0.9708 - val_loss: 0.1319\n",
      "Epoch 317/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1120 - val_accuracy: 0.9693 - val_loss: 0.1249\n",
      "Epoch 318/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1331 - val_accuracy: 0.9682 - val_loss: 0.1312\n",
      "Epoch 319/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1396 - val_accuracy: 0.9708 - val_loss: 0.1246\n",
      "Epoch 320/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1274 - val_accuracy: 0.9723 - val_loss: 0.1276\n",
      "Epoch 321/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1329 - val_accuracy: 0.9662 - val_loss: 0.1377\n",
      "Epoch 322/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1369 - val_accuracy: 0.9734 - val_loss: 0.1238\n",
      "Epoch 323/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1347 - val_accuracy: 0.9703 - val_loss: 0.1227\n",
      "Epoch 324/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1286 - val_accuracy: 0.9662 - val_loss: 0.1425\n",
      "Epoch 325/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1170 - val_accuracy: 0.9708 - val_loss: 0.1211\n",
      "Epoch 326/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1369 - val_accuracy: 0.9621 - val_loss: 0.1503\n",
      "Epoch 327/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1494 - val_accuracy: 0.9698 - val_loss: 0.1227\n",
      "Epoch 328/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1416 - val_accuracy: 0.9682 - val_loss: 0.1237\n",
      "Epoch 329/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1310 - val_accuracy: 0.9693 - val_loss: 0.1224\n",
      "Epoch 330/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1196 - val_accuracy: 0.9703 - val_loss: 0.1271\n",
      "Epoch 331/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1350 - val_accuracy: 0.9723 - val_loss: 0.1264\n",
      "Epoch 332/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1197 - val_accuracy: 0.9677 - val_loss: 0.1284\n",
      "Epoch 333/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1298 - val_accuracy: 0.9718 - val_loss: 0.1435\n",
      "Epoch 334/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1308 - val_accuracy: 0.9759 - val_loss: 0.1197\n",
      "Epoch 335/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1422 - val_accuracy: 0.9647 - val_loss: 0.1358\n",
      "Epoch 336/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1404 - val_accuracy: 0.9708 - val_loss: 0.1362\n",
      "Epoch 337/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1266 - val_accuracy: 0.9739 - val_loss: 0.1229\n",
      "Epoch 338/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1265 - val_accuracy: 0.9698 - val_loss: 0.1230\n",
      "Epoch 339/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1409 - val_accuracy: 0.9698 - val_loss: 0.1308\n",
      "Epoch 340/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1247 - val_accuracy: 0.9718 - val_loss: 0.1194\n",
      "Epoch 341/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1161 - val_accuracy: 0.9718 - val_loss: 0.1274\n",
      "Epoch 342/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1263 - val_accuracy: 0.9728 - val_loss: 0.1265\n",
      "Epoch 343/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1167 - val_accuracy: 0.9703 - val_loss: 0.1470\n",
      "Epoch 344/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1284 - val_accuracy: 0.9713 - val_loss: 0.1253\n",
      "Epoch 345/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1359 - val_accuracy: 0.9667 - val_loss: 0.1347\n",
      "Epoch 346/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1259 - val_accuracy: 0.9688 - val_loss: 0.1417\n",
      "Epoch 347/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1163 - val_accuracy: 0.9728 - val_loss: 0.1330\n",
      "Epoch 348/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1266 - val_accuracy: 0.9734 - val_loss: 0.1252\n",
      "Epoch 349/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1415 - val_accuracy: 0.9739 - val_loss: 0.1234\n",
      "Epoch 350/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1194 - val_accuracy: 0.9682 - val_loss: 0.1432\n",
      "Epoch 351/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1224 - val_accuracy: 0.9723 - val_loss: 0.1284\n",
      "Epoch 352/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1310 - val_accuracy: 0.9713 - val_loss: 0.1280\n",
      "Epoch 353/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1266 - val_accuracy: 0.9759 - val_loss: 0.1231\n",
      "Epoch 354/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1229 - val_accuracy: 0.9754 - val_loss: 0.1308\n",
      "Epoch 355/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1297 - val_accuracy: 0.9769 - val_loss: 0.1315\n",
      "Epoch 356/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1173 - val_accuracy: 0.9744 - val_loss: 0.1305\n",
      "Epoch 357/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1220 - val_accuracy: 0.9734 - val_loss: 0.1275\n",
      "Epoch 358/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1288 - val_accuracy: 0.9739 - val_loss: 0.1271\n",
      "Epoch 359/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1155 - val_accuracy: 0.9754 - val_loss: 0.1204\n",
      "Epoch 360/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1205 - val_accuracy: 0.9734 - val_loss: 0.1294\n",
      "Epoch 361/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1474 - val_accuracy: 0.9672 - val_loss: 0.1412\n",
      "Epoch 362/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1357 - val_accuracy: 0.9713 - val_loss: 0.1268\n",
      "Epoch 363/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1322 - val_accuracy: 0.9713 - val_loss: 0.1268\n",
      "Epoch 364/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1369 - val_accuracy: 0.9749 - val_loss: 0.1301\n",
      "Epoch 365/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1332 - val_accuracy: 0.9713 - val_loss: 0.1286\n",
      "Epoch 366/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.1160 - val_accuracy: 0.9728 - val_loss: 0.1263\n",
      "Epoch 367/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1299 - val_accuracy: 0.9693 - val_loss: 0.1258\n",
      "Epoch 368/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1180 - val_accuracy: 0.9728 - val_loss: 0.1280\n",
      "Epoch 369/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1296 - val_accuracy: 0.9749 - val_loss: 0.1243\n",
      "Epoch 370/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1198 - val_accuracy: 0.9677 - val_loss: 0.1351\n",
      "Epoch 371/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1249 - val_accuracy: 0.9718 - val_loss: 0.1312\n",
      "Epoch 372/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1236 - val_accuracy: 0.9688 - val_loss: 0.1321\n",
      "Epoch 373/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1134 - val_accuracy: 0.9749 - val_loss: 0.1237\n",
      "Epoch 374/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1294 - val_accuracy: 0.9744 - val_loss: 0.1344\n",
      "Epoch 375/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1258 - val_accuracy: 0.9780 - val_loss: 0.1201\n",
      "Epoch 376/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1101 - val_accuracy: 0.9769 - val_loss: 0.1126\n",
      "Epoch 377/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1159 - val_accuracy: 0.9682 - val_loss: 0.1430\n",
      "Epoch 378/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1288 - val_accuracy: 0.9688 - val_loss: 0.1389\n",
      "Epoch 379/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1316 - val_accuracy: 0.9672 - val_loss: 0.1454\n",
      "Epoch 380/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1181 - val_accuracy: 0.9734 - val_loss: 0.1249\n",
      "Epoch 381/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1169 - val_accuracy: 0.9728 - val_loss: 0.1307\n",
      "Epoch 382/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1194 - val_accuracy: 0.9744 - val_loss: 0.1353\n",
      "Epoch 383/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1257 - val_accuracy: 0.9728 - val_loss: 0.1250\n",
      "Epoch 384/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1136 - val_accuracy: 0.9713 - val_loss: 0.1337\n",
      "Epoch 385/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1220 - val_accuracy: 0.9769 - val_loss: 0.1283\n",
      "Epoch 386/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1198 - val_accuracy: 0.9688 - val_loss: 0.1288\n",
      "Epoch 387/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1214 - val_accuracy: 0.9744 - val_loss: 0.1272\n",
      "Epoch 388/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1173 - val_accuracy: 0.9688 - val_loss: 0.1323\n",
      "Epoch 389/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1307 - val_accuracy: 0.9672 - val_loss: 0.1435\n",
      "Epoch 390/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1179 - val_accuracy: 0.9749 - val_loss: 0.1340\n",
      "Epoch 391/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1221 - val_accuracy: 0.9698 - val_loss: 0.1331\n",
      "Epoch 392/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1301 - val_accuracy: 0.9688 - val_loss: 0.1370\n",
      "Epoch 393/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1134 - val_accuracy: 0.9728 - val_loss: 0.1218\n",
      "Epoch 394/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1300 - val_accuracy: 0.9734 - val_loss: 0.1307\n",
      "Epoch 395/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1173 - val_accuracy: 0.9734 - val_loss: 0.1352\n",
      "Epoch 396/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1177 - val_accuracy: 0.9713 - val_loss: 0.1263\n",
      "Epoch 397/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1196 - val_accuracy: 0.9728 - val_loss: 0.1196\n",
      "Epoch 398/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1295 - val_accuracy: 0.9652 - val_loss: 0.1504\n",
      "Epoch 399/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1243 - val_accuracy: 0.9708 - val_loss: 0.1342\n",
      "Epoch 400/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1231 - val_accuracy: 0.9718 - val_loss: 0.1341\n",
      "Epoch 401/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9572 - loss: 0.1238 - val_accuracy: 0.9718 - val_loss: 0.1290\n",
      "Epoch 402/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1122 - val_accuracy: 0.9718 - val_loss: 0.1218\n",
      "Epoch 403/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1234 - val_accuracy: 0.9693 - val_loss: 0.1282\n",
      "Epoch 404/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1217 - val_accuracy: 0.9728 - val_loss: 0.1143\n",
      "Epoch 405/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1286 - val_accuracy: 0.9688 - val_loss: 0.1367\n",
      "Epoch 406/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1298 - val_accuracy: 0.9734 - val_loss: 0.1242\n",
      "Epoch 407/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9575 - loss: 0.1267 - val_accuracy: 0.9616 - val_loss: 0.1434\n",
      "Epoch 408/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1066 - val_accuracy: 0.9739 - val_loss: 0.1212\n",
      "Epoch 409/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1243 - val_accuracy: 0.9718 - val_loss: 0.1228\n",
      "Epoch 410/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1262 - val_accuracy: 0.9708 - val_loss: 0.1235\n",
      "Epoch 411/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1195 - val_accuracy: 0.9769 - val_loss: 0.1134\n",
      "Epoch 412/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1190 - val_accuracy: 0.9739 - val_loss: 0.1279\n",
      "Epoch 413/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1263 - val_accuracy: 0.9785 - val_loss: 0.1099\n",
      "Epoch 414/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1348 - val_accuracy: 0.9677 - val_loss: 0.1230\n",
      "Epoch 415/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1163 - val_accuracy: 0.9703 - val_loss: 0.1359\n",
      "Epoch 416/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1016 - val_accuracy: 0.9728 - val_loss: 0.1400\n",
      "Epoch 417/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1146 - val_accuracy: 0.9749 - val_loss: 0.1317\n",
      "Epoch 418/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1060 - val_accuracy: 0.9739 - val_loss: 0.1285\n",
      "Epoch 419/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.1100 - val_accuracy: 0.9688 - val_loss: 0.1316\n",
      "Epoch 420/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1233 - val_accuracy: 0.9739 - val_loss: 0.1274\n",
      "Epoch 421/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1079 - val_accuracy: 0.9688 - val_loss: 0.1343\n",
      "Epoch 422/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1244 - val_accuracy: 0.9662 - val_loss: 0.1369\n",
      "Epoch 423/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1122 - val_accuracy: 0.9759 - val_loss: 0.1174\n",
      "Epoch 424/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1166 - val_accuracy: 0.9728 - val_loss: 0.1262\n",
      "Epoch 425/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1124 - val_accuracy: 0.9708 - val_loss: 0.1352\n",
      "Epoch 426/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1264 - val_accuracy: 0.9713 - val_loss: 0.1258\n",
      "Epoch 427/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1130 - val_accuracy: 0.9682 - val_loss: 0.1334\n",
      "Epoch 428/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1141 - val_accuracy: 0.9728 - val_loss: 0.1232\n",
      "Epoch 429/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9590 - loss: 0.1217 - val_accuracy: 0.9744 - val_loss: 0.1328\n",
      "Epoch 430/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1153 - val_accuracy: 0.9713 - val_loss: 0.1341\n",
      "Epoch 431/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1155 - val_accuracy: 0.9739 - val_loss: 0.1351\n",
      "Epoch 432/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1161 - val_accuracy: 0.9723 - val_loss: 0.1270\n",
      "Epoch 433/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1251 - val_accuracy: 0.9708 - val_loss: 0.1340\n",
      "Epoch 434/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1168 - val_accuracy: 0.9723 - val_loss: 0.1325\n",
      "Epoch 435/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1156 - val_accuracy: 0.9728 - val_loss: 0.1120\n",
      "Epoch 436/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1213 - val_accuracy: 0.9754 - val_loss: 0.1199\n",
      "Epoch 437/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1193 - val_accuracy: 0.9759 - val_loss: 0.1255\n",
      "Epoch 438/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1178 - val_accuracy: 0.9754 - val_loss: 0.1287\n",
      "Epoch 439/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1186 - val_accuracy: 0.9728 - val_loss: 0.1295\n",
      "Epoch 440/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1091 - val_accuracy: 0.9754 - val_loss: 0.1146\n",
      "Epoch 441/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1042 - val_accuracy: 0.9693 - val_loss: 0.1259\n",
      "Epoch 442/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1233 - val_accuracy: 0.9734 - val_loss: 0.1224\n",
      "Epoch 443/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1077 - val_accuracy: 0.9734 - val_loss: 0.1265\n",
      "Epoch 444/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1240 - val_accuracy: 0.9734 - val_loss: 0.1224\n",
      "Epoch 445/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1205 - val_accuracy: 0.9759 - val_loss: 0.1210\n",
      "Epoch 446/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1169 - val_accuracy: 0.9744 - val_loss: 0.1222\n",
      "Epoch 447/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1167 - val_accuracy: 0.9744 - val_loss: 0.1056\n",
      "Epoch 448/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1153 - val_accuracy: 0.9677 - val_loss: 0.1355\n",
      "Epoch 449/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1157 - val_accuracy: 0.9723 - val_loss: 0.1334\n",
      "Epoch 450/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1136 - val_accuracy: 0.9713 - val_loss: 0.1343\n",
      "Epoch 451/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1114 - val_accuracy: 0.9739 - val_loss: 0.1292\n",
      "Epoch 452/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1208 - val_accuracy: 0.9677 - val_loss: 0.1404\n",
      "Epoch 453/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9587 - loss: 0.1243 - val_accuracy: 0.9734 - val_loss: 0.1378\n",
      "Epoch 454/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1208 - val_accuracy: 0.9703 - val_loss: 0.1266\n",
      "Epoch 455/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1195 - val_accuracy: 0.9749 - val_loss: 0.1171\n",
      "Epoch 456/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1243 - val_accuracy: 0.9744 - val_loss: 0.1308\n",
      "Epoch 457/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1246 - val_accuracy: 0.9698 - val_loss: 0.1243\n",
      "Epoch 458/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1197 - val_accuracy: 0.9713 - val_loss: 0.1325\n",
      "Epoch 459/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1236 - val_accuracy: 0.9759 - val_loss: 0.1140\n",
      "Epoch 460/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1276 - val_accuracy: 0.9688 - val_loss: 0.1339\n",
      "Epoch 461/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1168 - val_accuracy: 0.9739 - val_loss: 0.1389\n",
      "Epoch 462/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1182 - val_accuracy: 0.9739 - val_loss: 0.1345\n",
      "Epoch 463/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1010 - val_accuracy: 0.9698 - val_loss: 0.1237\n",
      "Epoch 464/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0995 - val_accuracy: 0.9775 - val_loss: 0.1351\n",
      "Epoch 465/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1123 - val_accuracy: 0.9764 - val_loss: 0.1362\n",
      "Epoch 466/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1070 - val_accuracy: 0.9708 - val_loss: 0.1320\n",
      "Epoch 467/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1236 - val_accuracy: 0.9734 - val_loss: 0.1271\n",
      "Epoch 468/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1151 - val_accuracy: 0.9749 - val_loss: 0.1286\n",
      "Epoch 469/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1237 - val_accuracy: 0.9805 - val_loss: 0.1279\n",
      "Epoch 470/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1190 - val_accuracy: 0.9754 - val_loss: 0.1227\n",
      "Epoch 471/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1289 - val_accuracy: 0.9754 - val_loss: 0.1196\n",
      "Epoch 472/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1048 - val_accuracy: 0.9698 - val_loss: 0.1417\n",
      "Epoch 473/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1158 - val_accuracy: 0.9744 - val_loss: 0.1242\n",
      "Epoch 474/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1193 - val_accuracy: 0.9769 - val_loss: 0.1333\n",
      "Epoch 475/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1210 - val_accuracy: 0.9805 - val_loss: 0.1255\n",
      "Epoch 476/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1129 - val_accuracy: 0.9744 - val_loss: 0.1317\n",
      "Epoch 477/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1095 - val_accuracy: 0.9739 - val_loss: 0.1288\n",
      "Epoch 478/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1027 - val_accuracy: 0.9800 - val_loss: 0.1264\n",
      "Epoch 479/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1202 - val_accuracy: 0.9723 - val_loss: 0.1256\n",
      "Epoch 480/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1107 - val_accuracy: 0.9723 - val_loss: 0.1281\n",
      "Epoch 481/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1079 - val_accuracy: 0.9769 - val_loss: 0.1333\n",
      "Epoch 482/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1100 - val_accuracy: 0.9749 - val_loss: 0.1320\n",
      "Epoch 483/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1149 - val_accuracy: 0.9744 - val_loss: 0.1325\n",
      "Epoch 484/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1171 - val_accuracy: 0.9749 - val_loss: 0.1225\n",
      "Epoch 485/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1013 - val_accuracy: 0.9775 - val_loss: 0.1219\n",
      "Epoch 486/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1237 - val_accuracy: 0.9723 - val_loss: 0.1328\n",
      "Epoch 487/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1106 - val_accuracy: 0.9703 - val_loss: 0.1348\n",
      "Epoch 488/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1086 - val_accuracy: 0.9785 - val_loss: 0.1258\n",
      "Epoch 489/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1141 - val_accuracy: 0.9754 - val_loss: 0.1280\n",
      "Epoch 490/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1044 - val_accuracy: 0.9723 - val_loss: 0.1275\n",
      "Epoch 491/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.0931 - val_accuracy: 0.9728 - val_loss: 0.1312\n",
      "Epoch 492/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1178 - val_accuracy: 0.9749 - val_loss: 0.1420\n",
      "Epoch 493/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1224 - val_accuracy: 0.9693 - val_loss: 0.1371\n",
      "Epoch 494/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.1159 - val_accuracy: 0.9698 - val_loss: 0.1476\n",
      "Epoch 495/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1173 - val_accuracy: 0.9693 - val_loss: 0.1381\n",
      "Epoch 496/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1085 - val_accuracy: 0.9764 - val_loss: 0.1266\n",
      "Epoch 497/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1151 - val_accuracy: 0.9682 - val_loss: 0.1346\n",
      "Epoch 498/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1052 - val_accuracy: 0.9780 - val_loss: 0.1280\n",
      "Epoch 499/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1028 - val_accuracy: 0.9723 - val_loss: 0.1306\n",
      "Epoch 500/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1086 - val_accuracy: 0.9739 - val_loss: 0.1290\n",
      "Epoch 501/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1214 - val_accuracy: 0.9780 - val_loss: 0.1198\n",
      "Epoch 502/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1018 - val_accuracy: 0.9759 - val_loss: 0.1337\n",
      "Epoch 503/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.1066 - val_accuracy: 0.9780 - val_loss: 0.1220\n",
      "Epoch 504/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1037 - val_accuracy: 0.9703 - val_loss: 0.1316\n",
      "Epoch 505/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1060 - val_accuracy: 0.9703 - val_loss: 0.1363\n",
      "Epoch 506/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1070 - val_accuracy: 0.9769 - val_loss: 0.1308\n",
      "Epoch 507/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1131 - val_accuracy: 0.9759 - val_loss: 0.1304\n",
      "Epoch 508/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.0982 - val_accuracy: 0.9754 - val_loss: 0.1252\n",
      "Epoch 509/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1153 - val_accuracy: 0.9775 - val_loss: 0.1296\n",
      "Epoch 510/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1095 - val_accuracy: 0.9754 - val_loss: 0.1363\n",
      "Epoch 511/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1056 - val_accuracy: 0.9749 - val_loss: 0.1299\n",
      "Epoch 512/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0963 - val_accuracy: 0.9785 - val_loss: 0.1255\n",
      "Epoch 513/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1088 - val_accuracy: 0.9744 - val_loss: 0.1345\n",
      "Epoch 514/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1132 - val_accuracy: 0.9688 - val_loss: 0.1332\n",
      "Epoch 515/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1047 - val_accuracy: 0.9739 - val_loss: 0.1230\n",
      "Epoch 516/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1108 - val_accuracy: 0.9698 - val_loss: 0.1448\n",
      "Epoch 517/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1154 - val_accuracy: 0.9764 - val_loss: 0.1225\n",
      "Epoch 518/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1087 - val_accuracy: 0.9739 - val_loss: 0.1293\n",
      "Epoch 519/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.0998 - val_accuracy: 0.9734 - val_loss: 0.1352\n",
      "Epoch 520/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1131 - val_accuracy: 0.9785 - val_loss: 0.1271\n",
      "Epoch 521/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1022 - val_accuracy: 0.9759 - val_loss: 0.1417\n",
      "Epoch 522/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0923 - val_accuracy: 0.9775 - val_loss: 0.1298\n",
      "Epoch 523/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.0950 - val_accuracy: 0.9713 - val_loss: 0.1441\n",
      "Epoch 524/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1098 - val_accuracy: 0.9759 - val_loss: 0.1269\n",
      "Epoch 525/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1124 - val_accuracy: 0.9718 - val_loss: 0.1422\n",
      "Epoch 526/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1105 - val_accuracy: 0.9769 - val_loss: 0.1252\n",
      "Epoch 527/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1073 - val_accuracy: 0.9790 - val_loss: 0.1279\n",
      "Epoch 528/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1084 - val_accuracy: 0.9759 - val_loss: 0.1287\n",
      "Epoch 529/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1032 - val_accuracy: 0.9718 - val_loss: 0.1456\n",
      "Epoch 530/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1228 - val_accuracy: 0.9769 - val_loss: 0.1292\n",
      "Epoch 531/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1059 - val_accuracy: 0.9728 - val_loss: 0.1344\n",
      "Epoch 532/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1124 - val_accuracy: 0.9749 - val_loss: 0.1381\n",
      "Epoch 533/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1147 - val_accuracy: 0.9723 - val_loss: 0.1372\n",
      "Epoch 534/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1242 - val_accuracy: 0.9749 - val_loss: 0.1282\n",
      "Epoch 535/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1193 - val_accuracy: 0.9652 - val_loss: 0.1528\n",
      "Epoch 536/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1140 - val_accuracy: 0.9713 - val_loss: 0.1498\n",
      "Epoch 537/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1048 - val_accuracy: 0.9739 - val_loss: 0.1323\n",
      "Epoch 538/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.0999 - val_accuracy: 0.9759 - val_loss: 0.1357\n",
      "Epoch 539/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1163 - val_accuracy: 0.9703 - val_loss: 0.1441\n",
      "Epoch 540/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1016 - val_accuracy: 0.9713 - val_loss: 0.1297\n",
      "Epoch 541/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0974 - val_accuracy: 0.9759 - val_loss: 0.1329\n",
      "Epoch 542/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1105 - val_accuracy: 0.9790 - val_loss: 0.1343\n",
      "Epoch 543/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1123 - val_accuracy: 0.9749 - val_loss: 0.1307\n",
      "Epoch 544/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0891 - val_accuracy: 0.9775 - val_loss: 0.1207\n",
      "Epoch 545/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1147 - val_accuracy: 0.9780 - val_loss: 0.1237\n",
      "Epoch 546/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1109 - val_accuracy: 0.9790 - val_loss: 0.1326\n",
      "Epoch 547/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1048 - val_accuracy: 0.9759 - val_loss: 0.1338\n",
      "Epoch 548/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0968 - val_accuracy: 0.9785 - val_loss: 0.1286\n",
      "Epoch 549/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1045 - val_accuracy: 0.9723 - val_loss: 0.1410\n",
      "Epoch 550/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.0986 - val_accuracy: 0.9775 - val_loss: 0.1267\n",
      "Epoch 551/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1135 - val_accuracy: 0.9759 - val_loss: 0.1298\n",
      "Epoch 552/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1119 - val_accuracy: 0.9754 - val_loss: 0.1261\n",
      "Epoch 553/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1183 - val_accuracy: 0.9693 - val_loss: 0.1428\n",
      "Epoch 554/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9646 - loss: 0.1045 - val_accuracy: 0.9775 - val_loss: 0.1189\n",
      "Epoch 555/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.0981 - val_accuracy: 0.9769 - val_loss: 0.1284\n",
      "Epoch 556/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1031 - val_accuracy: 0.9734 - val_loss: 0.1271\n",
      "Epoch 557/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1231 - val_accuracy: 0.9749 - val_loss: 0.1350\n",
      "Epoch 558/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1136 - val_accuracy: 0.9775 - val_loss: 0.1370\n",
      "Epoch 559/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1041 - val_accuracy: 0.9795 - val_loss: 0.1265\n",
      "Epoch 560/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1145 - val_accuracy: 0.9728 - val_loss: 0.1404\n",
      "Epoch 561/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1091 - val_accuracy: 0.9764 - val_loss: 0.1211\n",
      "Epoch 562/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0947 - val_accuracy: 0.9749 - val_loss: 0.1328\n",
      "Epoch 563/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0917 - val_accuracy: 0.9759 - val_loss: 0.1308\n",
      "Epoch 564/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1209 - val_accuracy: 0.9749 - val_loss: 0.1278\n",
      "Epoch 565/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1059 - val_accuracy: 0.9810 - val_loss: 0.1191\n",
      "Epoch 566/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.1072 - val_accuracy: 0.9769 - val_loss: 0.1332\n",
      "Epoch 567/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1116 - val_accuracy: 0.9744 - val_loss: 0.1273\n",
      "Epoch 568/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.1102 - val_accuracy: 0.9744 - val_loss: 0.1221\n",
      "Epoch 569/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1060 - val_accuracy: 0.9734 - val_loss: 0.1403\n",
      "Epoch 570/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.1097 - val_accuracy: 0.9764 - val_loss: 0.1223\n",
      "Epoch 571/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1109 - val_accuracy: 0.9734 - val_loss: 0.1305\n",
      "Epoch 572/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9614 - loss: 0.1096 - val_accuracy: 0.9790 - val_loss: 0.1197\n",
      "Epoch 573/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.0997 - val_accuracy: 0.9769 - val_loss: 0.1349\n",
      "Epoch 574/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1164 - val_accuracy: 0.9769 - val_loss: 0.1185\n",
      "Epoch 575/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1136 - val_accuracy: 0.9713 - val_loss: 0.1367\n",
      "Epoch 576/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1022 - val_accuracy: 0.9780 - val_loss: 0.1316\n",
      "Epoch 577/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1070 - val_accuracy: 0.9754 - val_loss: 0.1381\n",
      "Epoch 578/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1119 - val_accuracy: 0.9754 - val_loss: 0.1250\n",
      "Epoch 579/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1095 - val_accuracy: 0.9785 - val_loss: 0.1267\n",
      "Epoch 580/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0898 - val_accuracy: 0.9749 - val_loss: 0.1280\n",
      "Epoch 581/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1083 - val_accuracy: 0.9713 - val_loss: 0.1326\n",
      "Epoch 582/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0964 - val_accuracy: 0.9769 - val_loss: 0.1418\n",
      "Epoch 583/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.1010 - val_accuracy: 0.9759 - val_loss: 0.1370\n",
      "Epoch 584/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.1000 - val_accuracy: 0.9769 - val_loss: 0.1361\n",
      "Epoch 585/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1129 - val_accuracy: 0.9739 - val_loss: 0.1444\n",
      "Epoch 586/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1086 - val_accuracy: 0.9662 - val_loss: 0.1626\n",
      "Epoch 587/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1193 - val_accuracy: 0.9754 - val_loss: 0.1261\n",
      "Epoch 588/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1052 - val_accuracy: 0.9749 - val_loss: 0.1274\n",
      "Epoch 589/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1122 - val_accuracy: 0.9739 - val_loss: 0.1316\n",
      "Epoch 590/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1121 - val_accuracy: 0.9775 - val_loss: 0.1258\n",
      "Epoch 591/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.1059 - val_accuracy: 0.9728 - val_loss: 0.1354\n",
      "Epoch 592/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.1140 - val_accuracy: 0.9703 - val_loss: 0.1389\n",
      "Epoch 593/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1142 - val_accuracy: 0.9744 - val_loss: 0.1316\n",
      "Epoch 594/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0917 - val_accuracy: 0.9718 - val_loss: 0.1438\n",
      "Epoch 595/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0967 - val_accuracy: 0.9759 - val_loss: 0.1338\n",
      "Epoch 596/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1086 - val_accuracy: 0.9728 - val_loss: 0.1258\n",
      "Epoch 597/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0918 - val_accuracy: 0.9759 - val_loss: 0.1302\n",
      "Epoch 598/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1076 - val_accuracy: 0.9744 - val_loss: 0.1432\n",
      "Epoch 599/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0932 - val_accuracy: 0.9734 - val_loss: 0.1366\n",
      "Epoch 600/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1072 - val_accuracy: 0.9739 - val_loss: 0.1417\n",
      "Epoch 601/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1155 - val_accuracy: 0.9764 - val_loss: 0.1330\n",
      "Epoch 602/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1054 - val_accuracy: 0.9780 - val_loss: 0.1343\n",
      "Epoch 603/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1012 - val_accuracy: 0.9754 - val_loss: 0.1344\n",
      "Epoch 604/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0955 - val_accuracy: 0.9769 - val_loss: 0.1325\n",
      "Epoch 605/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1032 - val_accuracy: 0.9728 - val_loss: 0.1356\n",
      "Epoch 606/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1206 - val_accuracy: 0.9739 - val_loss: 0.1347\n",
      "Epoch 607/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.0999 - val_accuracy: 0.9764 - val_loss: 0.1378\n",
      "Epoch 608/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1027 - val_accuracy: 0.9708 - val_loss: 0.1428\n",
      "Epoch 609/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1014 - val_accuracy: 0.9703 - val_loss: 0.1463\n",
      "Epoch 610/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1027 - val_accuracy: 0.9749 - val_loss: 0.1395\n",
      "Epoch 611/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1034 - val_accuracy: 0.9769 - val_loss: 0.1304\n",
      "Epoch 612/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0954 - val_accuracy: 0.9734 - val_loss: 0.1393\n",
      "Epoch 613/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1148 - val_accuracy: 0.9749 - val_loss: 0.1346\n",
      "Epoch 614/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0996 - val_accuracy: 0.9749 - val_loss: 0.1323\n",
      "Epoch 615/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1141 - val_accuracy: 0.9698 - val_loss: 0.1592\n",
      "Epoch 616/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1080 - val_accuracy: 0.9769 - val_loss: 0.1366\n",
      "Epoch 617/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1073 - val_accuracy: 0.9708 - val_loss: 0.1598\n",
      "Epoch 618/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1170 - val_accuracy: 0.9744 - val_loss: 0.1322\n",
      "Epoch 619/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0951 - val_accuracy: 0.9775 - val_loss: 0.1220\n",
      "Epoch 620/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1057 - val_accuracy: 0.9728 - val_loss: 0.1316\n",
      "Epoch 621/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9609 - loss: 0.1116 - val_accuracy: 0.9780 - val_loss: 0.1310\n",
      "Epoch 622/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1019 - val_accuracy: 0.9780 - val_loss: 0.1243\n",
      "Epoch 623/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0986 - val_accuracy: 0.9780 - val_loss: 0.1385\n",
      "Epoch 624/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1080 - val_accuracy: 0.9739 - val_loss: 0.1293\n",
      "Epoch 625/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1086 - val_accuracy: 0.9749 - val_loss: 0.1258\n",
      "Epoch 626/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1083 - val_accuracy: 0.9744 - val_loss: 0.1349\n",
      "Epoch 627/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1025 - val_accuracy: 0.9744 - val_loss: 0.1442\n",
      "Epoch 628/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1001 - val_accuracy: 0.9780 - val_loss: 0.1308\n",
      "Epoch 629/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0946 - val_accuracy: 0.9734 - val_loss: 0.1471\n",
      "Epoch 630/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0955 - val_accuracy: 0.9785 - val_loss: 0.1332\n",
      "Epoch 631/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0951 - val_accuracy: 0.9764 - val_loss: 0.1348\n",
      "Epoch 632/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0905 - val_accuracy: 0.9734 - val_loss: 0.1385\n",
      "Epoch 633/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.1037 - val_accuracy: 0.9790 - val_loss: 0.1285\n",
      "Epoch 634/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0922 - val_accuracy: 0.9800 - val_loss: 0.1243\n",
      "Epoch 635/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.0993 - val_accuracy: 0.9759 - val_loss: 0.1277\n",
      "Epoch 636/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1065 - val_accuracy: 0.9800 - val_loss: 0.1377\n",
      "Epoch 637/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1057 - val_accuracy: 0.9744 - val_loss: 0.1446\n",
      "Epoch 638/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9610 - loss: 0.1215 - val_accuracy: 0.9749 - val_loss: 0.1313\n",
      "Epoch 639/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1052 - val_accuracy: 0.9734 - val_loss: 0.1453\n",
      "Epoch 640/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1191 - val_accuracy: 0.9754 - val_loss: 0.1372\n",
      "Epoch 641/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1007 - val_accuracy: 0.9759 - val_loss: 0.1270\n",
      "Epoch 642/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.1017 - val_accuracy: 0.9693 - val_loss: 0.1326\n",
      "Epoch 643/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.0976 - val_accuracy: 0.9764 - val_loss: 0.1308\n",
      "Epoch 644/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0956 - val_accuracy: 0.9734 - val_loss: 0.1328\n",
      "Epoch 645/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1127 - val_accuracy: 0.9795 - val_loss: 0.1254\n",
      "Epoch 646/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1104 - val_accuracy: 0.9795 - val_loss: 0.1225\n",
      "Epoch 647/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1078 - val_accuracy: 0.9713 - val_loss: 0.1326\n",
      "Epoch 648/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1167 - val_accuracy: 0.9754 - val_loss: 0.1298\n",
      "Epoch 649/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1072 - val_accuracy: 0.9775 - val_loss: 0.1265\n",
      "Epoch 650/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1071 - val_accuracy: 0.9769 - val_loss: 0.1370\n",
      "Epoch 651/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0946 - val_accuracy: 0.9810 - val_loss: 0.1205\n",
      "Epoch 652/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1005 - val_accuracy: 0.9764 - val_loss: 0.1246\n",
      "Epoch 653/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0904 - val_accuracy: 0.9769 - val_loss: 0.1268\n",
      "Epoch 654/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1023 - val_accuracy: 0.9764 - val_loss: 0.1329\n",
      "Epoch 655/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0919 - val_accuracy: 0.9759 - val_loss: 0.1334\n",
      "Epoch 656/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.1035 - val_accuracy: 0.9764 - val_loss: 0.1226\n",
      "Epoch 657/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0927 - val_accuracy: 0.9795 - val_loss: 0.1381\n",
      "Epoch 658/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.1026 - val_accuracy: 0.9759 - val_loss: 0.1446\n",
      "Epoch 659/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1104 - val_accuracy: 0.9728 - val_loss: 0.1392\n",
      "Epoch 660/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0945 - val_accuracy: 0.9759 - val_loss: 0.1319\n",
      "Epoch 661/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.0968 - val_accuracy: 0.9775 - val_loss: 0.1274\n",
      "Epoch 662/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.0969 - val_accuracy: 0.9759 - val_loss: 0.1193\n",
      "Epoch 663/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1103 - val_accuracy: 0.9785 - val_loss: 0.1337\n",
      "Epoch 664/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1033 - val_accuracy: 0.9749 - val_loss: 0.1297\n",
      "Epoch 665/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0937 - val_accuracy: 0.9759 - val_loss: 0.1314\n",
      "Epoch 666/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1047 - val_accuracy: 0.9744 - val_loss: 0.1496\n",
      "Epoch 667/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0966 - val_accuracy: 0.9749 - val_loss: 0.1400\n",
      "Epoch 668/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0932 - val_accuracy: 0.9780 - val_loss: 0.1330\n",
      "Epoch 669/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.0919 - val_accuracy: 0.9769 - val_loss: 0.1371\n",
      "Epoch 670/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1060 - val_accuracy: 0.9764 - val_loss: 0.1353\n",
      "Epoch 671/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0991 - val_accuracy: 0.9764 - val_loss: 0.1302\n",
      "Epoch 672/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1004 - val_accuracy: 0.9754 - val_loss: 0.1441\n",
      "Epoch 673/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.0966 - val_accuracy: 0.9775 - val_loss: 0.1396\n",
      "Epoch 674/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.0992 - val_accuracy: 0.9708 - val_loss: 0.1481\n",
      "Epoch 675/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.0989 - val_accuracy: 0.9739 - val_loss: 0.1433\n",
      "Epoch 676/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1015 - val_accuracy: 0.9780 - val_loss: 0.1311\n",
      "Epoch 677/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0945 - val_accuracy: 0.9739 - val_loss: 0.1225\n",
      "Epoch 678/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9701 - loss: 0.0832 - val_accuracy: 0.9785 - val_loss: 0.1301\n",
      "Epoch 679/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1059 - val_accuracy: 0.9810 - val_loss: 0.1164\n",
      "Epoch 680/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.0963 - val_accuracy: 0.9790 - val_loss: 0.1329\n",
      "Epoch 681/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.0995 - val_accuracy: 0.9754 - val_loss: 0.1215\n",
      "Epoch 682/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0909 - val_accuracy: 0.9759 - val_loss: 0.1456\n",
      "Epoch 683/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.0992 - val_accuracy: 0.9734 - val_loss: 0.1550\n",
      "Epoch 684/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.1088 - val_accuracy: 0.9734 - val_loss: 0.1386\n",
      "Epoch 685/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0955 - val_accuracy: 0.9754 - val_loss: 0.1279\n",
      "Epoch 686/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0991 - val_accuracy: 0.9754 - val_loss: 0.1307\n",
      "Epoch 687/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1063 - val_accuracy: 0.9785 - val_loss: 0.1332\n",
      "Epoch 688/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.1093 - val_accuracy: 0.9728 - val_loss: 0.1418\n",
      "Epoch 689/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0960 - val_accuracy: 0.9759 - val_loss: 0.1263\n",
      "Epoch 690/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1085 - val_accuracy: 0.9723 - val_loss: 0.1310\n",
      "Epoch 691/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1097 - val_accuracy: 0.9780 - val_loss: 0.1364\n",
      "Epoch 692/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1043 - val_accuracy: 0.9728 - val_loss: 0.1412\n",
      "Epoch 693/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0903 - val_accuracy: 0.9754 - val_loss: 0.1430\n",
      "Epoch 694/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0866 - val_accuracy: 0.9754 - val_loss: 0.1394\n",
      "Epoch 695/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1008 - val_accuracy: 0.9744 - val_loss: 0.1355\n",
      "Epoch 696/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0950 - val_accuracy: 0.9713 - val_loss: 0.1487\n",
      "Epoch 697/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9646 - loss: 0.1097 - val_accuracy: 0.9754 - val_loss: 0.1411\n",
      "Epoch 698/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1079 - val_accuracy: 0.9734 - val_loss: 0.1477\n",
      "Epoch 699/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0965 - val_accuracy: 0.9754 - val_loss: 0.1472\n",
      "Epoch 700/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9614 - loss: 0.1058 - val_accuracy: 0.9759 - val_loss: 0.1385\n",
      "Epoch 701/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9646 - loss: 0.1117 - val_accuracy: 0.9749 - val_loss: 0.1372\n",
      "Epoch 702/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1189 - val_accuracy: 0.9769 - val_loss: 0.1384\n",
      "Epoch 703/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1055 - val_accuracy: 0.9734 - val_loss: 0.1416\n",
      "Epoch 704/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0889 - val_accuracy: 0.9749 - val_loss: 0.1408\n",
      "Epoch 705/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.1023 - val_accuracy: 0.9775 - val_loss: 0.1480\n",
      "Epoch 706/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1142 - val_accuracy: 0.9677 - val_loss: 0.1504\n",
      "Epoch 707/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0918 - val_accuracy: 0.9744 - val_loss: 0.1496\n",
      "Epoch 708/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0979 - val_accuracy: 0.9749 - val_loss: 0.1441\n",
      "Epoch 709/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.1010 - val_accuracy: 0.9744 - val_loss: 0.1379\n",
      "Epoch 710/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0970 - val_accuracy: 0.9764 - val_loss: 0.1516\n",
      "Epoch 711/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1050 - val_accuracy: 0.9785 - val_loss: 0.1352\n",
      "Epoch 712/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0942 - val_accuracy: 0.9759 - val_loss: 0.1426\n",
      "Epoch 713/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.1021 - val_accuracy: 0.9718 - val_loss: 0.1390\n",
      "Epoch 714/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1123 - val_accuracy: 0.9759 - val_loss: 0.1344\n",
      "Epoch 715/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1006 - val_accuracy: 0.9764 - val_loss: 0.1353\n",
      "Epoch 716/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1146 - val_accuracy: 0.9759 - val_loss: 0.1206\n",
      "Epoch 717/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0914 - val_accuracy: 0.9749 - val_loss: 0.1338\n",
      "Epoch 718/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0913 - val_accuracy: 0.9754 - val_loss: 0.1291\n",
      "Epoch 719/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0845 - val_accuracy: 0.9780 - val_loss: 0.1278\n",
      "Epoch 720/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0973 - val_accuracy: 0.9759 - val_loss: 0.1327\n",
      "Epoch 721/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0978 - val_accuracy: 0.9790 - val_loss: 0.1284\n",
      "Epoch 722/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0937 - val_accuracy: 0.9754 - val_loss: 0.1250\n",
      "Epoch 723/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1006 - val_accuracy: 0.9734 - val_loss: 0.1297\n",
      "Epoch 724/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.1037 - val_accuracy: 0.9749 - val_loss: 0.1299\n",
      "Epoch 725/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0951 - val_accuracy: 0.9785 - val_loss: 0.1214\n",
      "Epoch 726/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1014 - val_accuracy: 0.9723 - val_loss: 0.1443\n",
      "Epoch 727/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0841 - val_accuracy: 0.9780 - val_loss: 0.1277\n",
      "Epoch 728/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.0966 - val_accuracy: 0.9754 - val_loss: 0.1266\n",
      "Epoch 729/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0907 - val_accuracy: 0.9775 - val_loss: 0.1426\n",
      "Epoch 730/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.0941 - val_accuracy: 0.9749 - val_loss: 0.1411\n",
      "Epoch 731/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.0993 - val_accuracy: 0.9759 - val_loss: 0.1329\n",
      "Epoch 732/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0933 - val_accuracy: 0.9749 - val_loss: 0.1308\n",
      "Epoch 733/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9623 - loss: 0.1070 - val_accuracy: 0.9744 - val_loss: 0.1383\n",
      "Epoch 734/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1043 - val_accuracy: 0.9718 - val_loss: 0.1459\n",
      "Epoch 735/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.0970 - val_accuracy: 0.9769 - val_loss: 0.1370\n",
      "Epoch 736/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1023 - val_accuracy: 0.9759 - val_loss: 0.1367\n",
      "Epoch 737/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0946 - val_accuracy: 0.9734 - val_loss: 0.1262\n",
      "Epoch 738/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0889 - val_accuracy: 0.9759 - val_loss: 0.1339\n",
      "Epoch 739/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0934 - val_accuracy: 0.9764 - val_loss: 0.1309\n",
      "Epoch 740/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0903 - val_accuracy: 0.9723 - val_loss: 0.1477\n",
      "Epoch 741/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1006 - val_accuracy: 0.9759 - val_loss: 0.1418\n",
      "Epoch 742/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0998 - val_accuracy: 0.9780 - val_loss: 0.1264\n",
      "Epoch 743/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1157 - val_accuracy: 0.9775 - val_loss: 0.1341\n",
      "Epoch 744/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0975 - val_accuracy: 0.9754 - val_loss: 0.1509\n",
      "Epoch 745/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.1009 - val_accuracy: 0.9739 - val_loss: 0.1438\n",
      "Epoch 746/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1087 - val_accuracy: 0.9728 - val_loss: 0.1507\n",
      "Epoch 747/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.1064 - val_accuracy: 0.9754 - val_loss: 0.1374\n",
      "Epoch 748/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1114 - val_accuracy: 0.9775 - val_loss: 0.1344\n",
      "Epoch 749/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9676 - loss: 0.0896 - val_accuracy: 0.9754 - val_loss: 0.1410\n",
      "Epoch 750/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.1010 - val_accuracy: 0.9759 - val_loss: 0.1464\n",
      "Epoch 751/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0917 - val_accuracy: 0.9775 - val_loss: 0.1362\n",
      "Epoch 752/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1020 - val_accuracy: 0.9764 - val_loss: 0.1269\n",
      "Epoch 753/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0893 - val_accuracy: 0.9754 - val_loss: 0.1379\n",
      "Epoch 754/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.0917 - val_accuracy: 0.9744 - val_loss: 0.1405\n",
      "Epoch 755/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0840 - val_accuracy: 0.9790 - val_loss: 0.1293\n",
      "Epoch 756/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1121 - val_accuracy: 0.9744 - val_loss: 0.1436\n",
      "Epoch 757/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1021 - val_accuracy: 0.9749 - val_loss: 0.1427\n",
      "Epoch 758/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0940 - val_accuracy: 0.9718 - val_loss: 0.1453\n",
      "Epoch 759/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0966 - val_accuracy: 0.9759 - val_loss: 0.1311\n",
      "Epoch 760/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0818 - val_accuracy: 0.9785 - val_loss: 0.1338\n",
      "Epoch 761/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0894 - val_accuracy: 0.9805 - val_loss: 0.1224\n",
      "Epoch 762/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0960 - val_accuracy: 0.9734 - val_loss: 0.1270\n",
      "Epoch 763/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0986 - val_accuracy: 0.9785 - val_loss: 0.1242\n",
      "Epoch 764/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1023 - val_accuracy: 0.9795 - val_loss: 0.1224\n",
      "Epoch 765/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9628 - loss: 0.1065 - val_accuracy: 0.9759 - val_loss: 0.1276\n",
      "Epoch 766/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0864 - val_accuracy: 0.9764 - val_loss: 0.1193\n",
      "Epoch 767/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0987 - val_accuracy: 0.9754 - val_loss: 0.1359\n",
      "Epoch 768/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.0983 - val_accuracy: 0.9739 - val_loss: 0.1289\n",
      "Epoch 769/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.1019 - val_accuracy: 0.9795 - val_loss: 0.1324\n",
      "Epoch 770/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.1006 - val_accuracy: 0.9734 - val_loss: 0.1405\n",
      "Epoch 771/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0971 - val_accuracy: 0.9739 - val_loss: 0.1400\n",
      "Epoch 772/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0887 - val_accuracy: 0.9744 - val_loss: 0.1362\n",
      "Epoch 773/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0894 - val_accuracy: 0.9759 - val_loss: 0.1357\n",
      "Epoch 774/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1006 - val_accuracy: 0.9769 - val_loss: 0.1343\n",
      "Epoch 775/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1085 - val_accuracy: 0.9728 - val_loss: 0.1472\n",
      "Epoch 776/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0990 - val_accuracy: 0.9759 - val_loss: 0.1383\n",
      "Epoch 777/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0892 - val_accuracy: 0.9744 - val_loss: 0.1366\n",
      "Epoch 778/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0846 - val_accuracy: 0.9769 - val_loss: 0.1255\n",
      "Epoch 779/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0965 - val_accuracy: 0.9749 - val_loss: 0.1293\n",
      "Epoch 780/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0908 - val_accuracy: 0.9764 - val_loss: 0.1341\n",
      "Epoch 781/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1017 - val_accuracy: 0.9723 - val_loss: 0.1339\n",
      "Epoch 782/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.1046 - val_accuracy: 0.9723 - val_loss: 0.1482\n",
      "Epoch 783/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0933 - val_accuracy: 0.9739 - val_loss: 0.1275\n",
      "Epoch 784/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.1022 - val_accuracy: 0.9759 - val_loss: 0.1408\n",
      "Epoch 785/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0988 - val_accuracy: 0.9723 - val_loss: 0.1445\n",
      "Epoch 786/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9701 - loss: 0.0919 - val_accuracy: 0.9749 - val_loss: 0.1360\n",
      "Epoch 787/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0863 - val_accuracy: 0.9754 - val_loss: 0.1323\n",
      "Epoch 788/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0858 - val_accuracy: 0.9795 - val_loss: 0.1291\n",
      "Epoch 789/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.0964 - val_accuracy: 0.9795 - val_loss: 0.1267\n",
      "Epoch 790/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1052 - val_accuracy: 0.9739 - val_loss: 0.1312\n",
      "Epoch 791/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0813 - val_accuracy: 0.9769 - val_loss: 0.1352\n",
      "Epoch 792/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1171 - val_accuracy: 0.9723 - val_loss: 0.1539\n",
      "Epoch 793/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1140 - val_accuracy: 0.9764 - val_loss: 0.1486\n",
      "Epoch 794/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.1006 - val_accuracy: 0.9759 - val_loss: 0.1306\n",
      "Epoch 795/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0988 - val_accuracy: 0.9780 - val_loss: 0.1385\n",
      "Epoch 796/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0904 - val_accuracy: 0.9790 - val_loss: 0.1219\n",
      "Epoch 797/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0908 - val_accuracy: 0.9754 - val_loss: 0.1291\n",
      "Epoch 798/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1047 - val_accuracy: 0.9698 - val_loss: 0.1470\n",
      "Epoch 799/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0933 - val_accuracy: 0.9759 - val_loss: 0.1359\n",
      "Epoch 800/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.1016 - val_accuracy: 0.9749 - val_loss: 0.1218\n",
      "Epoch 801/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.0892 - val_accuracy: 0.9718 - val_loss: 0.1412\n",
      "Epoch 802/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.1008 - val_accuracy: 0.9780 - val_loss: 0.1266\n",
      "Epoch 803/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0937 - val_accuracy: 0.9775 - val_loss: 0.1296\n",
      "Epoch 804/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.1128 - val_accuracy: 0.9754 - val_loss: 0.1392\n",
      "Epoch 805/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0863 - val_accuracy: 0.9785 - val_loss: 0.1461\n",
      "Epoch 806/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1063 - val_accuracy: 0.9764 - val_loss: 0.1505\n",
      "Epoch 807/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0881 - val_accuracy: 0.9718 - val_loss: 0.1424\n",
      "Epoch 808/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0859 - val_accuracy: 0.9769 - val_loss: 0.1339\n",
      "Epoch 809/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0935 - val_accuracy: 0.9708 - val_loss: 0.1482\n",
      "Epoch 810/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0992 - val_accuracy: 0.9754 - val_loss: 0.1500\n",
      "Epoch 811/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0841 - val_accuracy: 0.9790 - val_loss: 0.1340\n",
      "Epoch 812/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0755 - val_accuracy: 0.9769 - val_loss: 0.1392\n",
      "Epoch 813/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.1002 - val_accuracy: 0.9764 - val_loss: 0.1287\n",
      "Epoch 814/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0943 - val_accuracy: 0.9698 - val_loss: 0.1534\n",
      "Epoch 815/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1018 - val_accuracy: 0.9759 - val_loss: 0.1313\n",
      "Epoch 816/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0943 - val_accuracy: 0.9785 - val_loss: 0.1262\n",
      "Epoch 817/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0958 - val_accuracy: 0.9728 - val_loss: 0.1491\n",
      "Epoch 818/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0903 - val_accuracy: 0.9810 - val_loss: 0.1262\n",
      "Epoch 819/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0953 - val_accuracy: 0.9739 - val_loss: 0.1400\n",
      "Epoch 820/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.1045 - val_accuracy: 0.9764 - val_loss: 0.1217\n",
      "Epoch 821/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1028 - val_accuracy: 0.9744 - val_loss: 0.1526\n",
      "Epoch 822/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.0833 - val_accuracy: 0.9769 - val_loss: 0.1258\n",
      "Epoch 823/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.0998 - val_accuracy: 0.9718 - val_loss: 0.1429\n",
      "Epoch 824/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9634 - loss: 0.1047 - val_accuracy: 0.9775 - val_loss: 0.1339\n",
      "Epoch 825/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.0985 - val_accuracy: 0.9769 - val_loss: 0.1204\n",
      "Epoch 826/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9736 - loss: 0.0808 - val_accuracy: 0.9708 - val_loss: 0.1549\n",
      "Epoch 827/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9701 - loss: 0.0915 - val_accuracy: 0.9785 - val_loss: 0.1280\n",
      "Epoch 828/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0894 - val_accuracy: 0.9749 - val_loss: 0.1378\n",
      "Epoch 829/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.1045 - val_accuracy: 0.9739 - val_loss: 0.1303\n",
      "Epoch 830/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0817 - val_accuracy: 0.9764 - val_loss: 0.1247\n",
      "Epoch 831/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.1046 - val_accuracy: 0.9759 - val_loss: 0.1299\n",
      "Epoch 832/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0901 - val_accuracy: 0.9769 - val_loss: 0.1202\n",
      "Epoch 833/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0880 - val_accuracy: 0.9744 - val_loss: 0.1433\n",
      "Epoch 834/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0999 - val_accuracy: 0.9744 - val_loss: 0.1420\n",
      "Epoch 835/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0846 - val_accuracy: 0.9754 - val_loss: 0.1382\n",
      "Epoch 836/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0900 - val_accuracy: 0.9739 - val_loss: 0.1415\n",
      "Epoch 837/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0855 - val_accuracy: 0.9769 - val_loss: 0.1291\n",
      "Epoch 838/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0873 - val_accuracy: 0.9759 - val_loss: 0.1287\n",
      "Epoch 839/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0958 - val_accuracy: 0.9780 - val_loss: 0.1371\n",
      "Epoch 840/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9667 - loss: 0.0921 - val_accuracy: 0.9769 - val_loss: 0.1361\n",
      "Epoch 841/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0905 - val_accuracy: 0.9775 - val_loss: 0.1311\n",
      "Epoch 842/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0901 - val_accuracy: 0.9764 - val_loss: 0.1275\n",
      "Epoch 843/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9636 - loss: 0.1123 - val_accuracy: 0.9785 - val_loss: 0.1366\n",
      "Epoch 844/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1109 - val_accuracy: 0.9785 - val_loss: 0.1309\n",
      "Epoch 845/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1028 - val_accuracy: 0.9790 - val_loss: 0.1325\n",
      "Epoch 846/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0854 - val_accuracy: 0.9795 - val_loss: 0.1348\n",
      "Epoch 847/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0843 - val_accuracy: 0.9759 - val_loss: 0.1404\n",
      "Epoch 848/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.0778 - val_accuracy: 0.9759 - val_loss: 0.1408\n",
      "Epoch 849/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9657 - loss: 0.0988 - val_accuracy: 0.9769 - val_loss: 0.1447\n",
      "Epoch 850/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.0793 - val_accuracy: 0.9754 - val_loss: 0.1372\n",
      "Epoch 851/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0859 - val_accuracy: 0.9749 - val_loss: 0.1510\n",
      "Epoch 852/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0790 - val_accuracy: 0.9769 - val_loss: 0.1277\n",
      "Epoch 853/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.0969 - val_accuracy: 0.9790 - val_loss: 0.1409\n",
      "Epoch 854/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0932 - val_accuracy: 0.9790 - val_loss: 0.1332\n",
      "Epoch 855/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1029 - val_accuracy: 0.9754 - val_loss: 0.1278\n",
      "Epoch 856/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0939 - val_accuracy: 0.9780 - val_loss: 0.1351\n",
      "Epoch 857/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0902 - val_accuracy: 0.9744 - val_loss: 0.1459\n",
      "Epoch 858/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0878 - val_accuracy: 0.9775 - val_loss: 0.1307\n",
      "Epoch 859/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.0916 - val_accuracy: 0.9764 - val_loss: 0.1333\n",
      "Epoch 860/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0825 - val_accuracy: 0.9744 - val_loss: 0.1525\n",
      "Epoch 861/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9660 - loss: 0.1077 - val_accuracy: 0.9754 - val_loss: 0.1305\n",
      "Epoch 862/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0870 - val_accuracy: 0.9759 - val_loss: 0.1427\n",
      "Epoch 863/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0847 - val_accuracy: 0.9785 - val_loss: 0.1308\n",
      "Epoch 864/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0827 - val_accuracy: 0.9739 - val_loss: 0.1496\n",
      "Epoch 865/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0945 - val_accuracy: 0.9749 - val_loss: 0.1373\n",
      "Epoch 866/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.1049 - val_accuracy: 0.9764 - val_loss: 0.1341\n",
      "Epoch 867/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1053 - val_accuracy: 0.9785 - val_loss: 0.1341\n",
      "Epoch 868/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0869 - val_accuracy: 0.9769 - val_loss: 0.1411\n",
      "Epoch 869/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0903 - val_accuracy: 0.9744 - val_loss: 0.1314\n",
      "Epoch 870/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0959 - val_accuracy: 0.9764 - val_loss: 0.1354\n",
      "Epoch 871/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.1045 - val_accuracy: 0.9790 - val_loss: 0.1383\n",
      "Epoch 872/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0929 - val_accuracy: 0.9780 - val_loss: 0.1276\n",
      "Epoch 873/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0960 - val_accuracy: 0.9810 - val_loss: 0.1331\n",
      "Epoch 874/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0991 - val_accuracy: 0.9800 - val_loss: 0.1356\n",
      "Epoch 875/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0861 - val_accuracy: 0.9810 - val_loss: 0.1353\n",
      "Epoch 876/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0868 - val_accuracy: 0.9775 - val_loss: 0.1442\n",
      "Epoch 877/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0925 - val_accuracy: 0.9769 - val_loss: 0.1324\n",
      "Epoch 878/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.1019 - val_accuracy: 0.9764 - val_loss: 0.1390\n",
      "Epoch 879/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9695 - loss: 0.0875 - val_accuracy: 0.9744 - val_loss: 0.1437\n",
      "Epoch 880/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0919 - val_accuracy: 0.9749 - val_loss: 0.1482\n",
      "Epoch 881/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.0954 - val_accuracy: 0.9795 - val_loss: 0.1331\n",
      "Epoch 882/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.0957 - val_accuracy: 0.9790 - val_loss: 0.1416\n",
      "Epoch 883/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 0.0949 - val_accuracy: 0.9795 - val_loss: 0.1274\n",
      "Epoch 884/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0949 - val_accuracy: 0.9759 - val_loss: 0.1559\n",
      "Epoch 885/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0916 - val_accuracy: 0.9775 - val_loss: 0.1363\n",
      "Epoch 886/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.0740 - val_accuracy: 0.9754 - val_loss: 0.1374\n",
      "Epoch 887/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0811 - val_accuracy: 0.9749 - val_loss: 0.1284\n",
      "Epoch 888/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0768 - val_accuracy: 0.9780 - val_loss: 0.1330\n",
      "Epoch 889/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.0989 - val_accuracy: 0.9713 - val_loss: 0.1487\n",
      "Epoch 890/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0878 - val_accuracy: 0.9795 - val_loss: 0.1366\n",
      "Epoch 891/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0886 - val_accuracy: 0.9754 - val_loss: 0.1431\n",
      "Epoch 892/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.0787 - val_accuracy: 0.9785 - val_loss: 0.1354\n",
      "Epoch 893/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1099 - val_accuracy: 0.9739 - val_loss: 0.1387\n",
      "Epoch 894/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0897 - val_accuracy: 0.9800 - val_loss: 0.1341\n",
      "Epoch 895/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0997 - val_accuracy: 0.9775 - val_loss: 0.1344\n",
      "Epoch 896/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0925 - val_accuracy: 0.9744 - val_loss: 0.1495\n",
      "Epoch 897/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0969 - val_accuracy: 0.9769 - val_loss: 0.1359\n",
      "Epoch 898/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.0933 - val_accuracy: 0.9790 - val_loss: 0.1287\n",
      "Epoch 899/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0966 - val_accuracy: 0.9785 - val_loss: 0.1450\n",
      "Epoch 900/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.1054 - val_accuracy: 0.9780 - val_loss: 0.1305\n",
      "Epoch 901/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0986 - val_accuracy: 0.9795 - val_loss: 0.1089\n",
      "Epoch 902/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0929 - val_accuracy: 0.9769 - val_loss: 0.1418\n",
      "Epoch 903/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0858 - val_accuracy: 0.9785 - val_loss: 0.1276\n",
      "Epoch 904/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9737 - loss: 0.0814 - val_accuracy: 0.9759 - val_loss: 0.1350\n",
      "Epoch 905/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0921 - val_accuracy: 0.9769 - val_loss: 0.1206\n",
      "Epoch 906/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0986 - val_accuracy: 0.9693 - val_loss: 0.1506\n",
      "Epoch 907/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0940 - val_accuracy: 0.9800 - val_loss: 0.1292\n",
      "Epoch 908/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0865 - val_accuracy: 0.9785 - val_loss: 0.1297\n",
      "Epoch 909/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0953 - val_accuracy: 0.9749 - val_loss: 0.1322\n",
      "Epoch 910/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9676 - loss: 0.0948 - val_accuracy: 0.9749 - val_loss: 0.1193\n",
      "Epoch 911/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9675 - loss: 0.0962 - val_accuracy: 0.9790 - val_loss: 0.1163\n",
      "Epoch 912/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0801 - val_accuracy: 0.9790 - val_loss: 0.1291\n",
      "Epoch 913/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0908 - val_accuracy: 0.9739 - val_loss: 0.1381\n",
      "Epoch 914/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0944 - val_accuracy: 0.9749 - val_loss: 0.1336\n",
      "Epoch 915/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0882 - val_accuracy: 0.9785 - val_loss: 0.1219\n",
      "Epoch 916/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0825 - val_accuracy: 0.9749 - val_loss: 0.1351\n",
      "Epoch 917/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1121 - val_accuracy: 0.9764 - val_loss: 0.1349\n",
      "Epoch 918/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0927 - val_accuracy: 0.9769 - val_loss: 0.1243\n",
      "Epoch 919/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.0980 - val_accuracy: 0.9775 - val_loss: 0.1371\n",
      "Epoch 920/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.0929 - val_accuracy: 0.9795 - val_loss: 0.1190\n",
      "Epoch 921/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0907 - val_accuracy: 0.9739 - val_loss: 0.1359\n",
      "Epoch 922/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.0856 - val_accuracy: 0.9723 - val_loss: 0.1539\n",
      "Epoch 923/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0845 - val_accuracy: 0.9759 - val_loss: 0.1442\n",
      "Epoch 924/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0954 - val_accuracy: 0.9795 - val_loss: 0.1233\n",
      "Epoch 925/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0883 - val_accuracy: 0.9780 - val_loss: 0.1325\n",
      "Epoch 926/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0881 - val_accuracy: 0.9780 - val_loss: 0.1305\n",
      "Epoch 927/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0843 - val_accuracy: 0.9775 - val_loss: 0.1272\n",
      "Epoch 928/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0958 - val_accuracy: 0.9759 - val_loss: 0.1344\n",
      "Epoch 929/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9685 - loss: 0.0977 - val_accuracy: 0.9769 - val_loss: 0.1428\n",
      "Epoch 930/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0953 - val_accuracy: 0.9795 - val_loss: 0.1377\n",
      "Epoch 931/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0966 - val_accuracy: 0.9769 - val_loss: 0.1299\n",
      "Epoch 932/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9682 - loss: 0.0890 - val_accuracy: 0.9775 - val_loss: 0.1323\n",
      "Epoch 933/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0930 - val_accuracy: 0.9744 - val_loss: 0.1508\n",
      "Epoch 934/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0879 - val_accuracy: 0.9780 - val_loss: 0.1353\n",
      "Epoch 935/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0798 - val_accuracy: 0.9790 - val_loss: 0.1244\n",
      "Epoch 936/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0885 - val_accuracy: 0.9780 - val_loss: 0.1252\n",
      "Epoch 937/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0804 - val_accuracy: 0.9734 - val_loss: 0.1293\n",
      "Epoch 938/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9701 - loss: 0.0847 - val_accuracy: 0.9754 - val_loss: 0.1394\n",
      "Epoch 939/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0982 - val_accuracy: 0.9759 - val_loss: 0.1451\n",
      "Epoch 940/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0891 - val_accuracy: 0.9764 - val_loss: 0.1429\n",
      "Epoch 941/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0998 - val_accuracy: 0.9723 - val_loss: 0.1407\n",
      "Epoch 942/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0956 - val_accuracy: 0.9759 - val_loss: 0.1353\n",
      "Epoch 943/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9735 - loss: 0.0836 - val_accuracy: 0.9821 - val_loss: 0.1285\n",
      "Epoch 944/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0842 - val_accuracy: 0.9769 - val_loss: 0.1425\n",
      "Epoch 945/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0889 - val_accuracy: 0.9739 - val_loss: 0.1534\n",
      "Epoch 946/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0978 - val_accuracy: 0.9775 - val_loss: 0.1418\n",
      "Epoch 947/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0825 - val_accuracy: 0.9785 - val_loss: 0.1424\n",
      "Epoch 948/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9658 - loss: 0.0985 - val_accuracy: 0.9800 - val_loss: 0.1305\n",
      "Epoch 949/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9695 - loss: 0.0936 - val_accuracy: 0.9754 - val_loss: 0.1515\n",
      "Epoch 950/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.0947 - val_accuracy: 0.9775 - val_loss: 0.1432\n",
      "Epoch 951/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0850 - val_accuracy: 0.9780 - val_loss: 0.1351\n",
      "Epoch 952/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0804 - val_accuracy: 0.9780 - val_loss: 0.1335\n",
      "Epoch 953/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0911 - val_accuracy: 0.9769 - val_loss: 0.1264\n",
      "Epoch 954/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0896 - val_accuracy: 0.9759 - val_loss: 0.1383\n",
      "Epoch 955/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0871 - val_accuracy: 0.9749 - val_loss: 0.1390\n",
      "Epoch 956/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0870 - val_accuracy: 0.9754 - val_loss: 0.1158\n",
      "Epoch 957/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9727 - loss: 0.0808 - val_accuracy: 0.9764 - val_loss: 0.1339\n",
      "Epoch 958/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9736 - loss: 0.0781 - val_accuracy: 0.9734 - val_loss: 0.1252\n",
      "Epoch 959/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0924 - val_accuracy: 0.9795 - val_loss: 0.1427\n",
      "Epoch 960/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0953 - val_accuracy: 0.9734 - val_loss: 0.1544\n",
      "Epoch 961/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1110 - val_accuracy: 0.9754 - val_loss: 0.1320\n",
      "Epoch 962/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0904 - val_accuracy: 0.9749 - val_loss: 0.1378\n",
      "Epoch 963/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0875 - val_accuracy: 0.9785 - val_loss: 0.1506\n",
      "Epoch 964/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0954 - val_accuracy: 0.9764 - val_loss: 0.1240\n",
      "Epoch 965/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9696 - loss: 0.0890 - val_accuracy: 0.9780 - val_loss: 0.1335\n",
      "Epoch 966/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0844 - val_accuracy: 0.9810 - val_loss: 0.1324\n",
      "Epoch 967/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.1045 - val_accuracy: 0.9764 - val_loss: 0.1272\n",
      "Epoch 968/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0961 - val_accuracy: 0.9800 - val_loss: 0.1396\n",
      "Epoch 969/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.0874 - val_accuracy: 0.9744 - val_loss: 0.1482\n",
      "Epoch 970/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0883 - val_accuracy: 0.9795 - val_loss: 0.1353\n",
      "Epoch 971/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0861 - val_accuracy: 0.9769 - val_loss: 0.1404\n",
      "Epoch 972/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.0845 - val_accuracy: 0.9790 - val_loss: 0.1335\n",
      "Epoch 973/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9690 - loss: 0.0930 - val_accuracy: 0.9759 - val_loss: 0.1401\n",
      "Epoch 974/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0837 - val_accuracy: 0.9759 - val_loss: 0.1422\n",
      "Epoch 975/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.0980 - val_accuracy: 0.9780 - val_loss: 0.1361\n",
      "Epoch 976/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9731 - loss: 0.0822 - val_accuracy: 0.9800 - val_loss: 0.1446\n",
      "Epoch 977/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0848 - val_accuracy: 0.9769 - val_loss: 0.1444\n",
      "Epoch 978/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0972 - val_accuracy: 0.9749 - val_loss: 0.1435\n",
      "Epoch 979/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0801 - val_accuracy: 0.9795 - val_loss: 0.1404\n",
      "Epoch 980/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0913 - val_accuracy: 0.9775 - val_loss: 0.1402\n",
      "Epoch 981/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9740 - loss: 0.0734 - val_accuracy: 0.9780 - val_loss: 0.1446\n",
      "Epoch 982/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0777 - val_accuracy: 0.9769 - val_loss: 0.1265\n",
      "Epoch 983/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0918 - val_accuracy: 0.9800 - val_loss: 0.1424\n",
      "Epoch 984/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.1035 - val_accuracy: 0.9764 - val_loss: 0.1471\n",
      "Epoch 985/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0839 - val_accuracy: 0.9841 - val_loss: 0.1379\n",
      "Epoch 986/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0849 - val_accuracy: 0.9810 - val_loss: 0.1524\n",
      "Epoch 987/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0863 - val_accuracy: 0.9769 - val_loss: 0.1458\n",
      "Epoch 988/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1022 - val_accuracy: 0.9785 - val_loss: 0.1492\n",
      "Epoch 989/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9662 - loss: 0.0987 - val_accuracy: 0.9775 - val_loss: 0.1522\n",
      "Epoch 990/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9651 - loss: 0.1053 - val_accuracy: 0.9754 - val_loss: 0.1386\n",
      "Epoch 991/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0909 - val_accuracy: 0.9759 - val_loss: 0.1428\n",
      "Epoch 992/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0893 - val_accuracy: 0.9790 - val_loss: 0.1365\n",
      "Epoch 993/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0912 - val_accuracy: 0.9795 - val_loss: 0.1316\n",
      "Epoch 994/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0875 - val_accuracy: 0.9780 - val_loss: 0.1387\n",
      "Epoch 995/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0840 - val_accuracy: 0.9759 - val_loss: 0.1433\n",
      "Epoch 996/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0836 - val_accuracy: 0.9749 - val_loss: 0.1356\n",
      "Epoch 997/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0903 - val_accuracy: 0.9764 - val_loss: 0.1415\n",
      "Epoch 998/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0913 - val_accuracy: 0.9800 - val_loss: 0.1399\n",
      "Epoch 999/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9719 - loss: 0.0856 - val_accuracy: 0.9769 - val_loss: 0.1368\n",
      "Epoch 1000/1000\n",
      "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0907 - val_accuracy: 0.9785 - val_loss: 0.1318\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8619610d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90ded",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3db52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(f\"{model_name}.keras\")\n",
    "with open(f\"{model_name}_label.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0155f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 126), dtype=tf.float32, name='keras_tensor_167')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 26), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13351857104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13351857296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13351857872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13352473552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13352470672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13352471056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1760547435.769765   52980 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1760547435.769939   52980 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-15 23:57:15.770372: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s\n",
      "2025-10-15 23:57:15.770803: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-15 23:57:15.770808: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s\n",
      "2025-10-15 23:57:15.774659: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-15 23:57:15.792171: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpzh45pk8s\n",
      "2025-10-15 23:57:15.797147: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 26777 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite file\n",
    "with open(f\"{model_name}.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
