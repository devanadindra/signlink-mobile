{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397381d5",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efbb9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting onnx>=1.4.1 (from tf2onnx)\n",
      "  Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf2onnx\n",
      "  Using cached tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Using cached tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\windows 10\\anaconda3\\envs\\aienv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached onnx-1.19.1-cp312-cp312-win_amd64.whl (16.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, urllib3, termcolor, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt_einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, idna, grpcio, google_pasta, gast, fonttools, cycler, charset_normalizer, certifi, astunparse, absl-py, werkzeug, scipy, requests, opencv-python, ml_dtypes, markdown-it-py, h5py, contourpy, tensorboard, rich, onnx, matplotlib, tf2onnx, keras, tensorflow\n",
      "\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "    ---------------------------------------  1/42 [libclang]\n",
      "   -- -------------------------------------  3/42 [wrapt]\n",
      "   ---- -----------------------------------  5/42 [termcolor]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   ------- --------------------------------  8/42 [protobuf]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   -------- -------------------------------  9/42 [pillow]\n",
      "   --------- ------------------------------ 10/42 [optree]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ----------- ---------------------------- 12/42 [numpy]\n",
      "   ------------- -------------------------- 14/42 [MarkupSafe]\n",
      "   ---------------- ----------------------- 17/42 [idna]\n",
      "   ----------------- ---------------------- 18/42 [grpcio]\n",
      "   ------------------ --------------------- 19/42 [google_pasta]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   -------------------- ------------------- 21/42 [fonttools]\n",
      "   --------------------- ------------------ 23/42 [charset_normalizer]\n",
      "   ------------------------ --------------- 26/42 [absl-py]\n",
      "   ------------------------- -------------- 27/42 [werkzeug]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   -------------------------- ------------- 28/42 [scipy]\n",
      "   --------------------------- ------------ 29/42 [requests]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ---------------------------- ----------- 30/42 [opencv-python]\n",
      "   ------------------------------ --------- 32/42 [markdown-it-py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   ------------------------------- -------- 33/42 [h5py]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   --------------------------------- ------ 35/42 [tensorboard]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ---------------------------------- ----- 36/42 [rich]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ----------------------------------- ---- 37/42 [onnx]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------ --- 38/42 [matplotlib]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   ------------------------------------- -- 39/42 [tf2onnx]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   -------------------------------------- - 40/42 [keras]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------  41/42 [tensorflow]\n",
      "   ---------------------------------------- 42/42 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.10.5 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.9.23 fonttools-4.60.1 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.15.0 idna-3.11 keras-3.11.3 kiwisolver-1.4.9 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.2.6 onnx-1.19.1 opencv-python-4.12.0.88 opt_einsum-3.4.0 optree-0.17.0 pillow-12.0.0 protobuf-6.33.0 pyparsing-3.2.5 requests-2.32.5 rich-14.2.0 scipy-1.16.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 tf2onnx-1.8.4 urllib3-2.5.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tf2onnx matplotlib numpy opencv-python scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed27fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting packaging (from tensorflow)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Using cached h5py-3.15.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing_extensions, termcolor, tensorboard-data-server, six, setuptools, pygments, protobuf, pillow, packaging, opt_einsum, numpy, mdurl, MarkupSafe, markdown, idna, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, ml_dtypes, markdown-it-py, h5py, grpcio, google_pasta, astunparse, tensorboard, rich, keras, tensorflow\n",
      "\n",
      "  Attempting uninstall: namex\n",
      "\n",
      "    Found existing installation: namex 0.1.0\n",
      "\n",
      "    Uninstalling namex-0.1.0:\n",
      "\n",
      "      Successfully uninstalled namex-0.1.0\n",
      "\n",
      "  Attempting uninstall: libclang\n",
      "\n",
      "    Found existing installation: libclang 18.1.1\n",
      "\n",
      "    Uninstalling libclang-18.1.1:\n",
      "\n",
      "      Successfully uninstalled libclang-18.1.1\n",
      "\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "  Attempting uninstall: flatbuffers\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Found existing installation: flatbuffers 25.9.23\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Uninstalling flatbuffers-25.9.23:\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "      Successfully uninstalled flatbuffers-25.9.23\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "  Attempting uninstall: wrapt\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Found existing installation: wrapt 1.17.3\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Uninstalling wrapt-1.17.3:\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "      Successfully uninstalled wrapt-1.17.3\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "  Attempting uninstall: wheel\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Found existing installation: wheel 0.45.1\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "    Uninstalling wheel-0.45.1:\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "      Successfully uninstalled wheel-0.45.1\n",
      "   - --------------------------------------  1/38 [libclang]\n",
      "   ---- -----------------------------------  4/38 [wheel]\n",
      "  Attempting uninstall: urllib3\n",
      "   ---- -----------------------------------  4/38 [wheel]\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "   ---- -----------------------------------  4/38 [wheel]\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "   ---- -----------------------------------  4/38 [wheel]\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "   ---- -----------------------------------  4/38 [wheel]\n",
      "   ----- ----------------------------------  5/38 [urllib3]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   ----- ----------------------------------  5/38 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "   ----- ----------------------------------  5/38 [urllib3]\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "   ----- ----------------------------------  5/38 [urllib3]\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "  Attempting uninstall: termcolor\n",
      "   ------ ---------------------------------  6/38 [typing_extensions]\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Found existing installation: termcolor 3.1.0\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Uninstalling termcolor-3.1.0:\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "      Successfully uninstalled termcolor-3.1.0\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "  Attempting uninstall: six\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Found existing installation: six 1.17.0\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "    Uninstalling six-1.17.0:\n",
      "   ------- --------------------------------  7/38 [termcolor]\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "      Successfully uninstalled six-1.17.0\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "  Attempting uninstall: setuptools\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "    Found existing installation: setuptools 80.9.0\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "    Uninstalling setuptools-80.9.0:\n",
      "   --------- ------------------------------  9/38 [six]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "      Successfully uninstalled setuptools-80.9.0\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "  Attempting uninstall: pygments\n",
      "   ---------- ----------------------------- 10/38 [setuptools]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "    Found existing installation: Pygments 2.19.2\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "    Uninstalling Pygments-2.19.2:\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "      Successfully uninstalled Pygments-2.19.2\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "  Attempting uninstall: protobuf\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "    Found existing installation: protobuf 6.33.0\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "    Uninstalling protobuf-6.33.0:\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "      Successfully uninstalled protobuf-6.33.0\n",
      "   ----------- ---------------------------- 11/38 [pygments]\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "  Attempting uninstall: pillow\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "    Found existing installation: pillow 12.0.0\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "    Uninstalling pillow-12.0.0:\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "      Successfully uninstalled pillow-12.0.0\n",
      "   ------------ --------------------------- 12/38 [protobuf]\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "  Attempting uninstall: packaging\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "  Attempting uninstall: opt_einsum\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "    Found existing installation: opt_einsum 3.4.0\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "    Uninstalling opt_einsum-3.4.0:\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "      Successfully uninstalled opt_einsum-3.4.0\n",
      "   ------------- -------------------------- 13/38 [pillow]\n",
      "   --------------- ------------------------ 15/38 [opt_einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   --------------- ------------------------ 15/38 [opt_einsum]\n",
      "    Found existing installation: numpy 2.2.6\n",
      "   --------------- ------------------------ 15/38 [opt_einsum]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Uninstalling numpy-2.2.6:\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "  Attempting uninstall: mdurl\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Found existing installation: mdurl 0.1.2\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Uninstalling mdurl-0.1.2:\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "      Successfully uninstalled mdurl-0.1.2\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "  Attempting uninstall: MarkupSafe\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Found existing installation: MarkupSafe 3.0.3\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Uninstalling MarkupSafe-3.0.3:\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "      Successfully uninstalled MarkupSafe-3.0.3\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "  Attempting uninstall: markdown\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Found existing installation: Markdown 3.9\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "    Uninstalling Markdown-3.9:\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "      Successfully uninstalled Markdown-3.9\n",
      "   ---------------- ----------------------- 16/38 [numpy]\n",
      "   -------------------- ------------------- 19/38 [markdown]\n",
      "  Attempting uninstall: idna\n",
      "   -------------------- ------------------- 19/38 [markdown]\n",
      "    Found existing installation: idna 3.11\n",
      "   -------------------- ------------------- 19/38 [markdown]\n",
      "    Uninstalling idna-3.11:\n",
      "   -------------------- ------------------- 19/38 [markdown]\n",
      "      Successfully uninstalled idna-3.11\n",
      "   -------------------- ------------------- 19/38 [markdown]\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "  Attempting uninstall: gast\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "    Found existing installation: gast 0.6.0\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "    Uninstalling gast-0.6.0:\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "      Successfully uninstalled gast-0.6.0\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "  Attempting uninstall: charset_normalizer\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "    Found existing installation: charset-normalizer 3.4.4\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "    Uninstalling charset-normalizer-3.4.4:\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "      Successfully uninstalled charset-normalizer-3.4.4\n",
      "   --------------------- ------------------ 20/38 [idna]\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "  Attempting uninstall: certifi\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "    Found existing installation: certifi 2025.10.5\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "    Uninstalling certifi-2025.10.5:\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "      Successfully uninstalled certifi-2025.10.5\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "  Attempting uninstall: absl-py\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "    Found existing installation: absl-py 2.3.1\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "    Uninstalling absl-py-2.3.1:\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "      Successfully uninstalled absl-py-2.3.1\n",
      "   ----------------------- ---------------- 22/38 [charset_normalizer]\n",
      "   ------------------------- -------------- 24/38 [absl-py]\n",
      "  Attempting uninstall: werkzeug\n",
      "   ------------------------- -------------- 24/38 [absl-py]\n",
      "    Found existing installation: Werkzeug 3.1.3\n",
      "   ------------------------- -------------- 24/38 [absl-py]\n",
      "    Uninstalling Werkzeug-3.1.3:\n",
      "   ------------------------- -------------- 24/38 [absl-py]\n",
      "      Successfully uninstalled Werkzeug-3.1.3\n",
      "   ------------------------- -------------- 24/38 [absl-py]\n",
      "   -------------------------- ------------- 25/38 [werkzeug]\n",
      "  Attempting uninstall: requests\n",
      "   -------------------------- ------------- 25/38 [werkzeug]\n",
      "    Found existing installation: requests 2.32.5\n",
      "   -------------------------- ------------- 25/38 [werkzeug]\n",
      "    Uninstalling requests-2.32.5:\n",
      "   -------------------------- ------------- 25/38 [werkzeug]\n",
      "      Successfully uninstalled requests-2.32.5\n",
      "   -------------------------- ------------- 25/38 [werkzeug]\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "  Attempting uninstall: optree\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "    Found existing installation: optree 0.17.0\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "    Uninstalling optree-0.17.0:\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "      Successfully uninstalled optree-0.17.0\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "  Attempting uninstall: ml_dtypes\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "    Found existing installation: ml_dtypes 0.5.3\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "    Uninstalling ml_dtypes-0.5.3:\n",
      "   --------------------------- ------------ 26/38 [requests]\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "      Successfully uninstalled ml_dtypes-0.5.3\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "  Attempting uninstall: markdown-it-py\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "    Found existing installation: markdown-it-py 4.0.0\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "    Uninstalling markdown-it-py-4.0.0:\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "      Successfully uninstalled markdown-it-py-4.0.0\n",
      "   ----------------------------- ---------- 28/38 [ml_dtypes]\n",
      "   ------------------------------ --------- 29/38 [markdown-it-py]\n",
      "  Attempting uninstall: h5py\n",
      "   ------------------------------ --------- 29/38 [markdown-it-py]\n",
      "    Found existing installation: h5py 3.15.0\n",
      "   ------------------------------ --------- 29/38 [markdown-it-py]\n",
      "    Uninstalling h5py-3.15.0:\n",
      "   ------------------------------ --------- 29/38 [markdown-it-py]\n",
      "      Successfully uninstalled h5py-3.15.0\n",
      "   ------------------------------ --------- 29/38 [markdown-it-py]\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "  Attempting uninstall: grpcio\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "    Found existing installation: grpcio 1.75.1\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "    Uninstalling grpcio-1.75.1:\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "      Successfully uninstalled grpcio-1.75.1\n",
      "   ------------------------------- -------- 30/38 [h5py]\n",
      "   -------------------------------- ------- 31/38 [grpcio]\n",
      "  Attempting uninstall: google_pasta\n",
      "   -------------------------------- ------- 31/38 [grpcio]\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "   -------------------------------- ------- 31/38 [grpcio]\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "   -------------------------------- ------- 31/38 [grpcio]\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "   -------------------------------- ------- 31/38 [grpcio]\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "  Attempting uninstall: astunparse\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "    Found existing installation: astunparse 1.6.3\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "  Attempting uninstall: tensorboard\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "    Found existing installation: tensorboard 2.20.0\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "    Uninstalling tensorboard-2.20.0:\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "      Successfully uninstalled tensorboard-2.20.0\n",
      "   --------------------------------- ------ 32/38 [google_pasta]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "  Attempting uninstall: rich\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "    Found existing installation: rich 14.2.0\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "    Uninstalling rich-14.2.0:\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "      Successfully uninstalled rich-14.2.0\n",
      "   ----------------------------------- ---- 34/38 [tensorboard]\n",
      "   ------------------------------------ --- 35/38 [rich]\n",
      "   ------------------------------------ --- 35/38 [rich]\n",
      "  Attempting uninstall: keras\n",
      "   ------------------------------------ --- 35/38 [rich]\n",
      "    Found existing installation: keras 3.11.3\n",
      "   ------------------------------------ --- 35/38 [rich]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "    Uninstalling keras-3.11.3:\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "      Successfully uninstalled keras-3.11.3\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "  Attempting uninstall: tensorflow\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "    Found existing installation: tensorflow 2.20.0\n",
      "   ------------------------------------- -- 36/38 [keras]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "    Uninstalling tensorflow-2.20.0:\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "      Successfully uninstalled tensorflow-2.20.0\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   -------------------------------------- - 37/38 [tensorflow]\n",
      "   ---------------------------------------- 38/38 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.10.5 charset_normalizer-3.4.4 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.15.0 idna-3.11 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.3.4 opt_einsum-3.4.0 optree-0.17.0 packaging-25.0 pillow-12.0.0 protobuf-6.33.0 pygments-2.19.2 requests-2.32.5 rich-14.2.0 setuptools-80.9.0 six-1.17.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 typing_extensions-4.15.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall numpy h5py tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18590",
   "metadata": {},
   "source": [
    "# import and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc1fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import string\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be719935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "model_name = 'sign_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13103e",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766be0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0  114M    0 83232    0     0  54378      0  0:36:51  0:00:01  0:36:50 54378\n",
      "  8  114M    8 10.0M    0     0  4148k      0  0:00:28  0:00:02  0:00:26 10.5M\n",
      " 18  114M   18 21.2M    0     0  6273k      0  0:00:18  0:00:03  0:00:15 10.9M\n",
      " 28  114M   28 32.5M    0     0  7453k      0  0:00:15  0:00:04  0:00:11 11.0M\n",
      " 38  114M   38 43.8M    0     0  8198k      0  0:00:14  0:00:05  0:00:09 11.0M\n",
      " 48  114M   48 55.1M    0     0  8716k      0  0:00:13  0:00:06  0:00:07 11.1M\n",
      " 56  114M   56 65.1M    0     0  8920k      0  0:00:13  0:00:07  0:00:06 11.0M\n",
      " 66  114M   66 76.4M    0     0  9230k      0  0:00:12  0:00:08  0:00:04 11.0M\n",
      " 76  114M   76 87.6M    0     0  9475k      0  0:00:12  0:00:09  0:00:03 11.0M\n",
      " 86  114M   86 98.9M    0     0  9671k      0  0:00:12  0:00:10  0:00:02 11.0M\n",
      " 96  114M   96  110M    0     0  9834k      0  0:00:11  0:00:11 --:--:-- 11.0M\n",
      "100  114M  100  114M    0     0  9892k      0  0:00:11  0:00:11 --:--:-- 11.2M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./alfabet-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/achmadnoer/alfabet-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66037a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ekstraksi dataset dari ./alfabet-bisindo.zip ...\n",
      " Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./alfabet-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21028c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memindahkan 'Citra BISINDO' ke './dataset' ...\n",
      " Berhasil dipindahkan ke ./dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src_dir = \"Citra BISINDO\"\n",
    "dst_dir = \"./dataset\"\n",
    "\n",
    "if not os.path.exists(src_dir):\n",
    "    raise FileNotFoundError(f\" Folder sumber tidak ditemukan: {src_dir}\")\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "print(f\" Memindahkan '{src_dir}' ke '{dst_dir}' ...\")\n",
    "shutil.move(src_dir, dst_dir)\n",
    "print(f\" Berhasil dipindahkan ke {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b1bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 1396M    0  110k    0     0  70686      0  5:45:23  0:00:01  5:45:22  111k\n",
      "  0 1396M    0 2528k    0     0   976k      0  0:24:25  0:00:02  0:24:23 1277k\n",
      "  0 1396M    0 7005k    0     0  1950k      0  0:12:13  0:00:03  0:12:10 2350k\n",
      "  0 1396M    0 11.4M    0     0  2551k      0  0:09:20  0:00:04  0:09:16 2942k\n",
      "  1 1396M    1 16.0M    0     0  2945k      0  0:08:05  0:00:05  0:08:00 3306k\n",
      "  1 1396M    1 20.4M    0     0  3179k      0  0:07:29  0:00:06  0:07:23 4178k\n",
      "  1 1396M    1 23.4M    0     0  3167k      0  0:07:31  0:00:07  0:07:24 4303k\n",
      "  1 1396M    1 27.1M    0     0  3238k      0  0:07:21  0:00:08  0:07:13 4164k\n",
      "  2 1396M    2 31.2M    0     0  3337k      0  0:07:08  0:00:09  0:06:59 4059k\n",
      "  2 1396M    2 35.2M    0     0  3403k      0  0:07:00  0:00:10  0:06:50 3915k\n",
      "  2 1396M    2 39.7M    0     0  3511k      0  0:06:47  0:00:11  0:06:36 3948k\n",
      "  3 1396M    3 43.8M    0     0  3566k      0  0:06:41  0:00:12  0:06:29 4172k\n",
      "  3 1396M    3 47.9M    0     0  3614k      0  0:06:35  0:00:13  0:06:22 4259k\n",
      "  3 1396M    3 52.5M    0     0  3688k      0  0:06:27  0:00:14  0:06:13 4361k\n",
      "  4 1396M    4 57.9M    0     0  3804k      0  0:06:16  0:00:15  0:06:01 4652k\n",
      "  4 1396M    4 62.7M    0     0  3871k      0  0:06:09  0:00:16  0:05:53 4708k\n",
      "  4 1396M    4 67.7M    0     0  3943k      0  0:06:02  0:00:17  0:05:45 4892k\n",
      "  5 1396M    5 72.7M    0     0  4004k      0  0:05:57  0:00:18  0:05:39 5064k\n",
      "  5 1396M    5 77.8M    0     0  4067k      0  0:05:51  0:00:19  0:05:32 5173k\n",
      "  5 1396M    5 82.9M    0     0  4124k      0  0:05:46  0:00:20  0:05:26 5123k\n",
      "  6 1396M    6 87.4M    0     0  4149k      0  0:05:44  0:00:21  0:05:23 5073k\n",
      "  6 1396M    6 92.4M    0     0  4191k      0  0:05:41  0:00:22  0:05:19 5061k\n",
      "  6 1396M    6 97.3M    0     0  4225k      0  0:05:38  0:00:23  0:05:15 5049k\n",
      "  7 1396M    7  102M    0     0  4260k      0  0:05:35  0:00:24  0:05:11 5016k\n",
      "  7 1396M    7  107M    0     0  4294k      0  0:05:33  0:00:25  0:05:08 4995k\n",
      "  8 1396M    8  112M    0     0  4318k      0  0:05:31  0:00:26  0:05:05 5046k\n",
      "  8 1396M    8  116M    0     0  4339k      0  0:05:29  0:00:27  0:05:02 5009k\n",
      "  8 1396M    8  121M    0     0  4360k      0  0:05:28  0:00:28  0:05:00 4992k\n",
      "  9 1396M    9  127M    0     0  4404k      0  0:05:24  0:00:29  0:04:55 5111k\n",
      "  9 1396M    9  132M    0     0  4437k      0  0:05:22  0:00:30  0:04:52 5171k\n",
      "  9 1396M    9  137M    0     0  4472k      0  0:05:19  0:00:31  0:04:48 5292k\n",
      " 10 1396M   10  142M    0     0  4486k      0  0:05:18  0:00:32  0:04:46 5299k\n",
      " 10 1396M   10  146M    0     0  4455k      0  0:05:21  0:00:33  0:04:48 5005k\n",
      " 10 1396M   10  150M    0     0  4445k      0  0:05:21  0:00:34  0:04:47 4690k\n",
      " 10 1396M   10  153M    0     0  4416k      0  0:05:23  0:00:35  0:04:48 4284k\n",
      " 11 1396M   11  157M    0     0  4399k      0  0:05:25  0:00:36  0:04:49 3939k\n",
      " 11 1396M   11  160M    0     0  4380k      0  0:05:26  0:00:37  0:04:49 3691k\n",
      " 11 1396M   11  164M    0     0  4364k      0  0:05:27  0:00:38  0:04:49 3750k\n",
      " 12 1396M   12  168M    0     0  4360k      0  0:05:28  0:00:39  0:04:49 3770k\n",
      " 12 1396M   12  172M    0     0  4364k      0  0:05:27  0:00:40  0:04:47 3993k\n",
      " 12 1396M   12  177M    0     0  4368k      0  0:05:27  0:00:41  0:04:46 4140k\n",
      " 12 1396M   12  181M    0     0  4363k      0  0:05:27  0:00:42  0:04:45 4231k\n",
      " 13 1396M   13  185M    0     0  4367k      0  0:05:27  0:00:43  0:04:44 4387k\n",
      " 13 1396M   13  190M    0     0  4370k      0  0:05:27  0:00:44  0:04:43 4454k\n",
      " 13 1396M   13  195M    0     0  4392k      0  0:05:25  0:00:45  0:04:40 4621k\n",
      " 14 1396M   14  202M    0     0  4448k      0  0:05:21  0:00:46  0:04:35 5116k\n",
      " 14 1396M   14  208M    0     0  4489k      0  0:05:18  0:00:47  0:04:31 5561k\n",
      " 15 1396M   15  214M    0     0  4514k      0  0:05:16  0:00:48  0:04:28 5802k\n",
      " 15 1396M   15  219M    0     0  4542k      0  0:05:14  0:00:49  0:04:25 6076k\n",
      " 16 1396M   16  225M    0     0  4567k      0  0:05:13  0:00:50  0:04:23 6166k\n",
      " 16 1396M   16  231M    0     0  4595k      0  0:05:11  0:00:51  0:04:20 5961k\n",
      " 16 1396M   16  237M    0     0  4622k      0  0:05:09  0:00:52  0:04:17 5886k\n",
      " 17 1396M   17  242M    0     0  4636k      0  0:05:08  0:00:53  0:04:15 5820k\n",
      " 17 1396M   17  248M    0     0  4661k      0  0:05:06  0:00:54  0:04:12 5840k\n",
      " 18 1396M   18  254M    0     0  4685k      0  0:05:05  0:00:55  0:04:10 5874k\n",
      " 18 1396M   18  260M    0     0  4720k      0  0:05:03  0:00:56  0:04:07 6006k\n",
      " 19 1396M   19  270M    0     0  4803k      0  0:04:57  0:00:57  0:04:00 6714k\n",
      " 20 1396M   20  281M    0     0  4918k      0  0:04:50  0:00:58  0:03:52 7942k\n",
      " 20 1396M   20  292M    0     0  5029k      0  0:04:44  0:00:59  0:03:45 9049k\n",
      " 21 1396M   21  303M    0     0  5137k      0  0:04:38  0:01:00  0:03:38  9.9M\n",
      " 22 1396M   22  315M    0     0  5241k      0  0:04:32  0:01:01  0:03:31 10.8M\n",
      " 23 1396M   23  325M    0     0  5320k      0  0:04:28  0:01:02  0:03:26 11.0M\n",
      " 24 1396M   24  336M    0     0  5418k      0  0:04:23  0:01:03  0:03:20 11.0M\n",
      " 24 1396M   24  347M    0     0  5513k      0  0:04:19  0:01:04  0:03:15 11.0M\n",
      " 25 1396M   25  359M    0     0  5605k      0  0:04:15  0:01:05  0:03:10 11.0M\n",
      " 26 1396M   26  370M    0     0  5694k      0  0:04:11  0:01:06  0:03:05 11.0M\n",
      " 27 1396M   27  380M    0     0  5762k      0  0:04:08  0:01:07  0:03:01 11.0M\n",
      " 28 1396M   28  391M    0     0  5846k      0  0:04:04  0:01:08  0:02:56 11.0M\n",
      " 28 1396M   28  402M    0     0  5928k      0  0:04:01  0:01:09  0:02:52 11.0M\n",
      " 29 1396M   29  414M    0     0  6008k      0  0:03:58  0:01:10  0:02:48 11.0M\n",
      " 30 1396M   30  425M    0     0  6085k      0  0:03:55  0:01:11  0:02:44 11.0M\n",
      " 31 1396M   31  436M    0     0  6159k      0  0:03:52  0:01:12  0:02:40 11.2M\n",
      " 31 1396M   31  446M    0     0  6216k      0  0:03:50  0:01:13  0:02:37 11.0M\n",
      " 32 1396M   32  458M    0     0  6287k      0  0:03:47  0:01:14  0:02:33 11.0M\n",
      " 33 1396M   33  469M    0     0  6357k      0  0:03:45  0:01:15  0:02:30 11.0M\n",
      " 34 1396M   34  480M    0     0  6424k      0  0:03:42  0:01:16  0:02:26 11.0M\n",
      " 35 1396M   35  490M    0     0  6466k      0  0:03:41  0:01:17  0:02:24 10.6M\n",
      " 35 1396M   35  496M    0     0  6463k      0  0:03:41  0:01:18  0:02:23  9.8M\n",
      " 36 1396M   36  504M    0     0  6494k      0  0:03:40  0:01:19  0:02:21 9580k\n",
      " 36 1396M   36  510M    0     0  6489k      0  0:03:40  0:01:20  0:02:20 8492k\n",
      " 37 1396M   37  521M    0     0  6549k      0  0:03:38  0:01:21  0:02:17 8464k\n",
      " 38 1396M   38  533M    0     0  6608k      0  0:03:36  0:01:22  0:02:14 8824k\n",
      " 38 1396M   38  544M    0     0  6664k      0  0:03:34  0:01:23  0:02:11 9815k\n",
      " 39 1396M   39  554M    0     0  6717k      0  0:03:32  0:01:24  0:02:08 10.0M\n",
      " 40 1396M   40  565M    0     0  6771k      0  0:03:31  0:01:25  0:02:06 11.0M\n",
      " 41 1396M   41  577M    0     0  6826k      0  0:03:29  0:01:26  0:02:03 11.0M\n",
      " 42 1396M   42  588M    0     0  6879k      0  0:03:27  0:01:27  0:02:00 11.0M\n",
      " 42 1396M   42  599M    0     0  6931k      0  0:03:26  0:01:28  0:01:58 11.1M\n",
      " 43 1396M   43  609M    0     0  6964k      0  0:03:25  0:01:29  0:01:56 10.8M\n",
      " 44 1396M   44  620M    0     0  7014k      0  0:03:23  0:01:30  0:01:53 10.9M\n",
      " 45 1396M   45  631M    0     0  7062k      0  0:03:22  0:01:31  0:01:51 10.8M\n",
      " 46 1396M   46  642M    0     0  7110k      0  0:03:21  0:01:32  0:01:49 10.8M\n",
      " 46 1396M   46  654M    0     0  7156k      0  0:03:19  0:01:33  0:01:46 10.8M\n",
      " 47 1396M   47  664M    0     0  7189k      0  0:03:18  0:01:34  0:01:44 10.9M\n",
      " 48 1396M   48  675M    0     0  7234k      0  0:03:17  0:01:35  0:01:42 10.9M\n",
      " 49 1396M   49  686M    0     0  7278k      0  0:03:16  0:01:36  0:01:40 10.9M\n",
      " 49 1396M   49  697M    0     0  7321k      0  0:03:15  0:01:37  0:01:38 10.9M\n",
      " 50 1396M   50  708M    0     0  7363k      0  0:03:14  0:01:38  0:01:36 10.9M\n",
      " 51 1396M   51  720M    0     0  7405k      0  0:03:13  0:01:39  0:01:34 11.2M\n",
      " 52 1396M   52  730M    0     0  7433k      0  0:03:12  0:01:40  0:01:32 10.9M\n",
      " 53 1396M   53  741M    0     0  7473k      0  0:03:11  0:01:41  0:01:30 10.9M\n",
      " 53 1396M   53  752M    0     0  7512k      0  0:03:10  0:01:42  0:01:28 10.9M\n",
      " 54 1396M   54  763M    0     0  7551k      0  0:03:09  0:01:43  0:01:26 10.9M\n",
      " 55 1396M   55  775M    0     0  7589k      0  0:03:08  0:01:44  0:01:24 10.9M\n",
      " 56 1396M   56  785M    0     0  7613k      0  0:03:07  0:01:45  0:01:22 10.9M\n",
      " 57 1396M   57  796M    0     0  7649k      0  0:03:06  0:01:46  0:01:20 10.9M\n",
      " 57 1396M   57  807M    0     0  7685k      0  0:03:06  0:01:47  0:01:19 10.9M\n",
      " 58 1396M   58  818M    0     0  7720k      0  0:03:05  0:01:48  0:01:17 10.9M\n",
      " 59 1396M   59  829M    0     0  7755k      0  0:03:04  0:01:49  0:01:15 10.9M\n",
      " 60 1396M   60  839M    0     0  7777k      0  0:03:03  0:01:50  0:01:13 10.9M\n",
      " 60 1396M   60  851M    0     0  7810k      0  0:03:03  0:01:51  0:01:12 10.9M\n",
      " 61 1396M   61  862M    0     0  7843k      0  0:03:02  0:01:52  0:01:10 10.9M\n",
      " 62 1396M   62  873M    0     0  7875k      0  0:03:01  0:01:53  0:01:08 10.9M\n",
      " 63 1396M   63  884M    0     0  7907k      0  0:03:00  0:01:54  0:01:06 10.9M\n",
      " 64 1396M   64  894M    0     0  7928k      0  0:03:00  0:01:55  0:01:05 11.0M\n",
      " 64 1396M   64  906M    0     0  7958k      0  0:02:59  0:01:56  0:01:03 10.9M\n",
      " 65 1396M   65  917M    0     0  7988k      0  0:02:59  0:01:57  0:01:02 10.9M\n",
      " 66 1396M   66  928M    0     0  8018k      0  0:02:58  0:01:58  0:01:00 10.9M\n",
      " 67 1396M   67  939M    0     0  8047k      0  0:02:57  0:01:59  0:00:58 10.9M\n",
      " 68 1396M   68  950M    0     0  8075k      0  0:02:57  0:02:00  0:00:57 11.2M\n",
      " 68 1396M   68  961M    0     0  8094k      0  0:02:56  0:02:01  0:00:55 10.9M\n",
      " 69 1396M   69  972M    0     0  8121k      0  0:02:56  0:02:02  0:00:54 10.9M\n",
      " 70 1396M   70  983M    0     0  8149k      0  0:02:55  0:02:03  0:00:52 10.9M\n",
      " 71 1396M   71  994M    0     0  8176k      0  0:02:54  0:02:04  0:00:50 10.9M\n",
      " 72 1396M   72 1006M    0     0  8202k      0  0:02:54  0:02:05  0:00:49 11.0M\n",
      " 72 1396M   72 1015M    0     0  8218k      0  0:02:54  0:02:06  0:00:48 10.9M\n",
      " 73 1396M   73 1027M    0     0  8244k      0  0:02:53  0:02:07  0:00:46 10.9M\n",
      " 74 1396M   74 1038M    0     0  8269k      0  0:02:52  0:02:08  0:00:44 10.9M\n",
      " 75 1396M   75 1049M    0     0  8294k      0  0:02:52  0:02:09  0:00:43 10.9M\n",
      " 75 1396M   75 1060M    0     0  8319k      0  0:02:51  0:02:10  0:00:41 10.9M\n",
      " 76 1396M   76 1070M    0     0  8332k      0  0:02:51  0:02:11  0:00:40 10.9M\n",
      " 77 1396M   77 1082M    0     0  8356k      0  0:02:51  0:02:12  0:00:39 10.9M\n",
      " 78 1396M   78 1093M    0     0  8380k      0  0:02:50  0:02:13  0:00:37 10.9M\n",
      " 79 1396M   79 1104M    0     0  8403k      0  0:02:50  0:02:14  0:00:36 10.9M\n",
      " 79 1396M   79 1115M    0     0  8426k      0  0:02:49  0:02:15  0:00:34 10.9M\n",
      " 80 1396M   80 1125M    0     0  8439k      0  0:02:49  0:02:16  0:00:33 10.9M\n",
      " 81 1396M   81 1136M    0     0  8461k      0  0:02:49  0:02:17  0:00:32 10.9M\n",
      " 82 1396M   82 1148M    0     0  8483k      0  0:02:48  0:02:18  0:00:30 10.9M\n",
      " 82 1396M   82 1159M    0     0  8505k      0  0:02:48  0:02:19  0:00:29 10.9M\n",
      " 83 1396M   83 1170M    0     0  8526k      0  0:02:47  0:02:20  0:00:27 10.9M\n",
      " 84 1396M   84 1181M    0     0  8545k      0  0:02:47  0:02:21  0:00:26 11.1M\n",
      " 85 1396M   85 1191M    0     0  8559k      0  0:02:47  0:02:22  0:00:25 10.9M\n",
      " 86 1396M   86 1203M    0     0  8579k      0  0:02:46  0:02:23  0:00:23 10.9M\n",
      " 86 1396M   86 1214M    0     0  8599k      0  0:02:46  0:02:24  0:00:22 10.9M\n",
      " 87 1396M   87 1225M    0     0  8619k      0  0:02:45  0:02:25  0:00:20 10.9M\n",
      " 88 1396M   88 1236M    0     0  8639k      0  0:02:45  0:02:26  0:00:19 11.0M\n",
      " 89 1396M   89 1246M    0     0  8650k      0  0:02:45  0:02:27  0:00:18 10.9M\n",
      " 90 1396M   90 1258M    0     0  8669k      0  0:02:45  0:02:28  0:00:17 10.9M\n",
      " 90 1396M   90 1269M    0     0  8688k      0  0:02:44  0:02:29  0:00:15 10.9M\n",
      " 91 1396M   91 1280M    0     0  8707k      0  0:02:44  0:02:30  0:00:14 10.9M\n",
      " 92 1396M   92 1291M    0     0  8725k      0  0:02:43  0:02:31  0:00:12 10.9M\n",
      " 93 1396M   93 1301M    0     0  8734k      0  0:02:43  0:02:32  0:00:11 10.9M\n",
      " 93 1396M   93 1312M    0     0  8752k      0  0:02:43  0:02:33  0:00:10 10.9M\n",
      " 94 1396M   94 1323M    0     0  8769k      0  0:02:43  0:02:34  0:00:09 10.9M\n",
      " 95 1396M   95 1335M    0     0  8787k      0  0:02:42  0:02:35  0:00:07 10.9M\n",
      " 96 1396M   96 1346M    0     0  8804k      0  0:02:42  0:02:36  0:00:06 10.9M\n",
      " 97 1396M   97 1356M    0     0  8813k      0  0:02:42  0:02:37  0:00:05 10.9M\n",
      " 97 1396M   97 1367M    0     0  8830k      0  0:02:41  0:02:38  0:00:03 10.9M\n",
      " 98 1396M   98 1378M    0     0  8847k      0  0:02:41  0:02:39  0:00:02 10.9M\n",
      " 99 1396M   99 1390M    0     0  8863k      0  0:02:41  0:02:40  0:00:01 10.9M\n",
      "100 1396M  100 1396M    0     0  8874k      0  0:02:41  0:02:41 --:--:-- 10.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/agungmrf/indonesian-sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b63abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    Example: src_folder/cat -> dataset/cat\n",
    "             src_folder/dog -> dataset/dog\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all label folders in the source\n",
    "    for label in os.listdir(src_folder):\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Skip if not a folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Move all files from src  dest\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Avoid overwriting files with same name\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_2{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\" Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ekstraksi dataset dari ./indonesian-sign-language-bisindo.zip ...\n",
      " Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61be52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged './bisindo/images/train' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged './bisindo/images/val' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset('./bisindo/images/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1353535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Menghapus folder: ./bisindo\n",
      " Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\" Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\" Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\" Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbeabb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/yunitayupratiwi/bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ekstraksi dataset dari ./bisindo-dataset.zip ...\n",
      " Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, based on the first letter of the filename.\n",
    "    Example: src_folder/A.66ae97e2-c1e4-11eb-83d3-0008ca6b6d30.jpg -> dataset/A\n",
    "             src_folder/B.002d8fdf-c1e3-11eb-952a-0008ca6b6d30.jpg -> dataset/B\n",
    "    \"\"\"\n",
    "    # Ensure destination exists\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over all file folders in the source\n",
    "    for filename in os.listdir(src_folder):\n",
    "        src_file = os.path.join(src_folder, filename)\n",
    "\n",
    "        # Skip if a folder\n",
    "        if os.path.isdir(src_file):\n",
    "            continue\n",
    "        \n",
    "        # Skip if not a jpg\n",
    "        if not src_file.lower().endswith('.jpg'):\n",
    "            continue\n",
    "        \n",
    "        label = filename[0].upper()  # First character as label\n",
    "        dest = os.path.join(dataset_dir, label)\n",
    "        # Create label folder in destination if needed\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        dst_file = os.path.join(dest, filename)\n",
    "\n",
    "        # Avoid overwriting files with same name\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            dst_file = os.path.join(dest, f\"{base}_3{ext}\")\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "    print(f\"successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b15a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf12b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully!\n"
     ]
    }
   ],
   "source": [
    "construct_dataset(\"./BISINDO - Dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e913a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Menghapus folder: ./BISINDO - Dataset\n",
      " Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./BISINDO - Dataset\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\" Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\" Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\" Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca6282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  238M  100  238M    0     0  2646k      0  0:01:32  0:01:32 --:--:-- 2901k  2370k      0  0:01:43  0:00:05  0:01:38 3158k   0  0:01:35  0:00:47  0:00:48 2584k590k      0  0:01:34  0:00:54  0:00:40 2818k   0  0:01:34  0:01:02  0:00:32 2759k1:33  0:01:15  0:00:18 2674k0  2626k      0  0:01:33  0:01:16  0:00:17 2800k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./sign-language-bisindo.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/bonarsitorus/sign-language-bisindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e87a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ekstraksi dataset dari ./sign-language-bisindo.zip ...\n",
      " Dataset berhasil diekstrak ke ./\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./sign-language-bisindo.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_4(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure,\n",
    "    except folders with '_npy' in their name.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "        # Lewati folder yang mengandung '_npy'\n",
    "        if \"_npy\" in label:\n",
    "            continue\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_4{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\" Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debd9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged './data_tambahan' into './dataset' successfully!\n"
     ]
    }
   ],
   "source": [
    "merge_dataset_4('./data_tambahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3406b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Menghapus folder: ./data_tambahan\n",
      " Folder berhasil dihapus.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./data_tambahan\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\" Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\" Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\" Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da58f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1944M  100 1944M    0     0  2602k      0  0:12:45  0:12:45 --:--:-- 2673k   0     0  2393k      0  0:13:52  0:00:13  0:13:39 2692kk      0  0:12:47  0:00:39  0:12:08 2700k:00  0:11:38 2686k   0  0:12:32  0:01:23  0:11:09 2677k655k      0  0:12:29  0:01:38  0:10:51 2709k    0     0  2657k      0  0:12:29  0:01:42  0:10:47 2615k 2660k      0  0:12:28  0:02:05  0:10:23 2516k31  0:02:29  0:10:02 2710k 0  2644k      0  0:12:32  0:03:03  0:09:29 2612k11  0:09:20 2628k      0  0:12:32  0:03:25  0:09:07 2644k0:12:32  0:03:30  0:09:02 2652k 2642k      0  0:12:33  0:03:44  0:08:49 2555k7k      0  0:12:38  0:04:26  0:08:12 2576k      0  0:12:37  0:04:28  0:08:09 2770k:37  0:08:00 2650k      0  0:12:37  0:04:41  0:07:56 2721k    0  0:12:37  0:04:45  0:07:52 2650k      0  0:12:37  0:04:47  0:07:50 2730k 0  2629k      0  0:12:37  0:05:01  0:07:36 2608k0  2629k      0  0:12:37  0:05:07  0:07:30 2596k2631k      0  0:12:36  0:05:30  0:07:06 2813k 2629k      0  0:12:37  0:05:45  0:06:52 2698k:06:11  0:06:27 2694k 0  0:12:38  0:06:14  0:06:24 2622k:40  0:07:45  0:04:55 2442k2619k      0  0:12:40  0:08:05  0:04:35 2466k   0  2619k      0  0:12:40  0:08:06  0:04:34 2924k0     0  2619k      0  0:12:40  0:08:12  0:04:28 2607k   0  2619k      0  0:12:40  0:08:13  0:04:27 2608k   0     0  2620k      0  0:12:39  0:08:20  0:04:19 2749k     0  0:12:40  0:08:21  0:04:19 2662k 2614k      0  0:12:41  0:08:40  0:04:01 2584k5k      0  0:12:41  0:09:16  0:03:25 2512k 0  2613k      0  0:12:42  0:09:38  0:03:04 2670k   0     0  2614k      0  0:12:41  0:09:39  0:03:02 2765k 0:02:53 2649k  2614k      0  0:12:41  0:09:58  0:02:43 2727k2k      0  0:12:42  0:10:36  0:02:06 2544k    0  0:12:45  0:11:37  0:01:08 2370k602k      0  0:12:45  0:11:47  0:00:58 2643k    0  0:12:45  0:11:54  0:00:51 2613k 0  2602k      0  0:12:45  0:12:02  0:00:43 2562k    0  0:12:45  0:12:06  0:00:39 2605k5  0:12:06  0:00:39 2610k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./indonesian-hand-sign-language-bisindo-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/kelsha/indonesian-hand-sign-language-bisindo-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-hand-sign-language-bisindo-dataset.zip\"\n",
    "extract_dir = \"./\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_5(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_5{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\" Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bsindo/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d39e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_5('./dataset_bsindo/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1beb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./dataset_bsindo\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\" Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\" Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\" Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0 24.1M    0   527    0     0    426      0 16:30:15  0:00:01 16:30:14   426\n",
      "  2 24.1M    2  501k    0     0   239k      0  0:01:43  0:00:02  0:01:41  585k\n",
      "  2 24.1M    2  723k    0     0   213k      0  0:01:55  0:00:03  0:01:52  334k\n",
      "  2 24.1M    2  723k    0     0   164k      0  0:02:30  0:00:04  0:02:26  228k\n",
      "  2 24.1M    2  723k    0     0   134k      0  0:03:04  0:00:05  0:02:59  173k\n",
      "  2 24.1M    2  723k    0     0   113k      0  0:03:38  0:00:06  0:03:32  140k\n",
      "  2 24.1M    2  723k    0     0    97k      0  0:04:12  0:00:07  0:04:05 42896\n",
      "  2 24.1M    2  723k    0     0  88168      0  0:04:47  0:00:08  0:04:39     0\n",
      "  2 24.1M    2  723k    0     0  78790      0  0:05:21  0:00:09  0:05:12     0\n",
      "  2 24.1M    2  723k    0     0  71129      0  0:05:55  0:00:10  0:05:45     0\n",
      "  2 24.1M    2  723k    0     0  64825      0  0:06:30  0:00:11  0:06:19     0\n",
      "  2 24.1M    2  723k    0     0  59545      0  0:07:05  0:00:12  0:06:53     0\n",
      "  2 24.1M    2  723k    0     0  55057      0  0:07:39  0:00:13  0:07:26     0\n",
      "  2 24.1M    2  723k    0     0  51244      0  0:08:13  0:00:14  0:07:59     0\n",
      "  2 24.1M    2  723k    0     0  47927      0  0:08:48  0:00:15  0:08:33     0\n",
      "  2 24.1M    2  723k    0     0  44978      0  0:09:22  0:00:16  0:09:06     0\n",
      "  2 24.1M    2  723k    0     0  42371      0  0:09:57  0:00:17  0:09:40     0\n",
      "  2 24.1M    2  723k    0     0  40076      0  0:10:31  0:00:18  0:10:13     0\n",
      "  2 24.1M    2  723k    0     0  37995      0  0:11:06  0:00:19  0:10:47     0\n",
      "  2 24.1M    2  723k    0     0  36143      0  0:11:40  0:00:20  0:11:20     0\n",
      "  2 24.1M    2  723k    0     0  34440      0  0:12:14  0:00:21  0:11:53     0\n",
      "  2 24.1M    2  723k    0     0  32893      0  0:12:49  0:00:22  0:12:27     0\n",
      "  2 24.1M    2  723k    0     0  31478      0  0:13:24  0:00:23  0:13:01     0\n",
      "  2 24.1M    2  723k    0     0  30178      0  0:13:58  0:00:24  0:13:34     0\n",
      "  2 24.1M    2  723k    0     0  28981      0  0:14:33  0:00:25  0:14:08     0\n",
      "  2 24.1M    2  723k    0     0  27889      0  0:15:07  0:00:26  0:14:41     0\n",
      "  2 24.1M    2  723k    0     0  26863      0  0:15:42  0:00:27  0:15:15     0\n",
      "  2 24.1M    2  723k    0     0  25912      0  0:16:16  0:00:28  0:15:48     0\n",
      "  2 24.1M    2  723k    0     0  25025      0  0:16:51  0:00:29  0:16:22     0\n",
      "  2 24.1M    2  723k    0     0  24197      0  0:17:26  0:00:30  0:16:56     0\n",
      "  2 24.1M    2  723k    0     0  23421      0  0:18:00  0:00:31  0:17:29     0\n",
      "  2 24.1M    2  723k    0     0  22695      0  0:18:35  0:00:32  0:18:03     0\n",
      "  2 24.1M    2  723k    0     0  22012      0  0:19:09  0:00:33  0:18:36     0\n",
      "  2 24.1M    2  723k    0     0  21369      0  0:19:44  0:00:34  0:19:10     0\n",
      "  2 24.1M    2  723k    0     0  20770      0  0:20:18  0:00:35  0:19:43     0\n",
      "  2 24.1M    2  723k    0     0  20196      0  0:20:53  0:00:36  0:20:17     0\n",
      "  2 24.1M    2  723k    0     0  19655      0  0:21:27  0:00:37  0:20:50     0\n",
      "  2 24.1M    2  723k    0     0  19140      0  0:22:02  0:00:38  0:21:24     0\n",
      "  3 24.1M    3  742k    0     0  19440      0  0:21:42  0:00:39  0:21:03  4324\n",
      "  3 24.1M    3  781k    0     0  19711      0  0:21:24  0:00:40  0:20:44 11999\n",
      "  3 24.1M    3  781k    0     0  19236      0  0:21:55  0:00:41  0:21:14 12031\n",
      "  3 24.1M    3  794k    0     0  19292      0  0:21:51  0:00:42  0:21:09 16230\n",
      "  3 24.1M    3  794k    0     0  18841      0  0:22:23  0:00:43  0:21:40 16252\n",
      "  3 24.1M    3  822k    0     0  19092      0  0:22:05  0:00:44  0:21:21 16377\n",
      "  3 24.1M    3  874k    0     0  19544      0  0:21:35  0:00:45  0:20:50 18246\n",
      "  3 24.1M    3  876k    0     0  19434      0  0:21:42  0:00:46  0:20:56 21235\n",
      "  3 24.1M    3  914k    0     0  19597      0  0:21:31  0:00:47  0:20:44 21900\n",
      "  3 24.1M    3  914k    0     0  19190      0  0:21:58  0:00:48  0:21:10 21884\n",
      "  3 24.1M    3  914k    0     0  18800      0  0:22:26  0:00:49  0:21:37 16535\n",
      "  3 24.1M    3  914k    0     0  18424      0  0:22:53  0:00:50  0:22:03  8193\n",
      "  3 24.1M    3  914k    0     0  18064      0  0:23:21  0:00:51  0:22:30  6964\n",
      "  3 24.1M    3  914k    0     0  17718      0  0:23:48  0:00:52  0:22:56     0\n",
      "  3 24.1M    3  914k    0     0  17384      0  0:24:15  0:00:53  0:23:22     0\n",
      "  3 24.1M    3  914k    0     0  17063      0  0:24:43  0:00:54  0:23:49     0\n",
      "  3 24.1M    3  914k    0     0  16753      0  0:25:10  0:00:55  0:24:15     0\n",
      "  3 24.1M    3  914k    0     0  16458      0  0:25:37  0:00:56  0:24:41     0\n",
      "  3 24.1M    3  914k    0     0  16174      0  0:26:04  0:00:57  0:25:07     0\n",
      "  3 24.1M    3  914k    0     0  15895      0  0:26:32  0:00:58  0:25:34     0\n",
      "  3 24.1M    3  914k    0     0  15630      0  0:26:59  0:00:59  0:26:00     0\n",
      "  3 24.1M    3  914k    0     0  15370      0  0:27:26  0:01:00  0:26:26     0\n",
      "  3 24.1M    3  914k    0     0  15118      0  0:27:54  0:01:01  0:26:53     0\n",
      "  3 24.1M    3  914k    0     0  14875      0  0:28:21  0:01:02  0:27:19     0\n",
      "  3 24.1M    3  914k    0     0  14639      0  0:28:49  0:01:03  0:27:46     0\n",
      "  3 24.1M    3  914k    0     0  14411      0  0:29:16  0:01:05  0:28:11     0\n",
      "  3 24.1M    3  914k    0     0  14192      0  0:29:43  0:01:06  0:28:37     0\n",
      "  3 24.1M    3  914k    0     0  13979      0  0:30:10  0:01:07  0:29:03     0\n",
      "  3 24.1M    3  914k    0     0  13773      0  0:30:37  0:01:08  0:29:29     0\n",
      "  3 24.1M    3  914k    0     0  13571      0  0:31:05  0:01:09  0:29:56     0\n",
      "  3 24.1M    3  917k    0     0  13474      0  0:31:18  0:01:09  0:30:09   585\n",
      "  4 24.1M    4  998k    0     0  14593      0  0:28:54  0:01:10  0:27:44 21095\n",
      " 15 24.1M   15 3742k    0     0  53921      0  0:07:49  0:01:11  0:06:38  696k\n",
      " 61 24.1M   61 14.7M    0     0   210k      0  0:01:57  0:01:12  0:00:45 3506k\n",
      "100 24.1M  100 24.1M    0     0   339k      0  0:01:12  0:01:12 --:--:-- 6139k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./bisindo-final.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/skripsiairlangga/bisindo-final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ca9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import platform\n",
    "\n",
    "zip_path = \"./indonesian-hand-sign-language-bisindo-dataset.zip\"\n",
    "extract_dir = \"./bisindo_final\"\n",
    "\n",
    "if not os.path.exists(zip_path):\n",
    "    raise FileNotFoundError(f\" File tidak ditemukan: {zip_path}\")\n",
    "\n",
    "# Membuat folder extract_dir jika belum ada\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "print(f\" Ekstraksi dataset dari {zip_path} ...\")\n",
    "if platform.system() in [\"Windows\", \"Darwin\", \"Linux\"]:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\" Dataset berhasil diekstrak ke {extract_dir}\")\n",
    "else:\n",
    "    print(f\" OS {platform.system()} belum dikenali, pastikan unzip dilakukan manual.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57255468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataset_6(src_folder):\n",
    "    \"\"\"\n",
    "    Move files from src_folder into dataset, preserving subfolder (label) structure.\n",
    "    \"\"\"\n",
    "    # Pastikan folder tujuan ada\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    # Iterasi semua folder di src_folder\n",
    "    for label in os.listdir(src_folder):\n",
    "\n",
    "        label_path_src = os.path.join(src_folder, label)\n",
    "        label_path_dest = os.path.join(dataset_dir, label)\n",
    "\n",
    "        # Pastikan ini folder\n",
    "        if not os.path.isdir(label_path_src):\n",
    "            continue\n",
    "\n",
    "        # Buat folder di tujuan jika belum ada\n",
    "        os.makedirs(label_path_dest, exist_ok=True)\n",
    "\n",
    "        # Pindahkan semua file\n",
    "        for filename in os.listdir(label_path_src):\n",
    "            src = os.path.join(label_path_src, filename)\n",
    "            dst = os.path.join(label_path_dest, filename)\n",
    "\n",
    "            # Hindari overwrite\n",
    "            if os.path.exists(dst):\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                dst = os.path.join(label_path_dest, f\"{base}_6{ext}\")\n",
    "\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(f\" Merged '{src_folder}' into '{dataset_dir}' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dataset_6('./bisindo_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_path = \"./bisindo_final\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\" Menghapus folder: {folder_path}\")\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(\" Folder berhasil dihapus.\")\n",
    "else:\n",
    "    print(\" Folder tidak ditemukan, tidak ada yang dihapus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5244c24",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data generators ===\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4257553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23267 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5805 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9411987",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db2e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f130e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f9fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Compile model ===\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeeaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 6. Tambahkan EarlyStopping ===\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "565b55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\anaconda3\\envs\\aienv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m727/727\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - accuracy: 0.7211 - loss: 1.0385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\anaconda3\\envs\\aienv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m727/727\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 662ms/step - accuracy: 0.8114 - loss: 0.6705 - val_accuracy: 0.2869 - val_loss: 3.0424\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/727\u001b[0m \u001b[37m\u001b[0m \u001b[1m2:57\u001b[0m 245ms/step - accuracy: 0.8750 - loss: 0.3267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WINDOWS 10\\anaconda3\\envs\\aienv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m727/727\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 143ms/step - accuracy: 0.8750 - loss: 0.3267 - val_accuracy: 0.2833 - val_loss: 3.0793\n",
      "Epoch 3/20\n",
      "\u001b[1m727/727\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 571ms/step - accuracy: 0.8986 - loss: 0.3285 - val_accuracy: 0.2925 - val_loss: 3.3264\n",
      "Epoch 4/20\n",
      "\u001b[1m727/727\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 143ms/step - accuracy: 0.9688 - loss: 0.2405 - val_accuracy: 0.2854 - val_loss: 3.3609\n"
     ]
    }
   ],
   "source": [
    "# === 7. Train model dengan validasi ===\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9753c53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m plt.plot(history.history[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel Accuracy and Loss\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(['Accuracy', 'Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e90ded",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{model_name}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 26), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  6010126160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079024016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079022288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010125776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010125968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010119632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079023632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079024784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079024400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079024208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079021328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079025936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079026128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079023056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079023440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079026704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079028816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079029008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079027856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079027280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079025744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079030160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079030352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079029584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079027088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079029200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079027664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079028624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079029776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079031312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079030736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079030928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079031120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079029968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079032272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079031696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079031888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079032080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079028048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079033232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079033616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079033808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079032848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079033424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079035536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079033040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010533072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010532688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010531728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010533840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079035920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079035728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079036496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079032656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079036688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079036112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079035152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079036880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079037264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079036304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079032464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079035344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079037072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079034192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075842832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075842640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075844752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075844176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075844368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075844560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075845712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075845136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075845328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075845520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075846672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075846096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075846288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075846480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075843024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075847632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075847056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075847248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075847440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075844944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075845904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075849552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075849168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075849360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075846864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075850512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075849936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075850128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075850320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075847824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075851472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075850896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075851088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075851280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075848784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075852432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075851856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075852048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075852240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075849744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075852816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075850704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075854352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075854160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075851664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075855312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075854736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075854928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075855120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075852624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075856272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075855696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075856080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075853584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075857232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075856656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075856848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075857040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075854544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075858192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075857616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075857808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075858384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075858768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075857424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075856464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075858000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079595536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075858576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6075855504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079595728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079594768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079594576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079595152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079596688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079596112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079596304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079596496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079595920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079597648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079597072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079597264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079597456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079595344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079594960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079599568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079599184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079599376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079596880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079600528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079599952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079600144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079600336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079597840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079601488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079600912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079601104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079601296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079598800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079602448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079601872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079602064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079602256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079599760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079602832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079600720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079604368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079604176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079601680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079605328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079604752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079604944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079605136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079602640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079606288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079605712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079605904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079606096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079603600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079607248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079606672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079606864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079607056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079604560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079607632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079607824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079605520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079609168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079606480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079610128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079609552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079609744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079610320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079610704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079609360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079608400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079609936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080480272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079610512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6079607440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080480464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080479504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080479312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080479888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080481424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080480848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080481040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080481232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080480656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080482384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080481808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080482000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080482192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080480080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080483344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080482768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080482960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080483152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080479696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080484304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6010125584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080485072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080484880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  6080484112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1760521269.879621 24783483 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1760521269.879659 24783483 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-15 16:41:09.879916: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75\n",
      "2025-10-15 16:41:09.888490: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-15 16:41:09.888542: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75\n",
      "2025-10-15 16:41:09.977671: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-15 16:41:10.523603: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/w3/12vhw4l144v3jqftz9jdh2cc0000gn/T/tmpy5vxmh75\n",
      "2025-10-15 16:41:10.641098: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 761182 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the .tflite file\n",
    "with open(f\"{model_name}.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a466141",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d3cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=f\"{model_name}.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a70785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input & output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0]['shape'][1:3]  # (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9a2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels A-Z\n",
    "labels = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cb4064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/ImageFile.py:644\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     fh = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m()\n\u001b[32m    645\u001b[39m     fp.flush()\n",
      "\u001b[31mAttributeError\u001b[39m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m         cv2.putText(frame, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mletter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, (\u001b[32m10\u001b[39m, \u001b[32m30\u001b[39m),\n\u001b[32m     26\u001b[39m                     cv2.FONT_HERSHEY_SIMPLEX, \u001b[32m1\u001b[39m, (\u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m), \u001b[32m2\u001b[39m)\n\u001b[32m     28\u001b[39m         clear_output(wait=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     cap.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/IPython/core/display_functions.py:278\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     publish_display_data(data=obj, metadata=metadata, **kwargs)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     format_dict, md_dict = \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/IPython/core/formatters.py:238\u001b[39m, in \u001b[36mDisplayFormatter.format\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    236\u001b[39m md = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     data = \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/IPython/core/formatters.py:282\u001b[39m, in \u001b[36mcatch_format_error\u001b[39m\u001b[34m(method, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     r = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/IPython/core/formatters.py:406\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    404\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/Image.py:717\u001b[39m, in \u001b[36mImage._repr_png_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    713\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"iPython display hook support for PNG format.\u001b[39;00m\n\u001b[32m    714\u001b[39m \n\u001b[32m    715\u001b[39m \u001b[33;03m    :returns: PNG version of the image as bytes\u001b[39;00m\n\u001b[32m    716\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_repr_image\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPNG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress_level\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/Image.py:707\u001b[39m, in \u001b[36mImage._repr_image\u001b[39m\u001b[34m(self, image_format, **kwargs)\u001b[39m\n\u001b[32m    705\u001b[39m b = io.BytesIO()\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/Image.py:2588\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2585\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[32m   2587\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2588\u001b[39m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2590\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/PngImagePlugin.py:1495\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename, chunk, save_all)\u001b[39m\n\u001b[32m   1491\u001b[39m     single_im = _write_multiple_frames(\n\u001b[32m   1492\u001b[39m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[32m   1493\u001b[39m     )\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_im:\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     \u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m   1502\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info.chunks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/ImageFile.py:648\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    646\u001b[39m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io.UnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[33m\"\u001b[39m\u001b[33mflush\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    650\u001b[39m     fp.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ai-rhn/lib/python3.12/site-packages/PIL/ImageFile.py:674\u001b[39m, in \u001b[36m_encode_tile\u001b[39m\u001b[34m(im, fp, tile, bufsize, fh, exc)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[32m    672\u001b[39m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m         errcode, data = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m:]\n\u001b[32m    675\u001b[39m         fp.write(data)\n\u001b[32m    676\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img = cv2.resize(frame, (224, 224))\n",
    "        input_data = np.expand_dims(img.astype(np.float32) / 255.0, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred = np.argmax(output)\n",
    "        letter = labels[pred] if pred < len(labels) else \"?\"\n",
    "\n",
    "        cv2.putText(frame, f\"Pred: {letter}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    time.sleep(0.5)\n",
    "    del cap\n",
    "    cv2.VideoCapture(0).release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera released.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-rhn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
