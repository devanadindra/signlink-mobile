{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "✅ Classes word: ['aku', 'hai']\n",
      "✅ Classes letter: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760424911.130979       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2025-10-14 13:55:11.227 python[3945:57703] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kamera aktif. Tekan 'q' untuk keluar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 13:55:13.693 python[3945:57703] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-10-14 13:55:13.693 python[3945:57703] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# mirror\u001b[39;00m\n\u001b[1;32m     71\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 72\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Gambar landmark\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slenv/lib/python3.10/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slenv/lib/python3.10/site-packages/mediapipe/python/solution_base.py:364\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m RGB_CHANNELS:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput image must contain three channel rgb data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    362\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    363\u001b[0m       stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m--> 364\u001b[0m       packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_stream_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    368\u001b[0m       stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    369\u001b[0m       packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    370\u001b[0m                                data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slenv/lib/python3.10/site-packages/mediapipe/python/solution_base.py:596\u001b[0m, in \u001b[0;36mSolutionBase._make_packet\u001b[0;34m(self, packet_data_type, data)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_packet\u001b[39m(\u001b[38;5;28mself\u001b[39m, packet_data_type: PacketDataType,\n\u001b[1;32m    593\u001b[0m                  data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m packet\u001b[38;5;241m.\u001b[39mPacket:\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (packet_data_type \u001b[38;5;241m==\u001b[39m PacketDataType\u001b[38;5;241m.\u001b[39mIMAGE_FRAME \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    595\u001b[0m       packet_data_type \u001b[38;5;241m==\u001b[39m PacketDataType\u001b[38;5;241m.\u001b[39mIMAGE):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpacket_data_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFormat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(packet_creator, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m packet_data_type\u001b[38;5;241m.\u001b[39mvalue)(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/slenv/lib/python3.10/site-packages/mediapipe/python/packet_creator.py:147\u001b[0m, in \u001b[0;36mcreate_image_frame\u001b[0;34m(data, image_format, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m is still writeable. Taking a reference of the data to create ImageFrame packet is dangerous.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_packet_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_image_frame_from_pixel_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ====== Load model kata ======\n",
    "model_word = tf.keras.models.load_model(\"../models/sign_word_model.keras\", compile=False)\n",
    "\n",
    "# ====== Load label encoder kata ======\n",
    "with open(\"../models/label_word_encoder.pkl\", \"rb\") as f:\n",
    "    le_word = pickle.load(f)\n",
    "classes_word = list(le_word.classes_)\n",
    "print(f\"✅ Classes word: {classes_word}\")\n",
    "\n",
    "# ====== Load model huruf ======\n",
    "model_letter = tf.keras.models.load_model(\"../models/sign_letter_model.keras\", compile=False)\n",
    "\n",
    "# ====== Load label encoder huruf ======\n",
    "with open(\"../models/label_letter_encoder.pkl\", \"rb\") as f:\n",
    "    le_letter = pickle.load(f)\n",
    "classes_letter = list(le_letter.classes_)\n",
    "print(f\"✅ Classes letter: {classes_letter}\")\n",
    "\n",
    "# ====== Inisialisasi Mediapipe ======\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    smooth_landmarks=True,\n",
    "    enable_segmentation=False,\n",
    "    refine_face_landmarks=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# ====== Fungsi ekstrak keypoints ======\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]).flatten() \\\n",
    "        if results.pose_landmarks else np.zeros(33*3)\n",
    "\n",
    "    lh = np.array([[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.left_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    rh = np.array([[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    return np.concatenate([pose, lh, rh])\n",
    "\n",
    "# ====== Variabel untuk menyimpan urutan frame ======\n",
    "sequence = []\n",
    "seq_length = 30  # jumlah frame sebelum prediksi kata\n",
    "\n",
    "# ====== Mulai kamera ======\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Kamera tidak terdeteksi.\")\n",
    "    exit()\n",
    "print(\"✅ Kamera aktif. Tekan 'q' untuk keluar...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"⚠️ Gagal membaca frame dari kamera.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # mirror\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image_rgb)\n",
    "\n",
    "    # Gambar landmark\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    # Ekstrak keypoints\n",
    "    keypoints = extract_keypoints(results)\n",
    "    sequence.append(keypoints)\n",
    "    sequence = sequence[-seq_length:]\n",
    "\n",
    "    # ====== Prediksi kata ======\n",
    "    if len(sequence) == seq_length:\n",
    "        X_input_word = np.expand_dims(sequence, axis=0)\n",
    "        y_pred_word = model_word.predict(X_input_word, verbose=0)\n",
    "        pred_word = classes_word[np.argmax(y_pred_word)]\n",
    "        cv2.putText(frame, f\"Word: {pred_word}\", (20, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # ====== Prediksi huruf ======\n",
    "    # Sesuaikan input dengan model huruf\n",
    "    X_input_letter = np.expand_dims(keypoints, axis=0)  # shape (1, 225)\n",
    "    y_pred_letter = model_letter.predict(X_input_letter, verbose=0)\n",
    "    pred_letter_idx = np.argmax(y_pred_letter)\n",
    "    pred_letter = le_letter.inverse_transform([pred_letter_idx])[0]\n",
    "\n",
    "    cv2.putText(frame, f\"Letter: {pred_letter}\", (20, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Tampilkan frame\n",
    "    cv2.imshow(\"Sign Translator\", frame)\n",
    "\n",
    "    # Tekan 'q' untuk keluar\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
